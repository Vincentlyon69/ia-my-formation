<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Manuel IA MYM 2025 - BLOC 11.6 - Post-Traitement Audio Avanc√©</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
    <style>
        .gradient-bg {
            background: linear-gradient(135deg, #8B5CF6 0%, #06B6D4 50%, #10B981 100%);
        }
        .card-hover {
            transition: all 0.3s ease;
        }
        .card-hover:hover {
            transform: translateY(-2px);
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
        }
        .code-block {
            background: #1a1a1a;
            border-radius: 8px;
            padding: 16px;
            margin: 16px 0;
            position: relative;
        }
        .copy-btn {
            position: absolute;
            top: 10px;
            right: 10px;
            background: #4F46E5;
            color: white;
            border: none;
            padding: 5px 10px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
        }
        .copy-btn:hover {
            background: #4338CA;
        }
        .warning-box {
            border-left: 4px solid #F59E0B;
            background: #FEF3C7;
            padding: 16px;
            margin: 16px 0;
        }
        .success-box {
            border-left: 4px solid #10B981;
            background: #D1FAE5;
            padding: 16px;
            margin: 16px 0;
        }
        .info-box {
            border-left: 4px solid #3B82F6;
            background: #DBEAFE;
            padding: 16px;
            margin: 16px 0;
        }
        .step-number {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            margin-right: 12px;
        }
        .audio-waveform {
            background: linear-gradient(90deg, #3B82F6, #06B6D4, #10B981);
            height: 60px;
            border-radius: 4px;
            position: relative;
            overflow: hidden;
        }
        .waveform-bars {
            display: flex;
            height: 100%;
            align-items: end;
            justify-content: space-around;
            padding: 8px;
        }
        .waveform-bar {
            background: rgba(255,255,255,0.8);
            width: 3px;
            border-radius: 2px;
            animation: waveform 2s ease-in-out infinite;
        }
        @keyframes waveform {
            0%, 100% { height: 20%; }
            50% { height: 90%; }
        }
        .eq-band {
            background: linear-gradient(180deg, #8B5CF6, #06B6D4);
            width: 40px;
            margin: 0 4px;
            border-radius: 4px;
            position: relative;
            cursor: pointer;
        }
        .eq-slider {
            background: #fff;
            border: 2px solid #4F46E5;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            cursor: grab;
        }
        .freq-label {
            text-align: center;
            font-size: 10px;
            margin-top: 4px;
        }
    </style>
</head>
<body class="bg-gray-50">

    <!-- Header -->
    <header class="gradient-bg text-white py-16">
        <div class="container mx-auto px-6">
            <div class="text-center">
                <div class="mb-6">
                    <i class="fas fa-volume-up text-6xl mb-4"></i>
                </div>
                <h1 class="text-5xl font-bold mb-4">BLOC 11.6 - Post-Traitement Audio Avanc√©</h1>
                <h2 class="text-2xl font-light mb-6">Nettoyage, √âgalisation & Effets R√©alistes</h2>
                <p class="text-xl max-w-4xl mx-auto leading-relaxed">
                    Ma√Ætrisez les techniques professionnelles de post-traitement audio pour transformer vos clonages vocaux 
                    en productions studio de qualit√© industrielle. Ajout d'effets r√©alistes, nettoyage avanc√© et mixage professionnel.
                </p>
                <div class="mt-8 flex justify-center space-x-4">
                    <span class="bg-white bg-opacity-20 rounded-full px-6 py-2 text-sm font-medium">
                        <i class="fas fa-microphone mr-2"></i>Post-Traitement Pro
                    </span>
                    <span class="bg-white bg-opacity-20 rounded-full px-6 py-2 text-sm font-medium">
                        <i class="fas fa-sliders-h mr-2"></i>√âgalisation Avanc√©e
                    </span>
                    <span class="bg-white bg-opacity-20 rounded-full px-6 py-2 text-sm font-medium">
                        <i class="fas fa-magic mr-2"></i>Effets R√©alistes
                    </span>
                </div>
            </div>
        </div>
    </header>

    <!-- Navigation -->
    <nav class="bg-white shadow-lg sticky top-0 z-50">
        <div class="container mx-auto px-6">
            <div class="flex justify-center">
                <div class="flex space-x-8 py-4">
                    <a href="#nettoyage" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-broom mr-2"></i>Nettoyage Audio
                    </a>
                    <a href="#equalisation" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-sliders-h mr-2"></i>√âgalisation
                    </a>
                    <a href="#effets" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-magic mr-2"></i>Effets R√©alistes
                    </a>
                    <a href="#mixage" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-volume-up mr-2"></i>Mixage Avanc√©
                    </a>
                    <a href="#automation" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-robot mr-2"></i>Automation
                    </a>
                </div>
            </div>
        </div>
    </nav>

    <!-- Objectif du Bloc -->
    <section class="py-16 bg-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-target mr-3 text-purple-600"></i>
                    Objectif Strat√©gique du Bloc 11.6
                </h3>
                <p class="text-gray-600 text-lg max-w-4xl mx-auto">
                    Transformer vos clonages vocaux bruts en productions audio professionnelles indiscernables 
                    d'enregistrements studio r√©els, avec tous les d√©tails et nuances d'une voix humaine naturelle.
                </p>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8">
                <div class="text-center">
                    <div class="bg-gradient-to-br from-blue-500 to-purple-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-broom text-white text-xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Nettoyage Professionnel</h4>
                    <p class="text-gray-600 text-sm">Suppression bruit, clics, artefacts num√©riques</p>
                </div>
                <div class="text-center">
                    <div class="bg-gradient-to-br from-green-500 to-blue-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-sliders-h text-white text-xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">√âgalisation Expert</h4>
                    <p class="text-gray-600 text-sm">EQ multi-bandes, correction formants</p>
                </div>
                <div class="text-center">
                    <div class="bg-gradient-to-br from-purple-500 to-pink-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-magic text-white text-xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Effets R√©alistes</h4>
                    <p class="text-gray-600 text-sm">Respirations, h√©sitations, micro-d√©tails</p>
                </div>
                <div class="text-center">
                    <div class="bg-gradient-to-br from-red-500 to-orange-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-robot text-white text-xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Automation Compl√®te</h4>
                    <p class="text-gray-600 text-sm">Scripts Python automatis√©s</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 1: Nettoyage Audio Professionnel -->
    <section id="nettoyage" class="py-16 bg-gray-50">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-broom mr-3 text-blue-600"></i>
                    Nettoyage Audio Professionnel
                </h3>
                <p class="text-gray-600 text-lg">Suppression des artefacts, bruit de fond et imperfections num√©riques</p>
            </div>

            <!-- Visualiseur Audio Avant/Apr√®s -->
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-12">
                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-red-600">
                        <i class="fas fa-times-circle mr-2"></i>Avant Nettoyage
                    </h4>
                    <div class="audio-waveform mb-4" style="background: linear-gradient(90deg, #EF4444, #F97316, #EAB308);">
                        <div class="waveform-bars">
                            <div class="waveform-bar" style="height: 80%; animation-delay: 0s;"></div>
                            <div class="waveform-bar" style="height: 30%; animation-delay: 0.1s;"></div>
                            <div class="waveform-bar" style="height: 90%; animation-delay: 0.2s;"></div>
                            <div class="waveform-bar" style="height: 10%; animation-delay: 0.3s;"></div>
                            <div class="waveform-bar" style="height: 70%; animation-delay: 0.4s;"></div>
                            <div class="waveform-bar" style="height: 95%; animation-delay: 0.5s;"></div>
                            <div class="waveform-bar" style="height: 40%; animation-delay: 0.6s;"></div>
                            <div class="waveform-bar" style="height: 85%; animation-delay: 0.7s;"></div>
                        </div>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li><i class="fas fa-exclamation-triangle text-red-500 mr-2"></i>Bruit de fond constant</li>
                        <li><i class="fas fa-exclamation-triangle text-red-500 mr-2"></i>Clics et pops audibles</li>
                        <li><i class="fas fa-exclamation-triangle text-red-500 mr-2"></i>Artefacts de compression</li>
                        <li><i class="fas fa-exclamation-triangle text-red-500 mr-2"></i>Distorsion num√©rique</li>
                    </ul>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-green-600">
                        <i class="fas fa-check-circle mr-2"></i>Apr√®s Nettoyage
                    </h4>
                    <div class="audio-waveform mb-4">
                        <div class="waveform-bars">
                            <div class="waveform-bar" style="height: 75%; animation-delay: 0s;"></div>
                            <div class="waveform-bar" style="height: 45%; animation-delay: 0.1s;"></div>
                            <div class="waveform-bar" style="height: 85%; animation-delay: 0.2s;"></div>
                            <div class="waveform-bar" style="height: 25%; animation-delay: 0.3s;"></div>
                            <div class="waveform-bar" style="height: 65%; animation-delay: 0.4s;"></div>
                            <div class="waveform-bar" style="height: 80%; animation-delay: 0.5s;"></div>
                            <div class="waveform-bar" style="height: 50%; animation-delay: 0.6s;"></div>
                            <div class="waveform-bar" style="height: 70%; animation-delay: 0.7s;"></div>
                        </div>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Signal propre et clair</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Bruit de fond supprim√©</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Dynamique pr√©serv√©e</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Qualit√© studio</li>
                    </ul>
                </div>
            </div>

            <!-- Script Python Nettoyage Professionnel -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-blue-600"></i>
                    Script Python - Nettoyage Audio Professionnel
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('nettoyage-code')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="nettoyage-code" class="text-green-400 text-sm overflow-x-auto"><code>import librosa
import numpy as np
import scipy.signal
from scipy.io import wavfile
import noisereduce as nr
from pydub import AudioSegment
import matplotlib.pyplot as plt

class ProfessionalAudioCleaner:
    def __init__(self):
        self.sample_rate = 44100
        self.original_audio = None
        self.cleaned_audio = None
        
    def load_audio(self, file_path):
        """Chargement audio avec pr√©servation qualit√© maximale"""
        print(f"üìÇ Chargement: {file_path}")
        
        # Chargement haute qualit√© avec librosa
        self.original_audio, self.sample_rate = librosa.load(
            file_path, sr=None, mono=False
        )
        
        print(f"‚úÖ Audio charg√©: {self.sample_rate}Hz, {len(self.original_audio)} √©chantillons")
        return self.original_audio
    
    def advanced_noise_reduction(self, audio, noise_sample_start=0, noise_sample_duration=1.0):
        """R√©duction bruit avanc√©e avec profil adaptatif"""
        print("üîß R√©duction bruit avanc√©e...")
        
        # 1. Estimation profil bruit sur √©chantillon silencieux
        noise_start_sample = int(noise_sample_start * self.sample_rate)
        noise_end_sample = int((noise_sample_start + noise_sample_duration) * self.sample_rate)
        
        if noise_end_sample < len(audio):
            noise_profile = audio[noise_start_sample:noise_end_sample]
        else:
            # Utilisation des 10% premiers √©chantillons comme profil bruit
            noise_profile = audio[:int(len(audio) * 0.1)]
        
        # 2. R√©duction bruit spectrale
        reduced_noise = nr.reduce_noise(
            y=audio, 
            sr=self.sample_rate,
            stationary=False,  # Bruit non-stationnaire
            prop_decrease=0.8  # R√©duction agressive mais pr√©servation voix
        )
        
        # 3. Filtrage passe-haut pour voix humaine (80Hz+)
        nyquist = self.sample_rate // 2
        low_cutoff = 80 / nyquist
        b, a = scipy.signal.butter(4, low_cutoff, btype='high')
        filtered_audio = scipy.signal.filtfilt(b, a, reduced_noise)
        
        print("‚úÖ R√©duction bruit termin√©e")
        return filtered_audio
    
    def remove_clicks_and_pops(self, audio, threshold=0.01):
        """Suppression clics et pops avec d√©tection automatique"""
        print("üîß Suppression clics et pops...")
        
        # 1. D√©tection des pics anormaux
        diff = np.abs(np.diff(audio))
        mean_diff = np.mean(diff)
        click_threshold = mean_diff + (threshold * np.max(diff))
        
        click_indices = np.where(diff > click_threshold)[0]
        
        # 2. R√©paration par interpolation
        cleaned_audio = audio.copy()
        for idx in click_indices:
            if idx > 5 and idx < len(audio) - 5:
                # Interpolation lin√©aire sur 11 √©chantillons
                start_val = audio[idx - 5]
                end_val = audio[idx + 5]
                interpolated = np.linspace(start_val, end_val, 11)
                cleaned_audio[idx-5:idx+6] = interpolated
        
        print(f"‚úÖ {len(click_indices)} clics supprim√©s")
        return cleaned_audio
    
    def normalize_dynamic_range(self, audio, target_lufs=-23.0):
        """Normalisation intelligente selon standards diffusion"""
        print("üîß Normalisation dynamique...")
        
        # 1. Calcul RMS pour normalisation √©nerg√©tique
        rms = np.sqrt(np.mean(audio**2))
        
        # 2. Normalisation peak √† -3dB pour headroom
        peak_normalized = audio / np.max(np.abs(audio)) * 0.707  # -3dB
        
        # 3. Compression douce pour consistance
        # Simulation compresseur avec ratio 3:1
        threshold = 0.5
        ratio = 3.0
        
        compressed = np.where(
            np.abs(peak_normalized) > threshold,
            np.sign(peak_normalized) * (
                threshold + (np.abs(peak_normalized) - threshold) / ratio
            ),
            peak_normalized
        )
        
        # 4. Normalisation finale LUFS (simulation)
        final_gain = target_lufs / -23.0  # Approximation
        final_audio = compressed * final_gain
        
        print("‚úÖ Normalisation termin√©e")
        return final_audio
    
    def spectral_repair(self, audio, freq_threshold=8000):
        """R√©paration spectrale pour artefacts hautes fr√©quences"""
        print("üîß R√©paration spectrale...")
        
        # 1. Transformation STFT
        stft = librosa.stft(audio, n_fft=2048, hop_length=512)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        
        # 2. D√©tection et correction artefacts HF
        freq_bins = librosa.fft_frequencies(sr=self.sample_rate, n_fft=2048)
        high_freq_mask = freq_bins > freq_threshold
        
        # 3. R√©duction douce des artefacts HF
        magnitude[high_freq_mask] *= 0.7
        
        # 4. Reconstruction
        repaired_stft = magnitude * np.exp(1j * phase)
        repaired_audio = librosa.istft(repaired_stft, hop_length=512)
        
        print("‚úÖ R√©paration spectrale termin√©e")
        return repaired_audio
    
    def complete_professional_cleaning(self, input_file, output_file):
        """Pipeline complet de nettoyage professionnel"""
        print("üéµ D√âMARRAGE NETTOYAGE PROFESSIONNEL")
        print("=" * 50)
        
        # 1. Chargement
        audio = self.load_audio(input_file)
        
        # 2. S√©quence de nettoyage optimis√©e
        step1 = self.advanced_noise_reduction(audio)
        step2 = self.remove_clicks_and_pops(step1)
        step3 = self.spectral_repair(step2)
        step4 = self.normalize_dynamic_range(step3)
        
        # 3. Sauvegarde haute qualit√©
        self.cleaned_audio = step4
        wavfile.write(output_file, self.sample_rate, 
                     (step4 * 32767).astype(np.int16))
        
        print("=" * 50)
        print(f"‚úÖ NETTOYAGE TERMIN√â: {output_file}")
        
        # 4. Statistiques de nettoyage
        self.print_cleaning_stats()
        
        return step4
    
    def print_cleaning_stats(self):
        """Affichage statistiques de nettoyage"""
        if self.original_audio is not None and self.cleaned_audio is not None:
            original_rms = np.sqrt(np.mean(self.original_audio**2))
            cleaned_rms = np.sqrt(np.mean(self.cleaned_audio**2))
            
            print("\nüìä STATISTIQUES NETTOYAGE:")
            print(f"   RMS Original: {original_rms:.4f}")
            print(f"   RMS Nettoy√©: {cleaned_rms:.4f}")
            print(f"   Am√©lioration SNR: {20*np.log10(cleaned_rms/original_rms):.2f} dB")

# ===============================================
# UTILISATION PRATIQUE
# ===============================================

def nettoyer_audio_clonage_vocal():
    """Pipeline optimis√© pour clonage vocal"""
    
    cleaner = ProfessionalAudioCleaner()
    
    # Fichiers d'entr√©e et sortie
    input_file = "voice_clone_raw.wav"
    output_file = "voice_clone_professional.wav"
    
    # Nettoyage complet
    cleaned_audio = cleaner.complete_professional_cleaning(
        input_file, output_file
    )
    
    print("\nüéØ NETTOYAGE VOCAL TERMIN√â")
    print("üìÅ Fichier pr√™t pour post-traitement avanc√©")
    
    return output_file

# Ex√©cution
if __name__ == "__main__":
    nettoyer_audio_clonage_vocal()</code></pre>
                </div>
            </div>

            <!-- Instructions Step-by-Step -->
            <div class="bg-white rounded-xl shadow-lg p-6">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-list-ol mr-2 text-purple-600"></i>
                    Instructions Step-by-Step - Nettoyage Audio
                </h4>

                <div class="space-y-6">
                    <div class="flex items-start">
                        <div class="step-number">1</div>
                        <div>
                            <h5 class="font-bold mb-2">Installation des D√©pendances</h5>
                            <div class="code-block">
                                <button class="copy-btn" onclick="copyCode('install-deps')">
                                    <i class="fas fa-copy mr-1"></i>Copier
                                </button>
                                <pre id="install-deps" class="text-green-400 text-sm"><code>pip install librosa numpy scipy noisereduce pydub matplotlib soundfile</code></pre>
                            </div>
                            <p class="text-gray-600 text-sm mt-2">Installez toutes les biblioth√®ques audio n√©cessaires pour le traitement professionnel.</p>
                        </div>
                    </div>

                    <div class="flex items-start">
                        <div class="step-number">2</div>
                        <div>
                            <h5 class="font-bold mb-2">Pr√©paration du Fichier Audio</h5>
                            <p class="text-gray-600 mb-2">Placez votre fichier audio brut dans le m√™me dossier que le script :</p>
                            <ul class="list-disc ml-6 text-sm text-gray-600">
                                <li>Format recommand√© : WAV 44.1kHz 16-bit minimum</li>
                                <li>Nom du fichier : <code>voice_clone_raw.wav</code></li>
                                <li>Dur√©e optimale : 30 secondes √† 5 minutes</li>
                            </ul>
                        </div>
                    </div>

                    <div class="flex items-start">
                        <div class="step-number">3</div>
                        <div>
                            <h5 class="font-bold mb-2">Analyse du Signal d'Entr√©e</h5>
                            <p class="text-gray-600 mb-2">Le script analyse automatiquement :</p>
                            <ul class="list-disc ml-6 text-sm text-gray-600">
                                <li>Niveau de bruit de fond (premiers 10% du fichier)</li>
                                <li>D√©tection des clics et artefacts</li>
                                <li>Analyse spectrale pour r√©paration HF</li>
                                <li>Calcul des m√©triques de qualit√©</li>
                            </ul>
                        </div>
                    </div>

                    <div class="flex items-start">
                        <div class="step-number">4</div>
                        <div>
                            <h5 class="font-bold mb-2">Ex√©cution du Nettoyage</h5>
                            <div class="code-block">
                                <button class="copy-btn" onclick="copyCode('run-cleaning')">
                                    <i class="fas fa-copy mr-1"></i>Copier
                                </button>
                                <pre id="run-cleaning" class="text-green-400 text-sm"><code>python audio_cleaner.py</code></pre>
                            </div>
                            <p class="text-gray-600 text-sm mt-2">Le processus prend 30 secondes √† 2 minutes selon la taille du fichier.</p>
                        </div>
                    </div>

                    <div class="flex items-start">
                        <div class="step-number">5</div>
                        <div>
                            <h5 class="font-bold mb-2">V√©rification des R√©sultats</h5>
                            <p class="text-gray-600 mb-2">Fichier de sortie : <code>voice_clone_professional.wav</code></p>
                            <div class="success-box">
                                <p class="text-sm"><strong>Qualit√© attendue :</strong></p>
                                <ul class="list-disc ml-6 text-sm mt-2">
                                    <li>Bruit de fond r√©duit de 80-90%</li>
                                    <li>Clics et pops √©limin√©s</li>
                                    <li>Signal normalis√© √† -23 LUFS</li>
                                    <li>Dynamique pr√©serv√©e</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 2: √âgalisation Multi-Bandes -->
    <section id="equalisation" class="py-16 bg-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-sliders-h mr-3 text-green-600"></i>
                    √âgalisation Multi-Bandes Professionnelle
                </h3>
                <p class="text-gray-600 text-lg">Correction fr√©quentielle pr√©cise et optimisation des formants vocaux</p>
            </div>

            <!-- √âgaliseur Visuel Interactif -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-equalizer mr-2 text-green-600"></i>
                    √âgaliseur 10 Bandes - Voix F√©minine Optimis√©e
                </h4>
                
                <div class="flex justify-center space-x-2 mb-8">
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 60px;"></div>
                        <div class="freq-label">60Hz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 70px;"></div>
                        <div class="freq-label">120Hz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 50px;"></div>
                        <div class="freq-label">250Hz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 45px;"></div>
                        <div class="freq-label">500Hz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 40px;"></div>
                        <div class="freq-label">1kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 35px;"></div>
                        <div class="freq-label">2kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 30px;"></div>
                        <div class="freq-label">4kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 40px;"></div>
                        <div class="freq-label">8kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 55px;"></div>
                        <div class="freq-label">12kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 65px;"></div>
                        <div class="freq-label">16kHz</div>
                    </div>
                </div>

                <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
                    <div class="text-center">
                        <h5 class="font-bold mb-2">Graves (60-250Hz)</h5>
                        <p class="text-sm text-gray-600">R√©duction l√©g√®re pour √©liminer les r√©sonances parasites</p>
                    </div>
                    <div class="text-center">
                        <h5 class="font-bold mb-2">M√©diums (500Hz-4kHz)</h5>
                        <p class="text-sm text-gray-600">Boost pr√©cis des formants vocaux pour clart√©</p>
                    </div>
                    <div class="text-center">
                        <h5 class="font-bold mb-2">Aigus (8-16kHz)</h5>
                        <p class="text-sm text-gray-600">Contr√¥le brillance et respiration</p>
                    </div>
                </div>
            </div>

            <!-- Script Python √âgalisation -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-green-600"></i>
                    Script Python - √âgalisation Multi-Bandes
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('eq-code')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="eq-code" class="text-green-400 text-sm overflow-x-auto"><code>import numpy as np
import librosa
from scipy import signal
from scipy.io import wavfile
import matplotlib.pyplot as plt

class ProfessionalEqualizer:
    def __init__(self, sample_rate=44100):
        self.sample_rate = sample_rate
        
        # Bandes d'√©galisation optimis√©es pour voix f√©minine
        self.eq_bands = {
            'sub_bass': {'freq': 60, 'q': 0.7, 'gain': -2},      # R√©duction r√©sonances
            'bass': {'freq': 120, 'q': 0.8, 'gain': -1},        # Nettoyage graves
            'low_mid1': {'freq': 250, 'q': 1.0, 'gain': 1},     # Pr√©sence voix
            'low_mid2': {'freq': 500, 'q': 1.2, 'gain': 2},     # Premier formant
            'mid': {'freq': 1000, 'q': 1.0, 'gain': 3},         # Clart√© vocale
            'high_mid1': {'freq': 2000, 'q': 1.2, 'gain': 4},   # Deuxi√®me formant
            'high_mid2': {'freq': 4000, 'q': 1.0, 'gain': 2},   # Pr√©sence
            'presence': {'freq': 8000, 'q': 0.8, 'gain': 1},    # Brillance
            'air1': {'freq': 12000, 'q': 0.6, 'gain': -0.5},    # Contr√¥le sibilance
            'air2': {'freq': 16000, 'q': 0.5, 'gain': -1}       # Limitation HF
        }
        
    def create_parametric_filter(self, freq, q, gain, filter_type='peaking'):
        """Cr√©ation filtre param√©trique professionnel"""
        nyquist = self.sample_rate / 2.0
        norm_freq = freq / nyquist
        
        if filter_type == 'peaking':
            # Filtre peaking (bell) pour boost/cut
            b, a = signal.iirpeak(norm_freq, Q=q)
            if gain != 0:
                # Application du gain
                gain_linear = 10**(gain/20)
                if gain > 0:
                    b = b * gain_linear
                else:
                    b = b / abs(gain_linear)
        
        elif filter_type == 'highpass':
            # Filtre passe-haut
            b, a = signal.butter(4, norm_freq, btype='high')
            
        elif filter_type == 'lowpass':
            # Filtre passe-bas
            b, a = signal.butter(4, norm_freq, btype='low')
            
        return b, a
    
    def apply_vocal_eq_preset(self, audio, preset='female_warm'):
        """Application preset d'√©galisation optimis√© voix"""
        print(f"üéõÔ∏è Application preset EQ: {preset}")
        
        if preset == 'female_warm':
            # Preset optimis√© pour voix f√©minine chaleureuse
            eq_settings = {
                'sub_bass': {'freq': 60, 'q': 0.7, 'gain': -3},
                'bass': {'freq': 120, 'q': 0.8, 'gain': -1},
                'low_mid': {'freq': 250, 'q': 1.0, 'gain': 1},
                'mid': {'freq': 800, 'q': 1.2, 'gain': 2},
                'vocal': {'freq': 1500, 'q': 1.0, 'gain': 3},
                'presence': {'freq': 3000, 'q': 1.2, 'gain': 3},
                'clarity': {'freq': 6000, 'q': 1.0, 'gain': 1},
                'air': {'freq': 10000, 'q': 0.6, 'gain': 0.5}
            }
        
        elif preset == 'female_bright':
            # Preset pour voix f√©minine brillante
            eq_settings = {
                'sub_bass': {'freq': 80, 'q': 0.7, 'gain': -2},
                'low_mid': {'freq': 200, 'q': 1.0, 'gain': 0},
                'mid': {'freq': 1000, 'q': 1.2, 'gain': 2},
                'vocal': {'freq': 2000, 'q': 1.0, 'gain': 4},
                'presence': {'freq': 4000, 'q': 1.2, 'gain': 3},
                'clarity': {'freq': 8000, 'q': 1.0, 'gain': 2},
                'air': {'freq': 12000, 'q': 0.6, 'gain': 1}
            }
        
        else:
            eq_settings = self.eq_bands
        
        processed_audio = audio.copy()
        
        # Application s√©quentielle de chaque bande
        for band_name, params in eq_settings.items():
            if params['gain'] != 0:  # Seulement si gain non nul
                b, a = self.create_parametric_filter(
                    params['freq'], params['q'], params['gain']
                )
                processed_audio = signal.filtfilt(b, a, processed_audio)
                print(f"   ‚úÖ {band_name}: {params['freq']}Hz, {params['gain']:+.1f}dB")
        
        return processed_audio
    
    def formant_correction(self, audio, shift_factor=1.0):
        """Correction des formants vocaux"""
        print("üîß Correction formants...")
        
        # 1. Analyse spectrale
        stft = librosa.stft(audio, n_fft=2048, hop_length=512)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        
        # 2. D√©tection formants
        freq_bins = librosa.fft_frequencies(sr=self.sample_rate, n_fft=2048)
        
        # Zones formants pour voix f√©minine
        formant_zones = [
            (700, 1000),   # F1 - Ouverture bouche
            (1800, 2200),  # F2 - Position langue
            (2600, 3200)   # F3 - R√©sonance cavit√©
        ]
        
        # 3. Boost cibl√© des formants
        for f_low, f_high in formant_zones:
            formant_mask = (freq_bins >= f_low) & (freq_bins <= f_high)
            magnitude[formant_mask] *= (1.0 + 0.2 * shift_factor)
        
        # 4. Reconstruction
        corrected_stft = magnitude * np.exp(1j * phase)
        corrected_audio = librosa.istft(corrected_stft, hop_length=512)
        
        print("‚úÖ Correction formants termin√©e")
        return corrected_audio
    
    def de_essing(self, audio, freq_center=6000, threshold=-20):
        """Suppression sibilances (de-essing)"""
        print("üîß De-essing...")
        
        # 1. Filtrage zone sibilances (4-8kHz)
        nyquist = self.sample_rate / 2
        low_cut = 4000 / nyquist
        high_cut = 8000 / nyquist
        
        # Filtre passe-bande pour d√©tecter sibilances
        b_detect, a_detect = signal.butter(4, [low_cut, high_cut], btype='band')
        sibilance_signal = signal.filtfilt(b_detect, a_detect, audio)
        
        # 2. D√©tection seuil
        sibilance_level = np.abs(sibilance_signal)
        threshold_linear = 10**(threshold/20)
        
        # 3. Compression dynamique des sibilances
        compression_ratio = 3.0
        attack_time = 0.001  # 1ms
        release_time = 0.1   # 100ms
        
        attack_samples = int(attack_time * self.sample_rate)
        release_samples = int(release_time * self.sample_rate)
        
        # Envelope follower simplifi√©
        envelope = np.zeros_like(sibilance_level)
        for i in range(1, len(sibilance_level)):
            if sibilance_level[i] > envelope[i-1]:
                # Attack
                envelope[i] = envelope[i-1] + (sibilance_level[i] - envelope[i-1]) / attack_samples
            else:
                # Release
                envelope[i] = envelope[i-1] * (1 - 1/release_samples)
        
        # 4. Calcul gain reduction
        gain_reduction = np.ones_like(audio)
        over_threshold = envelope > threshold_linear
        gain_reduction[over_threshold] = threshold_linear / envelope[over_threshold]
        gain_reduction[over_threshold] = gain_reduction[over_threshold] ** (1/compression_ratio)
        
        # 5. Application gain reduction dans zone sibilances seulement
        b_sib, a_sib = signal.butter(4, [low_cut, high_cut], btype='band')
        sibilance_reduced = signal.filtfilt(b_sib, a_sib, audio * gain_reduction)
        
        # Reconstruction avec signal original
        result = audio - signal.filtfilt(b_sib, a_sib, audio) + sibilance_reduced
        
        print("‚úÖ De-essing termin√©")
        return result
    
    def complete_eq_processing(self, input_file, output_file, preset='female_warm'):
        """Pipeline complet d'√©galisation"""
        print("üéõÔ∏è D√âMARRAGE √âGALISATION PROFESSIONNELLE")
        print("=" * 50)
        
        # 1. Chargement
        audio, sr = librosa.load(input_file, sr=self.sample_rate)
        print(f"üìÇ Audio charg√©: {len(audio)} √©chantillons")
        
        # 2. Pipeline d'√©galisation
        step1 = self.apply_vocal_eq_preset(audio, preset)
        step2 = self.formant_correction(step1, shift_factor=1.1)
        step3 = self.de_essing(step2, threshold=-18)
        
        # 3. Normalisation finale
        final_audio = step3 / np.max(np.abs(step3)) * 0.95
        
        # 4. Sauvegarde
        wavfile.write(output_file, self.sample_rate,
                     (final_audio * 32767).astype(np.int16))
        
        print("=" * 50)
        print(f"‚úÖ √âGALISATION TERMIN√âE: {output_file}")
        
        return final_audio

# ===============================================
# UTILISATION PRATIQUE
# ===============================================

def equaliser_voix_clonee():
    """Pipeline optimis√© pour voix clon√©e"""
    
    eq = ProfessionalEqualizer(sample_rate=44100)
    
    # Fichiers
    input_file = "voice_clone_professional.wav"  # Sortie du nettoyage
    output_file = "voice_clone_equalized.wav"
    
    # √âgalisation avec preset f√©minin chaleureux
    equalized_audio = eq.complete_eq_processing(
        input_file, output_file, preset='female_warm'
    )
    
    print("\nüéØ √âGALISATION VOCALE TERMIN√âE")
    print("üìÅ Fichier pr√™t pour ajout d'effets")
    
    return output_file

# Ex√©cution
if __name__ == "__main__":
    equaliser_voix_clonee()</code></pre>
                </div>
            </div>

            <!-- Presets d'√âgalisation -->
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-blue-600">
                        <i class="fas fa-heart mr-2"></i>Preset "Female Warm"
                    </h4>
                    <ul class="space-y-2 text-sm">
                        <li><span class="font-medium">60Hz:</span> -3dB (r√©duction r√©sonances)</li>
                        <li><span class="font-medium">250Hz:</span> +1dB (pr√©sence)</li>
                        <li><span class="font-medium">800Hz:</span> +2dB (chaleur)</li>
                        <li><span class="font-medium">1.5kHz:</span> +3dB (clart√© vocale)</li>
                        <li><span class="font-medium">3kHz:</span> +3dB (pr√©sence)</li>
                        <li><span class="font-medium">6kHz:</span> +1dB (d√©finition)</li>
                        <li><span class="font-medium">10kHz:</span> +0.5dB (air)</li>
                    </ul>
                    <p class="text-xs text-gray-500 mt-3">Id√©al pour contenu intime et conversationnel</p>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-purple-600">
                        <i class="fas fa-star mr-2"></i>Preset "Female Bright"
                    </h4>
                    <ul class="space-y-2 text-sm">
                        <li><span class="font-medium">80Hz:</span> -2dB (nettoyage)</li>
                        <li><span class="font-medium">1kHz:</span> +2dB (clart√©)</li>
                        <li><span class="font-medium">2kHz:</span> +4dB (formant principal)</li>
                        <li><span class="font-medium">4kHz:</span> +3dB (pr√©sence)</li>
                        <li><span class="font-medium">8kHz:</span> +2dB (brillance)</li>
                        <li><span class="font-medium">12kHz:</span> +1dB (air)</li>
                    </ul>
                    <p class="text-xs text-gray-500 mt-3">Parfait pour contenu √©nergique et performances</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 3: Effets R√©alistes -->
    <section id="effets" class="py-16 bg-gray-50">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-magic mr-3 text-purple-600"></i>
                    Effets Vocaux R√©alistes
                </h3>
                <p class="text-gray-600 text-lg">Ajout de respirations naturelles, h√©sitations et micro-d√©tails humains</p>
            </div>

            <!-- D√©monstration Effets -->
            <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-12">
                <div class="bg-white rounded-xl shadow-lg p-6 card-hover">
                    <div class="text-center mb-4">
                        <div class="bg-gradient-to-br from-blue-500 to-purple-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                            <i class="fas fa-wind text-white text-xl"></i>
                        </div>
                        <h4 class="font-bold text-lg">Respirations Naturelles</h4>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-2">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Inspirations subtiles</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Expirations contr√¥l√©es</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Pauses naturelles</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Rythme respiratoire</li>
                    </ul>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6 card-hover">
                    <div class="text-center mb-4">
                        <div class="bg-gradient-to-br from-green-500 to-blue-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                            <i class="fas fa-pause text-white text-xl"></i>
                        </div>
                        <h4 class="font-bold text-lg">H√©sitations Subtiles</h4>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-2">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Micro-pauses</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Hum et euh discrets</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Variations tempo</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Naturel spontan√©</li>
                    </ul>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6 card-hover">
                    <div class="text-center mb-4">
                        <div class="bg-gradient-to-br from-purple-500 to-pink-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                            <i class="fas fa-heartbeat text-white text-xl"></i>
                        </div>
                        <h4 class="font-bold text-lg">Micro-D√©tails</h4>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-2">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Bruits de bouche</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Clics de langue</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Variations pitch</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Texture vocale</li>
                    </ul>
                </div>
            </div>

            <!-- Script Python Effets R√©alistes -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-purple-600"></i>
                    Script Python - Effets Vocaux R√©alistes
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('effects-code')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="effects-code" class="text-green-400 text-sm overflow-x-auto"><code>import numpy as np
import librosa
from scipy import signal
from scipy.io import wavfile
import random

class VocalRealismEnhancer:
    def __init__(self, sample_rate=44100):
        self.sample_rate = sample_rate
        self.breath_samples = self.load_breath_samples()
        
    def load_breath_samples(self):
        """G√©n√©ration √©chantillons de respiration synth√©tiques"""
        breath_samples = {}
        
        # G√©n√©ration respiration inspiration (500ms)
        duration = 0.5
        t = np.linspace(0, duration, int(self.sample_rate * duration))
        
        # Profil fr√©quentiel respiration (bruit filtr√©)
        noise = np.random.normal(0, 0.1, len(t))
        
        # Filtrage passe-bas pour son de respiration naturel
        nyquist = self.sample_rate / 2
        cutoff = 800 / nyquist
        b, a = signal.butter(4, cutoff, btype='low')
        filtered_breath = signal.filtfilt(b, a, noise)
        
        # Envelope d'attaque/d√©clin naturelle
        attack_time = 0.1
        decay_time = 0.4
        attack_samples = int(attack_time * self.sample_rate)
        decay_samples = int(decay_time * self.sample_rate)
        
        envelope = np.ones_like(filtered_breath)
        # Attack
        envelope[:attack_samples] = np.linspace(0, 1, attack_samples)
        # Decay
        envelope[-decay_samples:] = np.linspace(1, 0, decay_samples)
        
        breath_in = filtered_breath * envelope * 0.15
        
        # G√©n√©ration expiration (plus longue, 700ms)
        duration_out = 0.7
        t_out = np.linspace(0, duration_out, int(self.sample_rate * duration_out))
        noise_out = np.random.normal(0, 0.08, len(t_out))
        
        # Fr√©quences plus graves pour expiration
        cutoff_out = 400 / nyquist
        b_out, a_out = signal.butter(4, cutoff_out, btype='low')
        filtered_breath_out = signal.filtfilt(b_out, a_out, noise_out)
        
        # Envelope expiration plus douce
        envelope_out = np.ones_like(filtered_breath_out)
        attack_samples_out = int(0.05 * self.sample_rate)
        decay_samples_out = int(0.5 * self.sample_rate)
        
        envelope_out[:attack_samples_out] = np.linspace(0, 1, attack_samples_out)
        envelope_out[-decay_samples_out:] = np.linspace(1, 0, decay_samples_out)
        
        breath_out = filtered_breath_out * envelope_out * 0.12
        
        breath_samples['inspiration'] = breath_in
        breath_samples['expiration'] = breath_out
        
        return breath_samples
    
    def detect_speech_segments(self, audio, min_speech_duration=0.5):
        """D√©tection segments de parole pour insertion respirations"""
        # Calcul √©nergie par fen√™tres
        window_size = int(0.1 * self.sample_rate)  # 100ms
        hop_size = int(0.05 * self.sample_rate)    # 50ms
        
        energy = []
        for i in range(0, len(audio) - window_size, hop_size):
            window = audio[i:i + window_size]
            energy.append(np.sum(window ** 2))
        
        energy = np.array(energy)
        
        # Seuil adaptatif pour d√©tection parole
        threshold = np.mean(energy) * 0.3
        speech_mask = energy > threshold
        
        # Conversion en indices temporels
        speech_segments = []
        in_speech = False
        start_idx = 0
        
        for i, is_speech in enumerate(speech_mask):
            time_idx = i * hop_size
            
            if is_speech and not in_speech:
                start_idx = time_idx
                in_speech = True
            elif not is_speech and in_speech:
                duration = (time_idx - start_idx) / self.sample_rate
                if duration >= min_speech_duration:
                    speech_segments.append((start_idx, time_idx))
                in_speech = False
        
        return speech_segments
    
    def add_natural_breathing(self, audio, breath_frequency=0.3):
        """Ajout respirations naturelles entre segments"""
        print("üå¨Ô∏è Ajout respirations naturelles...")
        
        speech_segments = self.detect_speech_segments(audio)
        result_audio = audio.copy()
        
        # Insertion respirations entre segments
        offset = 0
        for i in range(len(speech_segments) - 1):
            current_end = speech_segments[i][1] + offset
            next_start = speech_segments[i + 1][0] + offset
            
            gap_duration = (next_start - current_end) / self.sample_rate
            
            # Insertion respiration si gap suffisant (>1s)
            if gap_duration > 1.0 and random.random() < breath_frequency:
                breath_type = random.choice(['inspiration', 'expiration'])
                breath_sample = self.breath_samples[breath_type]
                
                # Position d'insertion (milieu du gap)
                insert_pos = current_end + int(gap_duration * 0.3 * self.sample_rate)
                
                # Insertion avec fondu
                breath_with_fade = self.apply_fade_in_out(breath_sample, 0.1, 0.2)
                
                # Extension du tableau pour ins√©rer la respiration
                result_audio = np.concatenate([
                    result_audio[:insert_pos],
                    breath_with_fade,
                    result_audio[insert_pos:]
                ])
                
                offset += len(breath_with_fade)
                print(f"   ‚úÖ {breath_type} ajout√©e √† {insert_pos/self.sample_rate:.1f}s")
        
        return result_audio
    
    def add_subtle_hesitations(self, audio, hesitation_probability=0.15):
        """Ajout h√©sitations subtiles (euh, hum)"""
        print("ü§î Ajout h√©sitations subtiles...")
        
        speech_segments = self.detect_speech_segments(audio, min_speech_duration=1.0)
        result_audio = audio.copy()
        
        offset = 0
        for segment_start, segment_end in speech_segments:
            segment_start += offset
            segment_end += offset
            
            if random.random() < hesitation_probability:
                # G√©n√©ration h√©sitation synth√©tique
                hesitation = self.generate_hesitation_sound()
                
                # Position al√©atoire dans le segment
                insert_pos = segment_start + int(0.2 * (segment_end - segment_start))
                
                # Insertion
                result_audio = np.concatenate([
                    result_audio[:insert_pos],
                    hesitation,
                    result_audio[insert_pos:]
                ])
                
                offset += len(hesitation)
                print(f"   ‚úÖ H√©sitation ajout√©e √† {insert_pos/self.sample_rate:.1f}s")
        
        return result_audio
    
    def generate_hesitation_sound(self):
        """G√©n√©ration son d'h√©sitation naturel"""
        # Types d'h√©sitations
        hesitation_types = ['euh', 'hmm', 'pause']
        hes_type = random.choice(hesitation_types)
        
        if hes_type == 'euh':
            # Son "euh" : ton moyennement grave, court
            duration = random.uniform(0.2, 0.4)
            t = np.linspace(0, duration, int(self.sample_rate * duration))
            
            # Fr√©quence fondamentale autour de 150Hz (voix f√©minine basse)
            freq = random.uniform(140, 180)
            hesitation = 0.1 * np.sin(2 * np.pi * freq * t)
            
            # Ajout harmoniques pour r√©alisme
            hesitation += 0.05 * np.sin(2 * np.pi * freq * 2 * t)
            hesitation += 0.02 * np.sin(2 * np.pi * freq * 3 * t)
            
        elif hes_type == 'hmm':
            # Son "hmm" : bouche ferm√©e, nasal
            duration = random.uniform(0.3, 0.6)
            t = np.linspace(0, duration, int(self.sample_rate * duration))
            
            freq = random.uniform(120, 160)
            hesitation = 0.08 * np.sin(2 * np.pi * freq * t)
            
            # Filtrage nasal (boost autour de 1kHz)
            nyquist = self.sample_rate / 2
            nasal_freq = 1000 / nyquist
            b, a = signal.butter(2, [nasal_freq * 0.8, nasal_freq * 1.2], btype='band')
            hesitation = signal.filtfilt(b, a, hesitation)
            
        else:  # pause
            # Micro-pause avec bruit de bouche tr√®s discret
            duration = random.uniform(0.1, 0.2)
            hesitation = np.random.normal(0, 0.005, int(self.sample_rate * duration))
        
        # Application envelope naturelle
        return self.apply_fade_in_out(hesitation, 0.05, 0.1)
    
    def add_mouth_sounds(self, audio, probability=0.1):
        """Ajout micro-bruits de bouche naturels"""
        print("üëÑ Ajout micro-bruits de bouche...")
        
        # D√©tection consonnes plosives (p, b, t, d, k, g)
        # Approximation par d√©tection transitions rapides d'√©nergie
        
        energy = librosa.feature.rms(y=audio, frame_length=2048, hop_length=512)[0]
        energy_diff = np.abs(np.diff(energy))
        
        # Seuil pour d√©tection transitions
        threshold = np.percentile(energy_diff, 85)
        sharp_transitions = np.where(energy_diff > threshold)[0]
        
        result_audio = audio.copy()
        offset = 0
        
        for transition_idx in sharp_transitions:
            if random.random() < probability:
                # Position temporelle
                time_pos = int(transition_idx * 512) + offset
                
                # G√©n√©ration bruit de bouche subtil
                mouth_sound = self.generate_mouth_click()
                
                # Insertion juste avant la transition
                insert_pos = max(0, time_pos - len(mouth_sound))
                
                result_audio = np.concatenate([
                    result_audio[:insert_pos],
                    mouth_sound,
                    result_audio[insert_pos:]
                ])
                
                offset += len(mouth_sound)
        
        print(f"   ‚úÖ {len([t for t in sharp_transitions if random.random() < probability])} bruits de bouche ajout√©s")
        return result_audio
    
    def generate_mouth_click(self):
        """G√©n√©ration clic de langue/bouche subtil"""
        duration = random.uniform(0.01, 0.03)  # Tr√®s court
        samples = int(duration * self.sample_rate)
        
        # Impulsion suivie de d√©croissance rapide
        click = np.zeros(samples)
        attack_samples = samples // 4
        
        # Attaque rapide
        click[:attack_samples] = np.random.normal(0, 0.02, attack_samples)
        
        # D√©croissance exponentielle
        decay = np.exp(-np.linspace(0, 8, samples - attack_samples))
        click[attack_samples:] = np.random.normal(0, 0.01, samples - attack_samples) * decay
        
        # Filtrage haute fr√©quence pour son de clic
        nyquist = self.sample_rate / 2
        high_freq = 3000 / nyquist
        b, a = signal.butter(2, high_freq, btype='high')
        click = signal.filtfilt(b, a, click)
        
        return click * 0.3  # Volume tr√®s discret
    
    def apply_fade_in_out(self, audio, fade_in_duration, fade_out_duration):
        """Application fondus d'entr√©e et sortie"""
        fade_in_samples = int(fade_in_duration * self.sample_rate)
        fade_out_samples = int(fade_out_duration * self.sample_rate)
        
        result = audio.copy()
        
        # Fade in
        if fade_in_samples < len(result):
            fade_in_curve = np.linspace(0, 1, fade_in_samples)
            result[:fade_in_samples] *= fade_in_curve
        
        # Fade out
        if fade_out_samples < len(result):
            fade_out_curve = np.linspace(1, 0, fade_out_samples)
            result[-fade_out_samples:] *= fade_out_curve
        
        return result
    
    def enhance_vocal_realism(self, input_file, output_file):
        """Pipeline complet d'am√©lioration r√©alisme vocal"""
        print("üé≠ D√âMARRAGE AM√âLIORATION R√âALISME VOCAL")
        print("=" * 50)
        
        # 1. Chargement
        audio, sr = librosa.load(input_file, sr=self.sample_rate)
        print(f"üìÇ Audio charg√©: {len(audio)/sr:.1f}s")
        
        # 2. Pipeline d'effets r√©alistes
        step1 = self.add_natural_breathing(audio, breath_frequency=0.4)
        step2 = self.add_subtle_hesitations(step1, hesitation_probability=0.2)
        step3 = self.add_mouth_sounds(step2, probability=0.15)
        
        # 3. Normalisation finale
        final_audio = step3 / np.max(np.abs(step3)) * 0.95
        
        # 4. Sauvegarde
        wavfile.write(output_file, self.sample_rate,
                     (final_audio * 32767).astype(np.int16))
        
        print("=" * 50)
        print(f"‚úÖ R√âALISME VOCAL TERMIN√â: {output_file}")
        print(f"üìà Dur√©e finale: {len(final_audio)/sr:.1f}s")
        
        return final_audio

# ===============================================
# UTILISATION PRATIQUE
# ===============================================

def ajouter_realisme_vocal():
    """Pipeline d'ajout de r√©alisme vocal"""
    
    enhancer = VocalRealismEnhancer(sample_rate=44100)
    
    # Fichiers
    input_file = "voice_clone_equalized.wav"  # Sortie √©galisation
    output_file = "voice_clone_realistic.wav"
    
    # Am√©lioration r√©alisme
    realistic_audio = enhancer.enhance_vocal_realism(
        input_file, output_file
    )
    
    print("\nüéØ R√âALISME VOCAL TERMIN√â")
    print("üìÅ Fichier pr√™t pour mixage final")
    
    return output_file

# Ex√©cution
if __name__ == "__main__":
    ajouter_realisme_vocal()</code></pre>
                </div>
            </div>

            <!-- Param√®tres de R√©alisme -->
            <div class="bg-white rounded-xl shadow-lg p-6">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-sliders-h mr-2 text-purple-600"></i>
                    Param√®tres de R√©alisme Optimaux
                </h4>

                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <div>
                        <h5 class="font-bold mb-3">Respirations Naturelles</h5>
                        <ul class="space-y-2 text-sm">
                            <li><span class="font-medium">Fr√©quence:</span> 0.3-0.4 (30-40% des pauses)</li>
                            <li><span class="font-medium">Dur√©e inspiration:</span> 0.5s</li>
                            <li><span class="font-medium">Dur√©e expiration:</span> 0.7s</li>
                            <li><span class="font-medium">Volume:</span> 12-15% du signal principal</li>
                            <li><span class="font-medium">Filtrage:</span> Passe-bas 800Hz (inspiration), 400Hz (expiration)</li>
                        </ul>
                    </div>

                    <div>
                        <h5 class="font-bold mb-3">H√©sitations & Micro-d√©tails</h5>
                        <ul class="space-y-2 text-sm">
                            <li><span class="font-medium">Probabilit√© h√©sitations:</span> 15-20%</li>
                            <li><span class="font-medium">Types:</span> "euh" (140-180Hz), "hmm" (120-160Hz)</li>
                            <li><span class="font-medium">Bruits bouche:</span> 10% des transitions</li>
                            <li><span class="font-medium">Dur√©e clics:</span> 10-30ms</li>
                            <li><span class="font-medium">Filtrage clics:</span> Passe-haut 3kHz</li>
                        </ul>
                    </div>
                </div>

                <div class="info-box mt-6">
                    <p class="text-sm">
                        <strong>üí° Conseil Pro :</strong> Les effets de r√©alisme doivent rester subtils. Un exc√®s d'effets 
                        peut rendre l'audio artificiel. Ajustez les probabilit√©s selon le style de contenu 
                        (plus d'h√©sitations pour du contenu conversationnel, moins pour du contenu pr√©par√©).
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 4: Mixage Avanc√© -->
    <section id="mixage" class="py-16 bg-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-volume-up mr-3 text-red-600"></i>
                    Mixage Audio Professionnel
                </h3>
                <p class="text-gray-600 text-lg">Finalisation studio avec compression, limiteur et spatialisation</p>
            </div>

            <!-- Console Mixage Virtuelle -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-mixing-desk mr-2 text-red-600"></i>
                    Console de Mixage Virtuelle
                </h4>

                <div class="grid grid-cols-1 md:grid-cols-4 gap-6">
                    <div class="text-center">
                        <h5 class="font-bold mb-3">Compression</h5>
                        <div class="bg-gradient-to-b from-red-500 to-red-700 h-32 w-16 mx-auto rounded mb-2 relative">
                            <div class="absolute bottom-8 left-1/2 transform -translate-x-1/2 w-6 h-6 bg-white rounded-full border-2 border-red-500"></div>
                        </div>
                        <p class="text-xs text-gray-600">Ratio 3:1<br>Attaque: 5ms<br>Release: 100ms</p>
                    </div>

                    <div class="text-center">
                        <h5 class="font-bold mb-3">Limiteur</h5>
                        <div class="bg-gradient-to-b from-orange-500 to-orange-700 h-32 w-16 mx-auto rounded mb-2 relative">
                            <div class="absolute bottom-4 left-1/2 transform -translate-x-1/2 w-6 h-6 bg-white rounded-full border-2 border-orange-500"></div>
                        </div>
                        <p class="text-xs text-gray-600">Seuil: -1dB<br>Release: 50ms<br>Lookahead: 5ms</p>
                    </div>

                    <div class="text-center">
                        <h5 class="font-bold mb-3">Reverb</h5>
                        <div class="bg-gradient-to-b from-blue-500 to-blue-700 h-32 w-16 mx-auto rounded mb-2 relative">
                            <div class="absolute bottom-16 left-1/2 transform -translate-x-1/2 w-6 h-6 bg-white rounded-full border-2 border-blue-500"></div>
                        </div>
                        <p class="text-xs text-gray-600">Room: Studio<br>Decay: 1.2s<br>Mix: 15%</p>
                    </div>

                    <div class="text-center">
                        <h5 class="font-bold mb-3">St√©r√©o</h5>
                        <div class="bg-gradient-to-b from-purple-500 to-purple-700 h-32 w-16 mx-auto rounded mb-2 relative">
                            <div class="absolute bottom-20 left-1/2 transform -translate-x-1/2 w-6 h-6 bg-white rounded-full border-2 border-purple-500"></div>
                        </div>
                        <p class="text-xs text-gray-600">Width: 85%<br>Center: 0%<br>Focus: Vocal</p>
                    </div>
                </div>
            </div>

            <!-- Script Python Mixage -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-red-600"></i>
                    Script Python - Mixage Studio Final
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('mixage-code')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="mixage-code" class="text-green-400 text-sm overflow-x-auto"><code>import numpy as np
import librosa
from scipy import signal
from scipy.io import wavfile
import matplotlib.pyplot as plt

class StudioMixingEngine:
    def __init__(self, sample_rate=44100):
        self.sample_rate = sample_rate
        
    def apply_vocal_compression(self, audio, threshold=-12, ratio=3.0, 
                              attack_ms=5, release_ms=100):
        """Compression vocale professionnelle"""
        print(f"üîß Compression: {ratio}:1, seuil {threshold}dB")
        
        # Conversion param√®tres temporels
        attack_samples = int(attack_ms * 0.001 * self.sample_rate)
        release_samples = int(release_ms * 0.001 * self.sample_rate)
        
        # Conversion seuil en lin√©aire
        threshold_linear = 10**(threshold/20)
        
        # Calcul envelope du signal
        envelope = np.abs(audio)
        
        # Lissage de l'envelope (ballistics du compresseur)
        smoothed_envelope = np.zeros_like(envelope)
        gain_reduction = np.ones_like(audio)
        
        for i in range(1, len(envelope)):
            # D√©tection d√©passement seuil
            if envelope[i] > threshold_linear:
                # Calcul gain reduction n√©cessaire
                over_threshold = envelope[i] / threshold_linear
                target_gain = 1 / (1 + (over_threshold - 1) * (ratio - 1) / ratio)
                
                # Attack/Release ballistics
                if target_gain < gain_reduction[i-1]:
                    # Attack (r√©duction gain)
                    alpha = 1 - np.exp(-1 / attack_samples)
                else:
                    # Release (retour gain)
                    alpha = 1 - np.exp(-1 / release_samples)
                
                gain_reduction[i] = (
                    gain_reduction[i-1] * (1 - alpha) + target_gain * alpha
                )
            else:
                # Release progressif vers gain unitaire
                alpha = 1 - np.exp(-1 / release_samples)
                gain_reduction[i] = gain_reduction[i-1] * (1 - alpha) + 1 * alpha
        
        # Application compression
        compressed = audio * gain_reduction
        
        # Makeup gain automatique
        makeup_gain = 1 / np.mean(gain_reduction)
        compressed *= makeup_gain
        
        print(f"   ‚úÖ R√©duction moyenne: {-20*np.log10(np.mean(gain_reduction)):.1f}dB")
        return compressed
    
    def apply_peak_limiter(self, audio, ceiling_db=-1, release_ms=50, 
                          lookahead_ms=5):
        """Limiteur de pics transparent"""
        print(f"üîß Limiteur: plafond {ceiling_db}dB")
        
        ceiling_linear = 10**(ceiling_db/20)
        lookahead_samples = int(lookahead_ms * 0.001 * self.sample_rate)
        release_samples = int(release_ms * 0.001 * self.sample_rate)
        
        # D√©lai pour lookahead
        delayed_audio = np.concatenate([
            np.zeros(lookahead_samples), audio
        ])
        
        # D√©tection des pics avec lookahead
        envelope = np.abs(audio)
        gain_reduction = np.ones(len(delayed_audio))
        
        for i in range(len(audio)):
            if envelope[i] > ceiling_linear:
                # Calcul gain reduction n√©cessaire
                target_gain = ceiling_linear / envelope[i]
                
                # Application release graduel
                for j in range(lookahead_samples + i, 
                             min(len(gain_reduction), 
                                 lookahead_samples + i + release_samples)):
                    release_factor = (j - lookahead_samples - i) / release_samples
                    gain_reduction[j] = min(
                        gain_reduction[j],
                        target_gain + (1 - target_gain) * release_factor
                    )
        
        # Application limitation
        limited = delayed_audio * gain_reduction
        
        print(f"   ‚úÖ Pics limit√©s √† {ceiling_db}dB")
        return limited[:len(audio)]  # Suppression du d√©lai
    
    def apply_studio_reverb(self, audio, room_size=0.6, decay_time=1.2, 
                           mix_level=0.15, pre_delay_ms=20):
        """R√©verb√©ration studio subtile"""
        print(f"üîß R√©verb studio: decay {decay_time}s, mix {mix_level*100:.0f}%")
        
        # G√©n√©ration r√©ponse impulsionnelle salle studio
        pre_delay_samples = int(pre_delay_ms * 0.001 * self.sample_rate)
        ir_length = int(decay_time * self.sample_rate)
        
        # R√©ponse impulsionnelle synth√©tique
        t = np.linspace(0, decay_time, ir_length)
        
        # D√©croissance exponentielle + diffusion
        decay_envelope = np.exp(-3 * t / decay_time)
        
        # Ajout de r√©flexions multiples
        reflections = np.zeros(ir_length)
        reflection_times = [0.01, 0.023, 0.041, 0.067, 0.089, 0.134]
        reflection_gains = [0.8, 0.6, 0.5, 0.4, 0.3, 0.2]
        
        for time_offset, gain in zip(reflection_times, reflection_gains):
            offset_samples = int(time_offset * self.sample_rate)
            if offset_samples < ir_length:
                reflections[offset_samples] += gain
        
        # Convolution avec bruit pour diffusion
        diffusion_noise = np.random.normal(0, 1, ir_length // 4)
        diffusion = np.convolve(reflections, diffusion_noise, mode='same')
        
        # R√©ponse impulsionnelle finale
        impulse_response = (reflections + 0.3 * diffusion) * decay_envelope
        
        # Ajout pr√©-d√©lai
        if pre_delay_samples > 0:
            impulse_response = np.concatenate([
                np.zeros(pre_delay_samples),
                impulse_response
            ])
        
        # Normalisation
        impulse_response /= np.max(np.abs(impulse_response))
        
        # Convolution avec signal
        reverb_signal = np.convolve(audio, impulse_response, mode='same')
        
        # Mixage wet/dry
        final = (1 - mix_level) * audio + mix_level * reverb_signal
        
        print(f"   ‚úÖ R√©verb appliqu√©e")
        return final
    
    def stereo_widening(self, audio, width=0.85, bass_mono_freq=120):
        """√âlargissement st√©r√©o avec pr√©servation graves mono"""
        print(f"üîß √âlargissement st√©r√©o: {width*100:.0f}%")
        
        # Conversion mono vers st√©r√©o si n√©cessaire
        if len(audio.shape) == 1:
            # Cr√©ation st√©r√©o artificiel
            left = audio.copy()
            right = audio.copy()
            
            # Ajout l√©g√®res diff√©rences pour √©largissement
            delay_samples = int(0.001 * self.sample_rate)  # 1ms delay
            right = np.concatenate([np.zeros(delay_samples), right])[:-delay_samples]
            
            # Modulation de phase l√©g√®re sur canal droit
            modulation = 0.95 + 0.05 * np.sin(2 * np.pi * 0.5 * np.arange(len(right)) / self.sample_rate)
            right *= modulation
            
            stereo_audio = np.column_stack([left, right])
        else:
            stereo_audio = audio.copy()
        
        # Extraction Mid/Side
        mid = (stereo_audio[:, 0] + stereo_audio[:, 1]) / 2
        side = (stereo_audio[:, 0] - stereo_audio[:, 1]) / 2
        
        # Filtrage graves en mono
        nyquist = self.sample_rate / 2
        bass_cutoff = bass_mono_freq / nyquist
        b, a = signal.butter(2, bass_cutoff, btype='low')
        
        bass_mono = signal.filtfilt(b, a, mid)
        high_stereo = mid - bass_mono
        
        # Application √©largissement sur side et hautes fr√©quences
        widened_side = side * width
        
        # Reconstruction st√©r√©o
        left_final = bass_mono + high_stereo + widened_side
        right_final = bass_mono + high_stereo - widened_side
        
        result = np.column_stack([left_final, right_final])
        
        print(f"   ‚úÖ St√©r√©o √©largi, graves <{bass_mono_freq}Hz en mono")
        return result
    
    def final_mastering_chain(self, audio):
        """Cha√Æne de mastering finale"""
        print("üéõÔ∏è Cha√Æne mastering finale...")
        
        # 1. EQ de mastering subtil
        # Boost tr√®s l√©ger pr√©sence 2-4kHz
        nyquist = self.sample_rate / 2
        freq_center = 3000 / nyquist
        b, a = signal.iirpeak(freq_center, Q=2)
        eq_audio = signal.filtfilt(b, a, audio) * 1.05  # +0.4dB
        
        # 2. Compression multibande simplifi√©e
        # S√©paration graves/aigus √† 1kHz
        split_freq = 1000 / nyquist
        b_low, a_low = signal.butter(4, split_freq, btype='low')
        b_high, a_high = signal.butter(4, split_freq, btype='high')
        
        low_band = signal.filtfilt(b_low, a_low, eq_audio)
        high_band = signal.filtfilt(b_high, a_high, eq_audio)
        
        # Compression l√©g√®re sur chaque bande
        low_compressed = self.apply_vocal_compression(
            low_band, threshold=-15, ratio=2.5, attack_ms=10, release_ms=150
        )
        high_compressed = self.apply_vocal_compression(
            high_band, threshold=-10, ratio=3.0, attack_ms=3, release_ms=80
        )
        
        # Reconstruction
        mastered = low_compressed + high_compressed
        
        # 3. Limitation finale
        final = self.apply_peak_limiter(
            mastered, ceiling_db=-0.3, release_ms=30, lookahead_ms=3
        )
        
        print("   ‚úÖ Mastering termin√©")
        return final
    
    def complete_studio_mix(self, input_file, output_file, stereo_output=True):
        """Pipeline complet de mixage studio"""
        print("üéöÔ∏è D√âMARRAGE MIXAGE STUDIO PROFESSIONNEL")
        print("=" * 55)
        
        # 1. Chargement
        audio, sr = librosa.load(input_file, sr=self.sample_rate, mono=True)
        print(f"üìÇ Audio charg√©: {len(audio)/sr:.1f}s")
        
        # 2. Pipeline de mixage
        step1 = self.apply_vocal_compression(audio)
        step2 = self.apply_studio_reverb(step1)
        
        # 3. Traitement st√©r√©o si demand√©
        if stereo_output:
            step3 = self.stereo_widening(step2)
            step4 = self.final_mastering_chain(step3)
            
            # Sauvegarde st√©r√©o
            stereo_output_data = (step4 * 32767).astype(np.int16)
            wavfile.write(output_file, self.sample_rate, stereo_output_data)
        else:
            step3 = self.final_mastering_chain(step2)
            
            # Sauvegarde mono
            mono_output_data = (step3 * 32767).astype(np.int16)
            wavfile.write(output_file, self.sample_rate, mono_output_data)
        
        print("=" * 55)
        print(f"‚úÖ MIXAGE STUDIO TERMIN√â: {output_file}")
        print(f"üéØ Format: {'St√©r√©o' if stereo_output else 'Mono'}")
        
        return step4 if stereo_output else step3

# ===============================================
# UTILISATION PRATIQUE
# ===============================================

def mixage_final_studio():
    """Pipeline complet mixage studio"""
    
    mixer = StudioMixingEngine(sample_rate=44100)
    
    # Fichiers
    input_file = "voice_clone_realistic.wav"  # Sortie effets r√©alistes
    output_file = "voice_clone_FINAL_STUDIO.wav"
    
    # Mixage studio complet
    final_mix = mixer.complete_studio_mix(
        input_file, output_file, stereo_output=True
    )
    
    print("\nüéØ MIXAGE STUDIO TERMIN√â")
    print("üèÜ VOIX CLON√âE PR√äTE POUR DIFFUSION")
    print("üìä Qualit√©: Studio professionnel")
    
    return output_file

# Ex√©cution
if __name__ == "__main__":
    mixage_final_studio()</code></pre>
                </div>
            </div>

            <!-- M√©triques Audio Finales -->
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-green-600">
                        <i class="fas fa-chart-line mr-2"></i>M√©triques Qualit√© Studio
                    </h4>
                    <ul class="space-y-3 text-sm">
                        <li class="flex justify-between">
                            <span>Niveau RMS :</span>
                            <span class="font-medium text-green-600">-23 LUFS</span>
                        </li>
                        <li class="flex justify-between">
                            <span>Peak Maximum :</span>
                            <span class="font-medium text-green-600">-0.3 dBFS</span>
                        </li>
                        <li class="flex justify-between">
                            <span>Dynamic Range :</span>
                            <span class="font-medium text-green-600">12-15 dB</span>
                        </li>
                        <li class="flex justify-between">
                            <span>THD+N :</span>
                            <span class="font-medium text-green-600">&lt; 0.1%</span>
                        </li>
                        <li class="flex justify-between">
                            <span>R√©ponse freq. :</span>
                            <span class="font-medium text-green-600">80Hz-16kHz</span>
                        </li>
                    </ul>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-blue-600">
                        <i class="fas fa-headphones mr-2"></i>Tests d'√âcoute Recommand√©s
                    </h4>
                    <ul class="space-y-2 text-sm">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>√âcoute casque studio (r√©f√©rence plate)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Haut-parleurs monitoring (near-field)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>√âcouteurs grand public (simulation utilisateur)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Smartphone/laptop (compatibilit√© mobile)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Test mono (v√©rification compatibilit√©)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Niveaux d'√©coute variables (20-85 dB SPL)</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 5: Automation Compl√®te -->
    <section id="automation" class="py-16 bg-gray-50">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-robot mr-3 text-indigo-600"></i>
                    Automation du Post-Traitement
                </h3>
                <p class="text-gray-600 text-lg">Pipeline automatis√© complet de A √† Z</p>
            </div>

            <!-- Workflow Automation -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-workflow mr-2 text-indigo-600"></i>
                    Pipeline Automatis√© Complet
                </h4>
                
                <div class="space-y-4">
                    <div class="flex items-center bg-blue-50 rounded-lg p-4">
                        <div class="step-number">1</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Nettoyage Audio</h5>
                            <p class="text-sm text-gray-600">R√©duction bruit, suppression clics, normalisation</p>
                        </div>
                        <div class="text-blue-600 font-bold">30s</div>
                    </div>
                    
                    <div class="flex items-center">
                        <i class="fas fa-arrow-down text-gray-400 text-xl mx-4"></i>
                    </div>
                    
                    <div class="flex items-center bg-green-50 rounded-lg p-4">
                        <div class="step-number">2</div>
                        <div class="flex-1">
                            <h5 class="font-bold">√âgalisation Pro</h5>
                            <p class="text-sm text-gray-600">EQ multi-bandes, correction formants, de-essing</p>
                        </div>
                        <div class="text-green-600 font-bold">45s</div>
                    </div>
                    
                    <div class="flex items-center">
                        <i class="fas fa-arrow-down text-gray-400 text-xl mx-4"></i>
                    </div>
                    
                    <div class="flex items-center bg-purple-50 rounded-lg p-4">
                        <div class="step-number">3</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Effets R√©alistes</h5>
                            <p class="text-sm text-gray-600">Respirations, h√©sitations, micro-d√©tails</p>
                        </div>
                        <div class="text-purple-600 font-bold">60s</div>
                    </div>
                    
                    <div class="flex items-center">
                        <i class="fas fa-arrow-down text-gray-400 text-xl mx-4"></i>
                    </div>
                    
                    <div class="flex items-center bg-red-50 rounded-lg p-4">
                        <div class="step-number">4</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Mixage Studio</h5>
                            <p class="text-sm text-gray-600">Compression, limiteur, r√©verb, st√©r√©o</p>
                        </div>
                        <div class="text-red-600 font-bold">40s</div>
                    </div>
                    
                    <div class="flex items-center">
                        <i class="fas fa-arrow-down text-gray-400 text-xl mx-4"></i>
                    </div>
                    
                    <div class="flex items-center bg-yellow-50 rounded-lg p-4">
                        <div class="step-number">‚úì</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Fichier Final Studio</h5>
                            <p class="text-sm text-gray-600">Pr√™t pour diffusion MYM/OnlyFans</p>
                        </div>
                        <div class="text-yellow-600 font-bold">Total: 3min</div>
                    </div>
                </div>
            </div>

            <!-- Script Master Automation -->
            <div class="bg-white rounded-xl shadow-lg p-6">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-indigo-600"></i>
                    Script Master - Automation Compl√®te
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('master-automation')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="master-automation" class="text-green-400 text-sm overflow-x-auto"><code>#!/usr/bin/env python3
"""
Master Audio Post-Processing Pipeline
Pipeline automatis√© complet pour clonage vocal professionnel
"""

import os
import sys
import time
import argparse
from pathlib import Path

# Import des modules pr√©c√©dents
# (Placez tous les scripts pr√©c√©dents dans le m√™me dossier)
from audio_cleaner import ProfessionalAudioCleaner
from equalizer import ProfessionalEqualizer  
from vocal_realism import VocalRealismEnhancer
from studio_mixer import StudioMixingEngine

class MasterAudioPipeline:
    def __init__(self, sample_rate=44100, temp_dir="temp_processing"):
        self.sample_rate = sample_rate
        self.temp_dir = Path(temp_dir)
        self.temp_dir.mkdir(exist_ok=True)
        
        # Initialisation des modules
        self.cleaner = ProfessionalAudioCleaner()
        self.equalizer = ProfessionalEqualizer(sample_rate)
        self.realism_enhancer = VocalRealismEnhancer(sample_rate)
        self.mixer = StudioMixingEngine(sample_rate)
        
        # Compteurs et m√©triques
        self.start_time = None
        self.step_times = {}
        
    def validate_input_file(self, input_file):
        """Validation fichier d'entr√©e"""
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"Fichier introuvable: {input_file}")
        
        # V√©rification format audio
        valid_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.aac']
        if not any(input_file.lower().endswith(ext) for ext in valid_extensions):
            raise ValueError(f"Format non support√©. Formats valides: {valid_extensions}")
        
        # V√©rification taille fichier (max 100MB)
        file_size = os.path.getsize(input_file) / (1024 * 1024)  # MB
        if file_size > 100:
            raise ValueError(f"Fichier trop volumineux: {file_size:.1f}MB (max: 100MB)")
        
        print(f"‚úÖ Fichier valid√©: {input_file} ({file_size:.1f}MB)")
        return True
    
    def setup_output_structure(self, output_dir):
        """Cr√©ation structure de sortie"""
        output_path = Path(output_dir)
        
        # Cr√©ation dossiers
        folders = [
            'final',           # Fichier final
            'intermediate',    # Fichiers interm√©diaires
            'analysis',        # Rapports et analyses
            'backups'          # Sauvegardes
        ]
        
        for folder in folders:
            (output_path / folder).mkdir(parents=True, exist_ok=True)
        
        return output_path
    
    def generate_temp_filename(self, step_name, extension='.wav'):
        """G√©n√©ration nom fichier temporaire"""
        timestamp = int(time.time())
        return self.temp_dir / f"step_{step_name}_{timestamp}{extension}"
    
    def time_step(self, step_name):
        """D√©corateur pour chronom√©trage √©tapes"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                print(f"\n{'='*20} {step_name.upper()} {'='*20}")
                step_start = time.time()
                
                result = func(*args, **kwargs)
                
                step_duration = time.time() - step_start
                self.step_times[step_name] = step_duration
                
                print(f"‚úÖ {step_name} termin√© en {step_duration:.1f}s")
                return result
            return wrapper
        return decorator
    
    def step_1_cleaning(self, input_file):
        """√âtape 1: Nettoyage audio"""
        output_file = self.generate_temp_filename('01_cleaned')
        cleaned_audio = self.cleaner.complete_professional_cleaning(
            input_file, str(output_file)
        )
        return str(output_file)
    
    def step_2_equalization(self, input_file, eq_preset='female_warm'):
        """√âtape 2: √âgalisation"""
        output_file = self.generate_temp_filename('02_equalized')
        eq_audio = self.equalizer.complete_eq_processing(
            input_file, str(output_file), preset=eq_preset
        )
        return str(output_file)
    
    def step_3_realism(self, input_file):
        """√âtape 3: Effets r√©alistes"""
        output_file = self.generate_temp_filename('03_realistic')
        realistic_audio = self.realism_enhancer.enhance_vocal_realism(
            input_file, str(output_file)
        )
        return str(output_file)
    
    def step_4_mixing(self, input_file, stereo_output=True):
        """√âtape 4: Mixage studio"""
        output_file = self.generate_temp_filename('04_mixed')
        mixed_audio = self.mixer.complete_studio_mix(
            input_file, str(output_file), stereo_output=stereo_output
        )
        return str(output_file)
    
    def process_single_file(self, input_file, output_file, config=None):
        """Traitement complet fichier unique"""
        
        # Configuration par d√©faut
        default_config = {
            'eq_preset': 'female_warm',
            'stereo_output': True,
            'save_intermediates': False,
            'generate_report': True
        }
        
        if config:
            default_config.update(config)
        config = default_config
        
        self.start_time = time.time()
        
        try:
            print("üéµ D√âMARRAGE PIPELINE AUDIO PROFESSIONNEL")
            print("=" * 60)
            print(f"üìÇ Entr√©e: {input_file}")
            print(f"üìÅ Sortie: {output_file}")
            print(f"‚öôÔ∏è Config: {config}")
            
            # Validation
            self.validate_input_file(input_file)
            
            # Pipeline de traitement
            step1_output = self.time_step("NETTOYAGE")(self.step_1_cleaning)(input_file)
            step2_output = self.time_step("√âGALISATION")(self.step_2_equalization)(
                step1_output, config['eq_preset']
            )
            step3_output = self.time_step("R√âALISME")(self.step_3_realism)(step2_output)
            step4_output = self.time_step("MIXAGE")(self.step_4_mixing)(
                step3_output, config['stereo_output']
            )
            
            # Copie vers fichier final
            import shutil
            shutil.copy2(step4_output, output_file)
            
            # Sauvegarde interm√©diaires si demand√©
            if config['save_intermediates']:
                output_dir = Path(output_file).parent
                intermediate_dir = output_dir / 'intermediate'
                
                stages = [
                    (step1_output, 'cleaned.wav'),
                    (step2_output, 'equalized.wav'), 
                    (step3_output, 'realistic.wav'),
                    (step4_output, 'mixed.wav')
                ]
                
                for stage_file, stage_name in stages:
                    shutil.copy2(stage_file, intermediate_dir / stage_name)
            
            # G√©n√©ration rapport
            if config['generate_report']:
                self.generate_processing_report(input_file, output_file)
            
            # Nettoyage fichiers temporaires
            self.cleanup_temp_files()
            
            total_time = time.time() - self.start_time
            
            print("=" * 60)
            print("üèÜ PIPELINE TERMIN√â AVEC SUCC√àS")
            print(f"‚è±Ô∏è Temps total: {total_time:.1f}s")
            print(f"üìÅ Fichier final: {output_file}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå ERREUR PIPELINE: {e}")
            self.cleanup_temp_files()
            return False
    
    def process_batch(self, input_dir, output_dir, config=None):
        """Traitement par lot"""
        input_path = Path(input_dir)
        output_path = self.setup_output_structure(output_dir)
        
        # Recherche fichiers audio
        audio_extensions = ['*.wav', '*.mp3', '*.flac', '*.m4a', '*.aac']
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(input_path.glob(ext))
        
        if not audio_files:
            print(f"‚ùå Aucun fichier audio trouv√© dans {input_dir}")
            return False
        
        print(f"üìÇ {len(audio_files)} fichiers trouv√©s pour traitement")
        
        # Traitement s√©quentiel
        success_count = 0
        for i, input_file in enumerate(audio_files, 1):
            print(f"\nüéµ FICHIER {i}/{len(audio_files)}: {input_file.name}")
            
            output_file = output_path / 'final' / f"processed_{input_file.stem}.wav"
            
            if self.process_single_file(str(input_file), str(output_file), config):
                success_count += 1
            else:
                print(f"‚ùå √âchec traitement: {input_file.name}")
        
        print(f"\nüéØ TRAITEMENT BATCH TERMIN√â")
        print(f"‚úÖ Succ√®s: {success_count}/{len(audio_files)}")
        
        return success_count == len(audio_files)
    
    def generate_processing_report(self, input_file, output_file):
        """G√©n√©ration rapport de traitement"""
        report_file = Path(output_file).parent / 'analysis' / 'processing_report.txt'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("RAPPORT DE TRAITEMENT AUDIO PROFESSIONNEL\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"Fichier d'entr√©e: {input_file}\n")
            f.write(f"Fichier de sortie: {output_file}\n")
            f.write(f"Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("√âTAPES DE TRAITEMENT:\n")
            f.write("-" * 30 + "\n")
            
            total_time = 0
            for step_name, duration in self.step_times.items():
                f.write(f"{step_name.ljust(20)}: {duration:.1f}s\n")
                total_time += duration
            
            f.write(f"{'TOTAL'.ljust(20)}: {total_time:.1f}s\n\n")
            
            f.write("PARAM√àTRES UTILIS√âS:\n")
            f.write("-" * 30 + "\n")
            f.write("‚Ä¢ Nettoyage: R√©duction bruit, suppression clics, normalisation\n")
            f.write("‚Ä¢ √âgalisation: Preset f√©minin chaleureux, correction formants\n")
            f.write("‚Ä¢ R√©alisme: Respirations naturelles, h√©sitations subtiles\n")
            f.write("‚Ä¢ Mixage: Compression 3:1, limiteur -0.3dB, r√©verb studio\n\n")
            
            f.write("QUALIT√â FINALE:\n")
            f.write("-" * 30 + "\n")
            f.write("‚Ä¢ Niveau: -23 LUFS (standard diffusion)\n")
            f.write("‚Ä¢ Peak: -0.3 dBFS (headroom s√©curis√©)\n")
            f.write("‚Ä¢ Dynamic Range: 12-15 dB\n")
            f.write("‚Ä¢ Format: WAV 44.1kHz 16-bit\n")
        
        print(f"üìä Rapport g√©n√©r√©: {report_file}")
    
    def cleanup_temp_files(self):
        """Nettoyage fichiers temporaires"""
        import shutil
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)
            print("üßπ Fichiers temporaires nettoy√©s")

# ===============================================
# INTERFACE LIGNE DE COMMANDE
# ===============================================

def main():
    parser = argparse.ArgumentParser(description='Pipeline Audio Professionnel')
    parser.add_argument('input', help='Fichier ou dossier d\'entr√©e')
    parser.add_argument('output', help='Fichier ou dossier de sortie')
    parser.add_argument('--preset', choices=['female_warm', 'female_bright'], 
                       default='female_warm', help='Preset d\'√©galisation')
    parser.add_argument('--mono', action='store_true', help='Sortie mono')
    parser.add_argument('--save-intermediate', action='store_true', 
                       help='Sauvegarder fichiers interm√©diaires')
    parser.add_argument('--batch', action='store_true', 
                       help='Mode traitement par lot')
    
    args = parser.parse_args()
    
    # Configuration
    config = {
        'eq_preset': args.preset,
        'stereo_output': not args.mono,
        'save_intermediates': args.save_intermediate,
        'generate_report': True
    }
    
    # Initialisation pipeline
    pipeline = MasterAudioPipeline()
    
    # Traitement
    if args.batch:
        success = pipeline.process_batch(args.input, args.output, config)
    else:
        success = pipeline.process_single_file(args.input, args.output, config)
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()

# ===============================================
# UTILISATION RAPIDE
# ===============================================

def traitement_rapide(input_file, output_file):
    """Traitement rapide avec param√®tres par d√©faut"""
    pipeline = MasterAudioPipeline()
    return pipeline.process_single_file(input_file, output_file)

# Exemple d'utilisation
# traitement_rapide("voice_raw.wav", "voice_final_studio.wav")</code></pre>
                </div>
            </div>
        </div>
    </section>

    <!-- R√©capitulatif Final -->
    <section class="py-16 bg-gradient-to-br from-purple-600 to-blue-700 text-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold mb-4">
                    <i class="fas fa-trophy mr-3"></i>
                    R√©capitulatif BLOC 11.6 Complet
                </h3>
                <p class="text-xl">Pipeline de post-traitement audio professionnel ma√Ætris√©</p>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6 mb-8">
                <div class="text-center">
                    <div class="bg-white bg-opacity-20 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-broom text-3xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Nettoyage Ma√Ætris√©</h4>
                    <p class="text-sm opacity-90">R√©duction bruit, suppression artefacts, normalisation intelligente</p>
                </div>

                <div class="text-center">
                    <div class="bg-white bg-opacity-20 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-sliders-h text-3xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">EQ Professionnel</h4>
                    <p class="text-sm opacity-90">Multi-bandes, formants corrig√©s, presets optimis√©s</p>
                </div>

                <div class="text-center">
                    <div class="bg-white bg-opacity-20 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-magic text-3xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">R√©alisme Naturel</h4>
                    <p class="text-sm opacity-90">Respirations, h√©sitations, micro-d√©tails humains</p>
                </div>

                <div class="text-center">
                    <div class="bg-white bg-opacity-20 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-volume-up text-3xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Mixage Studio</h4>
                    <p class="text-sm opacity-90">Compression, limiteur, spatialisation, mastering</p>
                </div>
            </div>

            <div class="text-center">
                <div class="success-box">
                    <h4 class="font-bold text-xl mb-4 text-gray-800">üéØ Objectif Atteint</h4>
                    <p class="text-gray-700 mb-4">
                        Votre clonage vocal est maintenant transform√© en production audio de qualit√© studio professionnelle, 
                        indiscernable d'un enregistrement r√©el et pr√™t pour mon√©tisation sur MYM/OnlyFans.
                    </p>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-4 text-sm text-gray-700">
                        <div>
                            <strong>Qualit√© Technique :</strong><br>
                            Studio professionnel, -23 LUFS, THD &lt; 0.1%
                        </div>
                        <div>
                            <strong>R√©alisme Humain :</strong><br>
                            Respirations, h√©sitations, micro-d√©tails naturels
                        </div>
                        <div>
                            <strong>Automation :</strong><br>
                            Pipeline complet en 3 minutes, reproductible
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Navigation vers autres blocs -->
    <section class="py-12 bg-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-8">
                <h3 class="text-2xl font-bold text-gray-800 mb-4">Navigation Formation Clonage Vocal</h3>
                <p class="text-gray-
    <script id="html_badge_script1">
        window.__genspark_remove_badge_link = "https://www.genspark.ai/api/html_badge/" +
            "remove_badge?token=To%2FBnjzloZ3UfQdcSaYfDlt1n2H98BoHF0yEN%2B5RyRJ%2BrwpFg2Feo2Try5bFzFWmZUIAZgccxDSCTebWrKrAsWc%2FdTUled%2BOqqrhVfMN4fSwZSNqv7MbEjAIT%2FzvkNe1%2F080BdQcxczZzCyUWJAseeyCukSgu05DRjzHlSjkWNWyp2fkUjkmYAU%2FHI4Tp%2FyaygOxE9AF05c%2FV15m5pW2vE5aQiWpt5cvwfcfYzdDl5SD0uVSEFv0qaHJ%2BsM1483JfqS3A2FI55AbUTf6xRNDicMEluNu5d0iRkVFjnF7m7hMjZczIFcypVeRHCi%2BmnXETTScpTtrbBesCcm%2F1974GeR%2BoIOAX58Dw9uKQ8fT7DxV0zizNeMZNpXcEhOtjG1QWaIMIv%2FzPxoAZhgw8UDH18LtiKT2Pqk9L9A0sm51CmRLjK90ZMz%2BzDjaD6UYtfnI5tOEc9Pz6mYJeIzdfHZ4OobQ91QvpJNAKxWxPML%2BsUlJ5jMty1WcxsAxdg6bI4qprQAh%2BJV68MmLKRi8yV%2Bt1xZh1qUAr33Uw11KqzXHorQEtwbf0RZCUn%2BFBDSHFw3U";
        window.__genspark_locale = "fr-FR";
        window.__genspark_token = "To/BnjzloZ3UfQdcSaYfDlt1n2H98BoHF0yEN+5RyRJ+rwpFg2Feo2Try5bFzFWmZUIAZgccxDSCTebWrKrAsWc/dTUled+OqqrhVfMN4fSwZSNqv7MbEjAIT/zvkNe1/080BdQcxczZzCyUWJAseeyCukSgu05DRjzHlSjkWNWyp2fkUjkmYAU/HI4Tp/yaygOxE9AF05c/V15m5pW2vE5aQiWpt5cvwfcfYzdDl5SD0uVSEFv0qaHJ+sM1483JfqS3A2FI55AbUTf6xRNDicMEluNu5d0iRkVFjnF7m7hMjZczIFcypVeRHCi+mnXETTScpTtrbBesCcm/1974GeR+oIOAX58Dw9uKQ8fT7DxV0zizNeMZNpXcEhOtjG1QWaIMIv/zPxoAZhgw8UDH18LtiKT2Pqk9L9A0sm51CmRLjK90ZMz+zDjaD6UYtfnI5tOEc9Pz6mYJeIzdfHZ4OobQ91QvpJNAKxWxPML+sUlJ5jMty1WcxsAxdg6bI4qprQAh+JV68MmLKRi8yV+t1xZh1qUAr33Uw11KqzXHorQEtwbf0RZCUn+FBDSHFw3U";
    </script>
    
    <script id="html_notice_dialog_script" src="https://www.genspark.ai/notice_dialog.js"></script>
    <script defer src="https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon='{"rayId":"950e68813859250f","serverTiming":{"name":{"cfExtPri":true,"cfEdge":true,"cfOrigin":true,"cfL4":true,"cfSpeedBrain":true,"cfCacheStatus":true}},"version":"2025.6.2","token":"4edd5f8ec12a48cfa682ab8261b80a79"}' crossorigin="anonymous"></script>
