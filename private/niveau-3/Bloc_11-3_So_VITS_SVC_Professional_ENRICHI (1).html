<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Manuel IA MYM 2025 - BLOC 11.3 - So-VITS-SVC Professional</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
    <style>
        .gradient-bg {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        }
        .code-block {
            background: #1a202c;
            color: #e2e8f0;
            border-radius: 8px;
            padding: 1rem;
            margin: 1rem 0;
            position: relative;
            font-family: 'Courier New', monospace;
        }
        .copy-btn {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            background: #4a5568;
            color: white;
            border: none;
            padding: 0.25rem 0.5rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 0.75rem;
        }
        .copy-btn:hover {
            background: #2d3748;
        }
        .step-indicator {
            background: linear-gradient(45deg, #f093fb 0%, #f5576c 100%);
            color: white;
            border-radius: 50%;
            width: 2rem;
            height: 2rem;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            margin-right: 1rem;
        }
        .warning-box {
            border-left: 4px solid #f59e0b;
            background: #fef3c7;
            padding: 1rem;
            margin: 1rem 0;
        }
        .success-box {
            border-left: 4px solid #10b981;
            background: #d1fae5;
            padding: 1rem;
            margin: 1rem 0;
        }
        .error-box {
            border-left: 4px solid #ef4444;
            background: #fee2e2;
            padding: 1rem;
            margin: 1rem 0;
        }
        .interactive-card {
            transition: all 0.3s ease;
            cursor: pointer;
        }
        .interactive-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 25px rgba(0,0,0,0.1);
        }
        .accordion-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
        }
        .accordion-content.active {
            max-height: 1000px;
        }
    </style>
</head>

<body class="bg-gray-50 font-sans">
    <!-- Header -->
    <header class="gradient-bg text-white py-16">
        <div class="container mx-auto px-6">
            <div class="text-center">
                <div class="mb-6">
                    <i class="fas fa-microphone-alt text-6xl mb-4"></i>
                </div>
                <h1 class="text-5xl font-bold mb-4">BLOC 11.3 ENRICHI</h1>
                <h2 class="text-3xl font-light mb-6">So-VITS-SVC Professional</h2>
                <p class="text-xl max-w-4xl mx-auto leading-relaxed">
                    Conversion vocale haute qualit√© avec So-VITS-SVC (Singing Voice Conversion). 
                    Installation environnement, entra√Ænement personnalis√©, inf√©rence professionnelle.
                </p>
                <div class="mt-8">
                    <span class="inline-block bg-white bg-opacity-20 rounded-full px-6 py-2 text-sm font-medium">
                        <i class="fas fa-graduation-cap mr-2"></i>
                        Niveau : Avanc√© ‚Ä¢ Conversion vocale ‚Ä¢ Qualit√© professionnelle
                    </span>
                </div>
            </div>
        </div>
    </header>

    <!-- Progress Indicator -->
    <div class="bg-white shadow-sm py-4">
        <div class="container mx-auto px-6">
            <div class="flex items-center justify-between text-sm">
                <span class="text-gray-600">Progression du Bloc 11.3</span>
                <span class="text-blue-600 font-semibold">So-VITS-SVC Professional</span>
            </div>
            <div class="w-full bg-gray-200 rounded-full h-2 mt-2">
                <div class="bg-gradient-to-r from-blue-500 to-purple-600 h-2 rounded-full" style="width: 25%"></div>
            </div>
        </div>
    </div>

    <!-- Navigation Tabs -->
    <div class="bg-white border-b border-gray-200 sticky top-0 z-50">
        <div class="container mx-auto px-6">
            <nav class="flex space-x-8">
                <button class="tab-btn active py-4 px-2 border-b-2 border-blue-500 text-blue-600 font-medium" data-tab="introduction">
                    <i class="fas fa-info-circle mr-2"></i>Introduction
                </button>
                <button class="tab-btn py-4 px-2 text-gray-500 hover:text-gray-700" data-tab="installation">
                    <i class="fas fa-download mr-2"></i>Installation
                </button>
                <button class="tab-btn py-4 px-2 text-gray-500 hover:text-gray-700" data-tab="preparation">
                    <i class="fas fa-database mr-2"></i>Pr√©paration
                </button>
                <button class="tab-btn py-4 px-2 text-gray-500 hover:text-gray-700" data-tab="training">
                    <i class="fas fa-brain mr-2"></i>Entra√Ænement
                </button>
                <button class="tab-btn py-4 px-2 text-gray-500 hover:text-gray-700" data-tab="inference">
                    <i class="fas fa-magic mr-2"></i>Inf√©rence
                </button>
                <button class="tab-btn py-4 px-2 text-gray-500 hover:text-gray-700" data-tab="optimisation">
                    <i class="fas fa-tachometer-alt mr-2"></i>Optimisation
                </button>
            </nav>
        </div>
    </div>

    <!-- Content Sections -->
    <div class="container mx-auto px-6 py-8">

        <!-- Introduction Section -->
        <div id="introduction" class="tab-content">
            <div class="bg-white rounded-xl shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold text-gray-800 mb-6">
                    <i class="fas fa-microphone text-purple-600 mr-3"></i>
                    Qu'est-ce que So-VITS-SVC ?
                </h2>
                
                <div class="grid grid-cols-1 lg:grid-cols-2 gap-8">
                    <div>
                        <p class="text-lg text-gray-700 mb-6 leading-relaxed">
                            <strong>So-VITS-SVC (Singing Voice Conversion)</strong> est un mod√®le de conversion vocale bas√© sur VITS, 
                            optimis√© pour le chant mais excellent pour la voix parl√©e. Il offre une qualit√© exceptionnelle 
                            avec seulement quelques minutes d'√©chantillons vocaux.
                        </p>
                        
                        <div class="success-box">
                            <h4 class="font-bold text-green-800 mb-2">
                                <i class="fas fa-star mr-2"></i>Avantages Cl√©s
                            </h4>
                            <ul class="list-disc list-inside text-green-700 space-y-1">
                                <li><strong>Qualit√© exceptionnelle :</strong> Son tr√®s naturel et expressif</li>
                                <li><strong>Peu d'√©chantillons :</strong> 5-10 minutes d'audio suffisent</li>
                                <li><strong>Contr√¥le pr√©cis :</strong> Pitch, timbre, √©motion ajustables</li>
                                <li><strong>Open source :</strong> Gratuit et personnalisable</li>
                                <li><strong>GPU efficace :</strong> Optimis√© pour cartes graphiques</li>
                            </ul>
                        </div>
                    </div>
                    
                    <div>
                        <img src="https://user-images.githubusercontent.com/34696535/206884686-f6f48026-a8dd-4a94-8c85-1a6a73b6039e.png" 
                             alt="Interface So-VITS-SVC" 
                             class="w-full rounded-lg shadow-lg">
                        <p class="text-sm text-gray-500 text-center mt-2">Interface So-VITS-SVC - Architecture du mod√®le</p>
                    </div>
                </div>

                <!-- Comparison Table -->
                <div class="mt-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Comparaison avec autres techniques</h3>
                    <div class="overflow-x-auto">
                        <table class="w-full border-collapse border border-gray-300">
                            <thead>
                                <tr class="bg-gray-100">
                                    <th class="border border-gray-300 px-4 py-2 text-left">Technique</th>
                                    <th class="border border-gray-300 px-4 py-2 text-left">Qualit√©</th>
                                    <th class="border border-gray-300 px-4 py-2 text-left">Temps requis</th>
                                    <th class="border border-gray-300 px-4 py-2 text-left">Complexit√©</th>
                                    <th class="border border-gray-300 px-4 py-2 text-left">Usage optimal</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td class="border border-gray-300 px-4 py-2 font-semibold">So-VITS-SVC</td>
                                    <td class="border border-gray-300 px-4 py-2">‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td>
                                    <td class="border border-gray-300 px-4 py-2">5-10 min</td>
                                    <td class="border border-gray-300 px-4 py-2">Avanc√©e</td>
                                    <td class="border border-gray-300 px-4 py-2">Conversion chant/voix</td>
                                </tr>
                                <tr class="bg-gray-50">
                                    <td class="border border-gray-300 px-4 py-2">RVC</td>
                                    <td class="border border-gray-300 px-4 py-2">‚≠ê‚≠ê‚≠ê‚≠ê</td>
                                    <td class="border border-gray-300 px-4 py-2">2-5 min</td>
                                    <td class="border border-gray-300 px-4 py-2">Moyenne</td>
                                    <td class="border border-gray-300 px-4 py-2">Voix parl√©e</td>
                                </tr>
                                <tr>
                                    <td class="border border-gray-300 px-4 py-2">ElevenLabs</td>
                                    <td class="border border-gray-300 px-4 py-2">‚≠ê‚≠ê‚≠ê‚≠ê</td>
                                    <td class="border border-gray-300 px-4 py-2">1-2 min</td>
                                    <td class="border border-gray-300 px-4 py-2">Simple</td>
                                    <td class="border border-gray-300 px-4 py-2">API rapide</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>

        <!-- Installation Section -->
        <div id="installation" class="tab-content hidden">
            <div class="bg-white rounded-xl shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold text-gray-800 mb-6">
                    <i class="fas fa-download text-blue-600 mr-3"></i>
                    Installation So-VITS-SVC
                </h2>

                <!-- Pr√©requis -->
                <div class="warning-box mb-8">
                    <h4 class="font-bold text-yellow-800 mb-2">
                        <i class="fas fa-exclamation-triangle mr-2"></i>Pr√©requis Syst√®me
                    </h4>
                    <ul class="list-disc list-inside text-yellow-700 space-y-1">
                        <li><strong>Python 3.8+</strong> install√© et fonctionnel</li>
                        <li><strong>Git</strong> pour cloner le repository</li>
                        <li><strong>GPU NVIDIA</strong> recommand√© (RTX 3060+ id√©al)</li>
                        <li><strong>16GB RAM</strong> minimum, 32GB recommand√©</li>
                        <li><strong>10GB espace disque</strong> libre</li>
                    </ul>
                </div>

                <!-- √âtape 1: Clone Repository -->
                <div class="mb-8">
                    <div class="flex items-center mb-4">
                        <div class="step-indicator">1</div>
                        <h3 class="text-xl font-bold text-gray-800">Cloner le Repository So-VITS-SVC</h3>
                    </div>
                    
                    <p class="text-gray-700 mb-4">
                        Nous utilisons la version 4.0 stable de So-VITS-SVC. Ouvrez votre terminal et ex√©cutez :
                    </p>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># Clonage du repository officiel So-VITS-SVC 4.0
git clone https://github.com/svc-develop-team/so-vits-svc.git
cd so-vits-svc

# V√©rification de la version
git branch
git checkout 4.0</pre>
                    </div>

                    <div class="success-box">
                        <h4 class="font-bold text-green-800 mb-2">‚úÖ V√©rification √©tape 1</h4>
                        <p class="text-green-700">
                            Vous devriez voir un dossier "so-vits-svc" cr√©√© avec tous les fichiers du projet. 
                            La commande <code>ls</code> ou <code>dir</code> doit afficher des fichiers comme "train.py", "inference.py", etc.
                        </p>
                    </div>
                </div>

                <!-- √âtape 2: Environnement virtuel -->
                <div class="mb-8">
                    <div class="flex items-center mb-4">
                        <div class="step-indicator">2</div>
                        <h3 class="text-xl font-bold text-gray-800">Cr√©er l'Environnement Virtuel</h3>
                    </div>
                    
                    <p class="text-gray-700 mb-4">
                        Cr√©ons un environnement Python isol√© pour √©viter les conflits de d√©pendances :
                    </p>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># Cr√©ation environnement virtuel
python -m venv sovits_env

# Activation de l'environnement
# Windows:
sovits_env\Scripts\activate
# Linux/Mac:
source sovits_env/bin/activate

# V√©rification
python --version
pip --version</pre>
                    </div>

                    <img src="https://docs.python.org/3/_images/pyvenv.png" 
                         alt="Environnement virtuel Python" 
                         class="w-full max-w-md mx-auto rounded-lg shadow-lg my-4">
                </div>

                <!-- √âtape 3: Installation des d√©pendances -->
                <div class="mb-8">
                    <div class="flex items-center mb-4">
                        <div class="step-indicator">3</div>
                        <h3 class="text-xl font-bold text-gray-800">Installation des D√©pendances</h3>
                    </div>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># Mise √† jour pip
pip install --upgrade pip

# Installation PyTorch avec support CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Installation des d√©pendances So-VITS-SVC
pip install -r requirements.txt

# D√©pendances additionnelles
pip install fairseq
pip install tensorboard
pip install librosa==0.9.2</pre>
                    </div>

                    <div class="warning-box">
                        <h4 class="font-bold text-yellow-800 mb-2">‚ö†Ô∏è Probl√®mes Courants</h4>
                        <div class="text-yellow-700">
                            <p><strong>Erreur "Microsoft Visual C++ required" :</strong></p>
                            <p>Installez les Microsoft C++ Build Tools depuis le site officiel Microsoft.</p>
                            <br>
                            <p><strong>Erreur "CUDA not available" :</strong></p>
                            <p>Installez CUDA Toolkit 11.8 depuis le site NVIDIA.</p>
                        </div>
                    </div>
                </div>

                <!-- √âtape 4: T√©l√©chargement des mod√®les -->
                <div class="mb-8">
                    <div class="flex items-center mb-4">
                        <div class="step-indicator">4</div>
                        <h3 class="text-xl font-bold text-gray-800">T√©l√©chargement des Mod√®les Pr√©-entra√Æn√©s</h3>
                    </div>
                    
                    <p class="text-gray-700 mb-4">
                        So-VITS-SVC n√©cessite plusieurs mod√®les pr√©-entra√Æn√©s pour fonctionner :
                    </p>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># Cr√©ation du dossier pour les mod√®les
mkdir pretrain
cd pretrain

# T√©l√©chargement du mod√®le de contenu (obligatoire)
wget -O hubert_base.pt https://huggingface.co/lj1995/VoiceConversionWebUI/resolve/main/hubert_base.pt

# T√©l√©chargement mod√®le G (g√©n√©rateur)
wget -O G_0.pth https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/G_0.pth

# T√©l√©chargement mod√®le D (discriminateur)  
wget -O D_0.pth https://huggingface.co/datasets/ms903/sovits4.0-768vec-layer12/resolve/main/D_0.pth

# Retour au dossier principal
cd ..</pre>
                    </div>

                    <div class="success-box">
                        <h4 class="font-bold text-green-800 mb-2">‚úÖ V√©rification Installation</h4>
                        <div class="text-green-700">
                            <p>Testez l'installation avec cette commande :</p>
                            <div class="code-block mt-2">
                                <button class="copy-btn" onclick="copyCode(this)">
                                    <i class="fas fa-copy"></i> Copier
                                </button>
<pre>python inference_main.py --help</pre>
                            </div>
                            <p class="mt-2">Si aucune erreur n'appara√Æt, l'installation est r√©ussie !</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Pr√©paration Section -->
        <div id="preparation" class="tab-content hidden">
            <div class="bg-white rounded-xl shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold text-gray-800 mb-6">
                    <i class="fas fa-database text-green-600 mr-3"></i>
                    Pr√©paration du Dataset Audio
                </h2>

                <!-- Structure des donn√©es -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Structure du Dataset</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>dataset_raw/
‚îú‚îÄ‚îÄ speaker_name/
‚îÇ   ‚îú‚îÄ‚îÄ audio_001.wav
‚îÇ   ‚îú‚îÄ‚îÄ audio_002.wav
‚îÇ   ‚îú‚îÄ‚îÄ audio_003.wav
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ 44k/</pre>
                    </div>

                    <div class="warning-box">
                        <h4 class="font-bold text-yellow-800 mb-2">üìã Exigences Audio</h4>
                        <ul class="list-disc list-inside text-yellow-700 space-y-1">
                            <li><strong>Format :</strong> WAV, 44.1kHz, 16-bit minimum</li>
                            <li><strong>Dur√©e :</strong> 5-30 secondes par fichier</li>
                            <li><strong>Qualit√© :</strong> Audio propre, sans bruit de fond</li>
                            <li><strong>Quantit√© :</strong> 50-200 fichiers (5-15 minutes total)</li>
                            <li><strong>Contenu :</strong> Une seule voix, diff√©rentes √©motions</li>
                        </ul>
                    </div>
                </div>

                <!-- Script de pr√©paration automatique -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Script de Pr√©paration Automatique</h3>
                    
                    <p class="text-gray-700 mb-4">
                        Cr√©ez ce script Python pour pr√©parer automatiquement vos fichiers audio :
                    </p>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>import os
import librosa
import soundfile as sf
import numpy as np
from pathlib import Path

class DatasetPreparator:
    def __init__(self, input_folder, output_folder, speaker_name):
        self.input_folder = Path(input_folder)
        self.output_folder = Path(output_folder)
        self.speaker_name = speaker_name
        self.target_sr = 44100
        
    def prepare_dataset(self):
        """Pr√©pare le dataset pour So-VITS-SVC"""
        print(f"üéµ Pr√©paration dataset pour {self.speaker_name}")
        
        # Cr√©ation structure dossiers
        output_speaker_dir = self.output_folder / "dataset_raw" / self.speaker_name
        output_speaker_dir.mkdir(parents=True, exist_ok=True)
        
        processed_count = 0
        
        # Traitement de chaque fichier audio
        for audio_file in self.input_folder.glob("*.wav"):
            try:
                # Chargement audio
                audio, sr = librosa.load(audio_file, sr=None)
                
                # Nettoyage et normalisation
                cleaned_audio = self.clean_audio(audio, sr)
                
                # D√©coupage si trop long
                segments = self.split_long_audio(cleaned_audio, max_duration=25)
                
                # Sauvegarde segments
                for i, segment in enumerate(segments):
                    output_file = output_speaker_dir / f"{audio_file.stem}_{i:03d}.wav"
                    sf.write(output_file, segment, self.target_sr)
                    processed_count += 1
                    
                print(f"‚úÖ Trait√©: {audio_file.name} -> {len(segments)} segments")
                
            except Exception as e:
                print(f"‚ùå Erreur {audio_file.name}: {e}")
        
        print(f"üéâ Dataset pr√©par√©: {processed_count} fichiers audio")
        return processed_count
    
    def clean_audio(self, audio, sr):
        """Nettoie et normalise l'audio"""
        # R√©√©chantillonnage si n√©cessaire
        if sr != self.target_sr:
            audio = librosa.resample(audio, orig_sr=sr, target_sr=self.target_sr)
        
        # Suppression du silence
        audio_trimmed, _ = librosa.effects.trim(audio, top_db=20)
        
        # Normalisation
        audio_normalized = librosa.util.normalize(audio_trimmed)
        
        # R√©duction de bruit simple
        audio_filtered = self.simple_denoise(audio_normalized)
        
        return audio_filtered
    
    def simple_denoise(self, audio):
        """R√©duction de bruit basique"""
        # Filtre passe-haut pour √©liminer les basses fr√©quences
        audio_filtered = librosa.effects.preemphasis(audio)
        return audio_filtered
    
    def split_long_audio(self, audio, max_duration=25):
        """D√©coupe les longs fichiers audio"""
        max_samples = int(max_duration * self.target_sr)
        
        if len(audio) <= max_samples:
            return [audio]
        
        segments = []
        for start in range(0, len(audio), max_samples):
            end = min(start + max_samples, len(audio))
            segment = audio[start:end]
            
            # Garde seulement les segments d'au moins 3 secondes
            if len(segment) >= 3 * self.target_sr:
                segments.append(segment)
        
        return segments

# Utilisation du script
if __name__ == "__main__":
    # Configuration
    INPUT_FOLDER = "raw_audio_files"  # Dossier avec vos fichiers audio bruts
    OUTPUT_FOLDER = "."               # Dossier So-VITS-SVC
    SPEAKER_NAME = "leana_mystere"    # Nom du speaker pour L√©ana
    
    # Pr√©paration
    preparator = DatasetPreparator(INPUT_FOLDER, OUTPUT_FOLDER, SPEAKER_NAME)
    preparator.prepare_dataset()</pre>
                    </div>
                </div>

                <!-- V√©rification de la qualit√© -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">V√©rification Qualit√© Dataset</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>import librosa
import matplotlib.pyplot as plt
import numpy as np

def analyze_dataset_quality(dataset_path):
    """Analyse la qualit√© du dataset pr√©par√©"""
    print("üîç Analyse qualit√© du dataset...")
    
    audio_files = list(Path(dataset_path).glob("*.wav"))
    durations = []
    sample_rates = []
    rms_levels = []
    
    for audio_file in audio_files[:10]:  # Analyse des 10 premiers
        audio, sr = librosa.load(audio_file, sr=None)
        
        duration = len(audio) / sr
        rms = np.sqrt(np.mean(audio**2))
        
        durations.append(duration)
        sample_rates.append(sr)
        rms_levels.append(rms)
    
    # Statistiques
    print(f"üìä Nombre de fichiers: {len(audio_files)}")
    print(f"‚è±Ô∏è  Dur√©e moyenne: {np.mean(durations):.2f}s")
    print(f"üéµ Sample rate: {sample_rates[0]}Hz")
    print(f"üîä Niveau RMS moyen: {np.mean(rms_levels):.4f}")
    
    # Recommandations
    if np.mean(durations) < 3:
        print("‚ö†Ô∏è  Fichiers trop courts, ajoutez plus d'audio")
    elif np.mean(durations) > 30:
        print("‚ö†Ô∏è  Fichiers trop longs, d√©coupez-les")
    else:
        print("‚úÖ Dur√©es audio optimales")
    
    if np.mean(rms_levels) < 0.1:
        print("‚ö†Ô∏è  Audio trop faible, augmentez le volume")
    elif np.mean(rms_levels) > 0.5:
        print("‚ö†Ô∏è  Audio trop fort, r√©duisez le volume")
    else:
        print("‚úÖ Niveaux audio optimaux")

# Utilisation
analyze_dataset_quality("dataset_raw/leana_mystere/")</pre>
                    </div>

                    <img src="https://librosa.org/doc/latest/_images/librosa-display-waveshow-1.png" 
                         alt="Analyse forme d'onde audio" 
                         class="w-full max-w-lg mx-auto rounded-lg shadow-lg my-4">
                </div>
            </div>
        </div>

        <!-- Training Section -->
        <div id="training" class="tab-content hidden">
            <div class="bg-white rounded-xl shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold text-gray-800 mb-6">
                    <i class="fas fa-brain text-red-600 mr-3"></i>
                    Entra√Ænement du Mod√®le
                </h2>

                <!-- Configuration de l'entra√Ænement -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Configuration de l'Entra√Ænement</h3>
                    
                    <p class="text-gray-700 mb-4">
                        Cr√©ez le fichier de configuration <code>configs/config.json</code> :
                    </p>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>{
  "train": {
    "log_interval": 200,
    "eval_interval": 1000,
    "seed": 1234,
    "epochs": 10000,
    "learning_rate": 2e-4,
    "betas": [0.8, 0.99],
    "eps": 1e-9,
    "batch_size": 6,
    "fp16_run": true,
    "lr_decay": 0.999875,
    "segment_size": 8192,
    "init_lr_ratio": 1,
    "warmup_epochs": 0,
    "c_mel": 45,
    "c_kl": 1.0
  },
  "data": {
    "training_files": "filelists/train.txt",
    "validation_files": "filelists/val.txt",
    "text_cleaners": ["cjke_cleaners2"],
    "max_wav_value": 32768.0,
    "sampling_rate": 44100,
    "filter_length": 2048,
    "hop_length": 512,
    "win_length": 2048,
    "n_mel_channels": 128,
    "mel_fmin": 0.0,
    "mel_fmax": 22050
  },
  "model": {
    "inter_channels": 192,
    "hidden_channels": 192,
    "filter_channels": 768,
    "n_heads": 2,
    "n_layers": 6,
    "kernel_size": 3,
    "p_dropout": 0.1,
    "resblock": "1",
    "resblock_kernel_sizes": [3, 7, 11],
    "resblock_dilation_sizes": [[1, 3, 5], [1, 3, 5], [1, 3, 5]],
    "upsample_rates": [8, 8, 2, 2, 2],
    "upsample_initial_channel": 512,
    "upsample_kernel_sizes": [16, 16, 4, 4, 4],
    "n_layers_q": 3,
    "use_spectral_norm": false,
    "gin_channels": 768,
    "ssl_dim": 768,
    "n_speakers": 1
  },
  "speakers": ["leana_mystere"],
  "spk2id": {
    "leana_mystere": 0
  }
}</pre>
                    </div>
                </div>

                <!-- Pr√©processing -->
                <div class="mb-8">
                    <div class="flex items-center mb-4">
                        <div class="step-indicator">1</div>
                        <h3 class="text-xl font-bold text-gray-800">Pr√©processing du Dataset</h3>
                    </div>
                    
                    <p class="text-gray-700 mb-4">
                        Avant l'entra√Ænement, nous devons pr√©traiter les donn√©es audio :
                    </p>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># 1. R√©√©chantillonnage des fichiers audio
python resample.py

# 2. Pr√©processing automatique
python preprocess_flist_config.py --speech_encoder vec768l12

# 3. G√©n√©ration des features HuBERT
python preprocess_hubert_f0.py --f0_predictor dio

# V√©rification des fichiers g√©n√©r√©s
ls logs/44k/
# Vous devriez voir : 3_feature256/, 3_feature768/, f0/, spec/</pre>
                    </div>

                    <div class="success-box">
                        <h4 class="font-bold text-green-800 mb-2">‚úÖ V√©rification Pr√©processing</h4>
                        <p class="text-green-700">
                            Le pr√©processing est r√©ussi si vous voyez les dossiers "3_feature768", "f0", et "spec" 
                            dans "logs/44k/" avec des fichiers .npy correspondant √† vos audios.
                        </p>
                    </div>
                </div>

                <!-- Lancement de l'entra√Ænement -->
                <div class="mb-8">
                    <div class="flex items-center mb-4">
                        <div class="step-indicator">2</div>
                        <h3 class="text-xl font-bold text-gray-800">Lancement de l'Entra√Ænement</h3>
                    </div>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># Lancement entra√Ænement avec GPU
python train.py -c configs/config.json -m 44k

# Ou avec monitoring tensorboard en parall√®le
tensorboard --logdir=logs/44k --port=6006</pre>
                    </div>

                    <div class="warning-box">
                        <h4 class="font-bold text-yellow-800 mb-2">‚è∞ Temps d'Entra√Ænement</h4>
                        <ul class="list-disc list-inside text-yellow-700 space-y-1">
                            <li><strong>RTX 3060 :</strong> 8-12 heures pour 10k epochs</li>
                            <li><strong>RTX 3080 :</strong> 4-6 heures pour 10k epochs</li>
                            <li><strong>RTX 4090 :</strong> 2-3 heures pour 10k epochs</li>
                            <li><strong>Sauvegarde :</strong> Mod√®le sauv√© toutes les 1000 epochs</li>
                        </ul>
                    </div>
                </div>

                <!-- Monitoring de l'entra√Ænement -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Monitoring de l'Entra√Ænement</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>import torch
import matplotlib.pyplot as plt
import json
from pathlib import Path

def monitor_training_progress(log_dir="logs/44k"):
    """Monitore le progr√®s de l'entra√Ænement"""
    
    # Lecture des logs d'entra√Ænement
    log_file = Path(log_dir) / "train.log"
    
    if not log_file.exists():
        print("‚ùå Fichier de log non trouv√©")
        return
    
    losses = []
    epochs = []
    
    with open(log_file, 'r') as f:
        for line in f:
            if 'loss_gen_all' in line:
                # Extraction loss et epoch
                parts = line.split()
                epoch = int(parts[1].split(':')[0])
                loss = float(parts[3].split(':')[1])
                
                epochs.append(epoch)
                losses.append(loss)
    
    # Graphique du progr√®s
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, losses)
    plt.title('Progression de l\'Entra√Ænement So-VITS-SVC')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.savefig('training_progress.png')
    plt.show()
    
    # Statistiques
    if losses:
        print(f"üéØ Epoch actuel: {epochs[-1]}")
        print(f"üìâ Loss actuelle: {losses[-1]:.4f}")
        print(f"üìà Am√©lioration: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%")
        
        # Estimation du temps restant
        if len(epochs) > 100:
            epoch_per_hour = len(epochs) / (epochs[-1] / 1000)  # Estimation
            remaining_epochs = 10000 - epochs[-1]
            eta_hours = remaining_epochs / (epoch_per_hour * 1000)
            print(f"‚è±Ô∏è  Temps restant estim√©: {eta_hours:.1f} heures")

# Utilisation
monitor_training_progress()</pre>
                    </div>

                    <img src="https://tensorflow.org/tensorboard/images/scalars_step_chart.png" 
                         alt="Monitoring TensorBoard" 
                         class="w-full max-w-lg mx-auto rounded-lg shadow-lg my-4">
                </div>

                <!-- Arr√™t et reprise -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Arr√™t et Reprise d'Entra√Ænement</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># Arr√™t propre de l'entra√Ænement (Ctrl+C dans le terminal)

# Reprise depuis le dernier checkpoint
python train.py -c configs/config.json -m 44k

# Ou reprise depuis un checkpoint sp√©cifique
python train.py -c configs/config.json -m 44k --resume logs/44k/G_5000.pth</pre>
                    </div>
                </div>
            </div>
        </div>

        <!-- Inference Section -->
        <div id="inference" class="tab-content hidden">
            <div class="bg-white rounded-xl shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold text-gray-800 mb-6">
                    <i class="fas fa-magic text-purple-600 mr-3"></i>
                    Inf√©rence et Conversion Vocale
                </h2>

                <!-- Interface Web -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Interface Web (M√©thode Simple)</h3>
                    
                    <p class="text-gray-700 mb-4">
                        La fa√ßon la plus simple d'utiliser So-VITS-SVC est via l'interface web :
                    </p>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># Lancement de l'interface web
python webUI.py

# L'interface sera accessible sur: http://localhost:7860</pre>
                    </div>

                    <div class="success-box">
                        <h4 class="font-bold text-green-800 mb-2">üåê Utilisation Interface Web</h4>
                        <ol class="list-decimal list-inside text-green-700 space-y-1">
                            <li>Ouvrez votre navigateur sur http://localhost:7860</li>
                            <li>S√©lectionnez votre mod√®le dans "Model Path"</li>
                            <li>Uploadez votre fichier audio source</li>
                            <li>Ajustez les param√®tres (pitch, etc.)</li>
                            <li>Cliquez sur "Convert" et t√©l√©chargez le r√©sultat</li>
                        </ol>
                    </div>
                </div>

                <!-- Script d'inf√©rence avanc√© -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Script d'Inf√©rence Avanc√©</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>import torch
import librosa
import soundfile as sf
import numpy as np
from pathlib import Path
from inference import svc_inference

class SoVITSConverter:
    def __init__(self, model_path, config_path, device="cuda"):
        self.device = device
        self.model_path = model_path
        self.config_path = config_path
        self.model = None
        
        # Chargement du mod√®le
        self.load_model()
    
    def load_model(self):
        """Charge le mod√®le So-VITS-SVC"""
        try:
            print(f"üîÑ Chargement mod√®le: {self.model_path}")
            
            # Ici vous int√©grerez le code de chargement sp√©cifique √† So-VITS-SVC
            # (Le code exact d√©pend de la version utilis√©e)
            
            print("‚úÖ Mod√®le charg√© avec succ√®s")
            
        except Exception as e:
            print(f"‚ùå Erreur chargement mod√®le: {e}")
    
    def convert_voice(self, input_audio_path, output_path, 
                     speaker_id=0, pitch_adjust=0, noise_scale=0.4):
        """Convertit la voix d'un fichier audio"""
        
        print(f"üéµ Conversion: {input_audio_path}")
        
        try:
            # 1. Chargement audio source
            audio, sr = librosa.load(input_audio_path, sr=44100)
            
            # 2. Pr√©paration pour l'inf√©rence
            audio_preprocessed = self.preprocess_audio(audio)
            
            # 3. Conversion avec le mod√®le
            converted_audio = self.inference(
                audio_preprocessed, 
                speaker_id=speaker_id,
                pitch_adjust=pitch_adjust,
                noise_scale=noise_scale
            )
            
            # 4. Post-traitement et sauvegarde
            final_audio = self.postprocess_audio(converted_audio)
            sf.write(output_path, final_audio, 44100)
            
            print(f"‚úÖ Conversion termin√©e: {output_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur conversion: {e}")
            return False
    
    def preprocess_audio(self, audio):
        """Pr√©traitement de l'audio pour l'inf√©rence"""
        # Normalisation
        audio = librosa.util.normalize(audio)
        
        # Suppression des silences
        audio, _ = librosa.effects.trim(audio, top_db=20)
        
        return audio
    
    def inference(self, audio, speaker_id=0, pitch_adjust=0, noise_scale=0.4):
        """Effectue l'inf√©rence avec le mod√®le"""
        # Ce code d√©pend de l'impl√©mentation sp√©cifique de So-VITS-SVC
        # Consultez la documentation officielle pour les d√©tails
        
        with torch.no_grad():
            # Conversion du tensor audio
            audio_tensor = torch.from_numpy(audio).float().unsqueeze(0)
            
            if self.device == "cuda":
                audio_tensor = audio_tensor.cuda()
            
            # Inf√©rence (code sp√©cifique au mod√®le)
            # converted = self.model.inference(audio_tensor, speaker_id, pitch_adjust)
            
            # Pour l'exemple, on retourne l'audio original
            converted = audio_tensor.cpu().numpy()[0]
            
        return converted
    
    def postprocess_audio(self, audio):
        """Post-traitement de l'audio converti"""
        # Normalisation finale
        audio = librosa.util.normalize(audio)
        
        # Suppression d'artefacts potentiels
        audio = np.clip(audio, -1.0, 1.0)
        
        return audio
    
    def batch_convert(self, input_folder, output_folder, **kwargs):
        """Conversion par lot de plusieurs fichiers"""
        input_path = Path(input_folder)
        output_path = Path(output_folder)
        output_path.mkdir(exist_ok=True)
        
        audio_files = list(input_path.glob("*.wav")) + list(input_path.glob("*.mp3"))
        
        print(f"üéØ Conversion de {len(audio_files)} fichiers...")
        
        success_count = 0
        for audio_file in audio_files:
            output_file = output_path / f"converted_{audio_file.stem}.wav"
            
            if self.convert_voice(audio_file, output_file, **kwargs):
                success_count += 1
        
        print(f"‚úÖ Conversion termin√©e: {success_count}/{len(audio_files)} r√©ussies")

# Utilisation du convertisseur
if __name__ == "__main__":
    # Configuration
    MODEL_PATH = "logs/44k/G_10000.pth"  # Votre mod√®le entra√Æn√©
    CONFIG_PATH = "configs/config.json"
    
    # Initialisation
    converter = SoVITSConverter(MODEL_PATH, CONFIG_PATH)
    
    # Conversion simple
    converter.convert_voice(
        input_audio_path="test_audio.wav",
        output_path="converted_audio.wav",
        pitch_adjust=2  # Augmente la voix de 2 demi-tons
    )
    
    # Conversion par lot
    converter.batch_convert(
        input_folder="input_audios/",
        output_folder="converted_audios/",
        pitch_adjust=0,
        noise_scale=0.4
    )</pre>
                    </div>
                </div>

                <!-- Interface en ligne de commande -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Inf√©rence en Ligne de Commande</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre># Conversion simple
python inference_main.py \
    -m "logs/44k/G_10000.pth" \
    -c "configs/config.json" \
    -s "leana_mystere" \
    -n "test_audio.wav" \
    -t 0 \
    -f0p "dio"

# Conversion avec ajustement de pitch
python inference_main.py \
    -m "logs/44k/G_10000.pth" \
    -c "configs/config.json" \
    -s "leana_mystere" \
    -n "test_audio.wav" \
    -t 2 \
    -f0p "dio" \
    -o "output_converted.wav"

# Conversion par lot
python inference_main.py \
    -m "logs/44k/G_10000.pth" \
    -c "configs/config.json" \
    -s "leana_mystere" \
    -d "input_folder/" \
    -t 0 \
    -f0p "dio"</pre>
                    </div>

                    <div class="warning-box">
                        <h4 class="font-bold text-yellow-800 mb-2">üéõÔ∏è Param√®tres Importants</h4>
                        <ul class="list-disc list-inside text-yellow-700 space-y-1">
                            <li><strong>-t (transpose) :</strong> Ajustement pitch (-12 √† +12 demi-tons)</li>
                            <li><strong>-f0p :</strong> M√©thode extraction F0 (dio, harvest, crepe)</li>
                            <li><strong>-cr :</strong> Ratio de clustering (0.0 √† 1.0)</li>
                            <li><strong>-ns :</strong> Noise scale (0.1 √† 1.0)</li>
                        </ul>
                    </div>
                </div>

                <!-- Qualit√© et optimisation -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Optimisation de la Qualit√©</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>def optimize_conversion_quality(converter, test_audio):
    """Trouve les meilleurs param√®tres pour un audio donn√©"""
    
    best_params = {}
    best_score = 0
    
    # Test diff√©rents param√®tres
    noise_scales = [0.2, 0.4, 0.6, 0.8]
    pitch_adjusts = [-2, -1, 0, 1, 2]
    
    print("üîç Optimisation des param√®tres...")
    
    for noise in noise_scales:
        for pitch in pitch_adjusts:
            # Conversion avec param√®tres actuels
            output_file = f"temp_test_{noise}_{pitch}.wav"
            
            success = converter.convert_voice(
                test_audio, 
                output_file,
                pitch_adjust=pitch,
                noise_scale=noise
            )
            
            if success:
                # √âvaluation qualit√© (ici simplifi√©e)
                score = evaluate_audio_quality(output_file)
                
                if score > best_score:
                    best_score = score
                    best_params = {
                        'noise_scale': noise,
                        'pitch_adjust': pitch,
                        'score': score
                    }
                
                # Suppression fichier temporaire
                os.remove(output_file)
    
    print(f"‚úÖ Meilleurs param√®tres trouv√©s: {best_params}")
    return best_params

def evaluate_audio_quality(audio_file):
    """√âvalue la qualit√© d'un fichier audio (m√©trique simple)"""
    audio, sr = librosa.load(audio_file, sr=44100)
    
    # Calculs de m√©triques simples
    rms = np.sqrt(np.mean(audio**2))
    zcr = np.mean(librosa.feature.zero_crossing_rate(audio))
    spectral_centroid = np.mean(librosa.feature.spectral_centroid(audio, sr=sr))
    
    # Score composite (√† ajuster selon vos crit√®res)
    score = rms * 0.5 + (1.0 - zcr) * 0.3 + (spectral_centroid / 10000) * 0.2
    
    return score</pre>
                    </div>
                </div>
            </div>
        </div>

        <!-- Optimisation Section -->
        <div id="optimisation" class="tab-content hidden">
            <div class="bg-white rounded-xl shadow-lg p-8 mb-8">
                <h2 class="text-3xl font-bold text-gray-800 mb-6">
                    <i class="fas fa-tachometer-alt text-orange-600 mr-3"></i>
                    Optimisation & Performance
                </h2>

                <!-- Optimisation GPU -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Optimisation GPU</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>import torch
import gc

class GPUOptimizer:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
    def optimize_gpu_settings(self):
        """Optimise les param√®tres GPU pour So-VITS-SVC"""
        
        if torch.cuda.is_available():
            print(f"üéÆ GPU d√©tect√©: {torch.cuda.get_device_name(0)}")
            
            # Activation optimisations PyTorch
            torch.backends.cudnn.benchmark = True
            torch.backends.cudnn.deterministic = False
            
            # Optimisation m√©moire
            torch.cuda.empty_cache()
            
            # Configuration mixed precision
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            
            # Affichage m√©moire disponible
            total_memory = torch.cuda.get_device_properties(0).total_memory
            allocated = torch.cuda.memory_allocated(0)
            cached = torch.cuda.memory_reserved(0)
            
            print(f"üíæ M√©moire GPU totale: {total_memory / 1e9:.1f} GB")
            print(f"üíæ M√©moire allou√©e: {allocated / 1e9:.1f} GB")
            print(f"üíæ M√©moire en cache: {cached / 1e9:.1f} GB")
            
            return True
        else:
            print("‚ùå Aucun GPU CUDA disponible")
            return False
    
    def monitor_gpu_usage(self):
        """Monitore l'utilisation GPU en temps r√©el"""
        import time
        import psutil
        
        while True:
            if torch.cuda.is_available():
                # M√©moire GPU
                allocated = torch.cuda.memory_allocated(0) / 1e9
                cached = torch.cuda.memory_reserved(0) / 1e9
                
                # Utilisation CPU
                cpu_percent = psutil.cpu_percent(interval=1)
                
                # RAM syst√®me
                ram = psutil.virtual_memory()
                ram_used = ram.used / 1e9
                ram_total = ram.total / 1e9
                
                print(f"üéÆ GPU: {allocated:.1f}GB | üñ•Ô∏è  CPU: {cpu_percent:.1f}% | üíæ RAM: {ram_used:.1f}/{ram_total:.1f}GB")
                
            time.sleep(5)
    
    def clear_gpu_memory(self):
        """Nettoie la m√©moire GPU"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
            print("üßπ M√©moire GPU nettoy√©e")

# Utilisation
optimizer = GPUOptimizer()
optimizer.optimize_gpu_settings()</pre>
                    </div>
                </div>

                <!-- Optimisation inference -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Optimisation Inf√©rence</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>class FastInference:
    def __init__(self, model_path, config_path):
        self.model = self.load_optimized_model(model_path, config_path)
        
    def load_optimized_model(self, model_path, config_path):
        """Charge le mod√®le avec optimisations"""
        
        # Chargement avec optimisations
        model = torch.jit.load(model_path) if model_path.endswith('.pt') else None
        
        if model and torch.cuda.is_available():
            model = model.cuda()
            model = model.half()  # Precision FP16 pour plus de vitesse
            model.eval()
            
            # Compilation JIT pour optimisation
            with torch.no_grad():
                # Warmup avec dummy input
                dummy_input = torch.randn(1, 80, 100).cuda().half()
                _ = model(dummy_input)
                
        return model
    
    def fast_batch_inference(self, audio_list, batch_size=4):
        """Inf√©rence par batch pour plus d'efficacit√©"""
        
        results = []
        
        for i in range(0, len(audio_list), batch_size):
            batch = audio_list[i:i+batch_size]
            
            # Pr√©paration batch
            batch_tensors = []
            for audio in batch:
                tensor = self.preprocess_audio_fast(audio)
                batch_tensors.append(tensor)
            
            # Padding pour taille uniforme
            max_len = max(t.shape[-1] for t in batch_tensors)
            padded_batch = []
            
            for tensor in batch_tensors:
                pad_size = max_len - tensor.shape[-1]
                if pad_size > 0:
                    tensor = torch.nn.functional.pad(tensor, (0, pad_size))
                padded_batch.append(tensor)
            
            # Inf√©rence batch
            batch_input = torch.stack(padded_batch)
            
            with torch.no_grad():
                batch_output = self.model(batch_input)
            
            # Extraction des r√©sultats individuels
            for j, output in enumerate(batch_output):
                original_len = batch_tensors[j].shape[-1]
                result = output[:, :original_len]
                results.append(result.cpu().numpy())
        
        return results
    
    def preprocess_audio_fast(self, audio):
        """Pr√©processing audio optimis√©"""
        # Conversion rapide en tensor
        if isinstance(audio, np.ndarray):
            tensor = torch.from_numpy(audio).float()
        else:
            tensor = audio
        
        # Normalisation rapide
        tensor = tensor / torch.max(torch.abs(tensor))
        
        # GPU + half precision
        if torch.cuda.is_available():
            tensor = tensor.cuda().half()
        
        return tensor.unsqueeze(0)

# Configuration optimis√©e pour inf√©rence rapide
def setup_fast_inference():
    """Configuration pour inf√©rence rapide"""
    
    # Variables d'environnement pour optimisation
    import os
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'
    os.environ['TORCH_CUDNN_V8_API_ENABLED'] = '1'
    
    # Optimisations PyTorch
    torch.set_num_threads(4)  # Ajustez selon votre CPU
    torch.set_grad_enabled(False)  # Pas de gradient pour l'inf√©rence
    
    print("‚ö° Configuration rapide activ√©e")</pre>
                    </div>
                </div>

                <!-- Benchmarking -->
                <div class="mb-8">
                    <h3 class="text-xl font-bold text-gray-800 mb-4">Benchmarking Performance</h3>
                    
                    <div class="code-block">
                        <button class="copy-btn" onclick="copyCode(this)">
                            <i class="fas fa-copy"></i> Copier
                        </button>
<pre>import time
import statistics

class SoVITSBenchmark:
    def __init__(self, converter):
        self.converter = converter
        self.results = {}
    
    def benchmark_inference_speed(self, test_audios, num_runs=5):
        """Benchmark de la vitesse d'inf√©rence"""
        
        print(f"‚è±Ô∏è  Benchmark sur {len(test_audios)} audios, {num_runs} runs...")
        
        all_times = []
        
        for run in range(num_runs):
            run_times = []
            
            for i, audio_path in enumerate(test_audios):
                start_time = time.time()
                
                # Conversion
                output_path = f"benchmark_output_{run}_{i}.wav"
                success = self.converter.convert_voice(audio_path, output_path)
                
                end_time = time.time()
                conversion_time = end_time - start_time
                
                if success:
                    run_times.append(conversion_time)
                    # Suppression fichier temporaire
                    os.remove(output_path)
            
            all_times.extend(run_times)
            print(f"Run {run+1}: {statistics.mean(run_times):.2f}s moyen")
        
        # Statistiques finales
        avg_time = statistics.mean(all_times)
        min_time = min(all_times)
        max_time = max(all_times)
        std_dev = statistics.stdev(all_times)
        
        self.results['inference_speed'] = {
            'average': avg_time,
            'minimum': min_time,
            'maximum': max_time,
            'std_dev': std_dev,
            'samples': len(all_times)
        }
        
        print(f"\nüìä R√©sultats Benchmark:")
        print(f"‚è±Ô∏è  Temps moyen: {avg_time:.2f}s")
        print(f"‚ö° Temps minimum: {min_time:.2f}s")
        print(f"üêå Temps maximum: {max_time:.2f}s")
        print(f"üìà √âcart-type: {std_dev:.2f}s")
        
        return self.results
    
    def benchmark_gpu_utilization(self, duration_minutes=5):
        """Benchmark utilisation GPU"""
        
        print(f"üéÆ Benchmark GPU pendant {duration_minutes} minutes...")
        
        gpu_usage = []
        memory_usage = []
        
        start_time = time.time()
        end_time = start_time + (duration_minutes * 60)
        
        while time.time() < end_time:
            if torch.cuda.is_available():
                # Utilisation m√©moire
                allocated = torch.cuda.memory_allocated(0) / 1e9
                reserved = torch.cuda.memory_reserved(0) / 1e9
                
                memory_usage.append(allocated)
                
                print(f"üíæ M√©moire GPU: {allocated:.1f}GB / {reserved:.1f}GB")
            
            time.sleep(10)
        
        # R√©sultats
        if memory_usage:
            avg_memory = statistics.mean(memory_usage)
            max_memory = max(memory_usage)
            
            self.results['gpu_usage'] = {
                'average_memory': avg_memory,
                'peak_memory': max_memory,
                'samples': len(memory_usage)
            }
            
            print(f"\nüéÆ Utilisation GPU:")
            print(f"üíæ M√©moire moyenne: {avg_memory:.1f}GB")
            print(f"üî∫ Pic m√©moire: {max_memory:.1f}GB")
    
    def generate_performance_report(self):
        """G√©n√®re un rapport de performance complet"""
        
        report = f"""
üìä RAPPORT DE PERFORMANCE SO-VITS-SVC
{'='*50}

‚è±Ô∏è  VITESSE D'INF√âRENCE:
   ‚Ä¢ Temps moyen: {self.results.get('inference_speed', {}).get('average', 'N/A')}s
   ‚Ä¢ Temps minimum: {self.results.get('inference_speed', {}).get('minimum', 'N/A')}s
   ‚Ä¢ Temps maximum: {self.results.get('inference_speed', {}).get('maximum', 'N/A')}s

üéÆ UTILISATION GPU:
   ‚Ä¢ M√©moire moyenne: {self.results.get('gpu_usage', {}).get('average_memory', 'N/A')}GB
   ‚Ä¢ Pic m√©moire: {self.results.get('gpu_usage', {}).get('peak_memory', 'N/A')}GB

üí° RECOMMANDATIONS:
   ‚Ä¢ Utilisez batch inference pour traiter plusieurs audios
   ‚Ä¢ Activez FP16 precision pour gagner en vitesse
   ‚Ä¢ Surveillez l'utilisation m√©moire pour √©viter l'OOM
        """
        
        print(report)
        
        # Sauvegarde rapport
        with open('sovits_performance_report.txt', 'w') as f:
            f.write(report)
        
        return report

# Utilisation
# benchmark = SoVITSBenchmark(converter)
# benchmark.benchmark_inference_speed(['test1.wav', 'test2.wav'])
# benchmark.generate_performance_report()</pre>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer class="bg-gray-800 text-white py-12 mt-16">
        <div class="container mx-auto px-6">
            <div class="text-center">
                <div class="mb-6">
                    <i class="fas fa-microphone-alt text-4xl mb-4"></i>
                </div>
                <h3 class="text-2xl font-bold mb-4">Bloc 11.3 Termin√©</h3>
                <p class="text-gray-300 mb-6">
                    So-VITS-SVC Professional ma√Ætris√© ‚Ä¢ Conversion vocale haute qualit√© ‚Ä¢ Optimisation compl√®te
                </p>
                
                <div class="grid grid-cols-1 md:grid-cols-4 gap-6 text-sm">
                    <div>
                        <h4 class="font-bold mb-2">Installation</h4>
                        <p class="text-gray-400">Configuration environnement compl√®te</p>
                    </div>
                    <div>
                        <h4 class="font-bold mb-2">Entra√Ænement</h4>
                        <p class="text-gray-400">Mod√®le personnalis√© haute qualit√©</p>
                    </div>
                    <div>
                        <h4 class="font-bold mb-2">Inf√©rence</h4>
                        <p class="text-gray-400">Conversion vocale professionnelle</p>
                    </div>
                    <div>
                        <h4 class="font-bold mb-2">Optimisation</h4>
                        <p class="text-gray-400">Performance maximale GPU</p>
                    </div>
                </div>
                
                <div class="mt-8 text-xs text-gray-500">
                    So-VITS-SVC 4.0 ‚Ä¢ Technique avanc√©e ‚Ä¢ Guide complet d√©butant
                </div>
            </div>
        </div>
    </footer>

    <script>
        // Navigation par onglets
        document.addEventListener('DOMContentLoaded', function() {
            const tabBtns = document.querySelectorAll('.tab-btn');
            const tabContents = document.querySelectorAll('.tab-content');
            
            tabBtns.forEach(btn => {
                btn.addEventListener('click', function() {
                    const targetTab = this.getAttribute('data-tab');
                    
                    // Reset tous les onglets
                    tabBtns.forEach(b => {
                        b.classList.remove('border-blue-500', 'text-blue-600');
                        b.classList.add('text-gray-500');
                    });
                    
                    tabContents.forEach(content => {
                        content.classList.add('hidden');
                    });
                    
                    // Activer l'onglet s√©lectionn√©
                    this.classList.add('border-blue-500', 'text-blue-600');
                    this.classList.remove('text-gray-500');
                    
                    document.getElementById(targetTab).classList.remove('hidden');
                });
            });
        });

        // Fonction de copie de code
        function copyCode(button) {
            const codeBlock = button.parentNode;
            const code = codeBlock.querySelector('pre').textContent;
            
            navigator.clipboard.writeText(code).then(function() {
                button.innerHTML = '<i class="fas fa-check"></i> Copi√©';
                button.style.background = '#10b981';
                
                setTimeout(function() {
                    button.innerHTML = '<i class="fas fa-copy"></i> Copier';
                    button.style.background = '#4a5568';
                }, 2000);
            });
        }

        // Accord√©ons
        document.addEventListener('DOMContentLoaded', function() {
            const accordionBtns = document.querySelectorAll('.accordion-btn');
            
            accordionBtns.forEach(btn => {
                btn.addEventListener('click', function() {
                    const content = this.nextElementSibling;
                    const icon = this.querySelector('i');
                    
                    if (content.classList.contains('active')) {
                        content.classList.remove('active');
                        icon.style.transform = 'rotate(0deg)';
                    } else {
                        content.classList.add('active');
                        icon.style.transform = 'rotate(90deg)';
                    }
                });
            });
        });
    </script>
<script defer src="https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon='{"rayId":"950e6833c92a250f","serverTiming":{"name":{"cfExtPri":true,"cfEdge":true,"cfOrigin":true,"cfL4":true,"cfSpeedBrain":true,"cfCacheStatus":true}},"version":"2025.6.2","token":"4edd5f8ec12a48cfa682ab8261b80a79"}' crossorigin="anonymous"></script>
</body>
</html>
    <script id="html_badge_script1">
        window.__genspark_remove_badge_link = "https://www.genspark.ai/api/html_badge/" +
            "remove_badge?token=To%2FBnjzloZ3UfQdcSaYfDrURjeZq84d2g2M9wO5hRoHKuDsPxn66H0oEQaORw09fYqL%2BH7SUYiUj8omgntEluwtJDniAH4jA6Rk1%2Bth2qe9hPbaJIGMG1YvIkQ76btJRjG2fcVCk11W5Vf0Khfu2PKz7pdRBmVNRMzNc3IEfbWrXUxbVSV8NLjuUVxxOY8PDJVm78ewgjmc%2Fg4wbgJFCcToqmOfK9vnj7Wd172l2u5CI6nZFTXUmYRtsZAAl0IK3HZ2F%2B%2FFd6HctNoKrl614hKlEjKvSCkuNmmmv9BtDmk8ACmU%2Bf17dpYvfMXTC%2BaDnjH3SegxVgJ9l4IJGQe1itFHuPl3Ro5wx%2Bx8A8Tb4H5tCCf7dFz5M1kNIQmp%2Fq1wf1QFhyn5K2EsGJHwjch8h46TqX5Jl4bMHlYFHqeqybi8IjTFG1B0JGIDcc4r1F0AGMNsYNKGF03qvvFN6J3y6eDphVI057v6Zx2FfuK80UVIrawvBb4ZPqr2bf9HSZyiEyDY82xmEkqse3DC2mdH%2B6eU67a1AmMw1WdG%2FYWoUW1KOWqES6KLKVZ6uil93BAdD";
        window.__genspark_locale = "fr-FR";
        window.__genspark_token = "To/BnjzloZ3UfQdcSaYfDrURjeZq84d2g2M9wO5hRoHKuDsPxn66H0oEQaORw09fYqL+H7SUYiUj8omgntEluwtJDniAH4jA6Rk1+th2qe9hPbaJIGMG1YvIkQ76btJRjG2fcVCk11W5Vf0Khfu2PKz7pdRBmVNRMzNc3IEfbWrXUxbVSV8NLjuUVxxOY8PDJVm78ewgjmc/g4wbgJFCcToqmOfK9vnj7Wd172l2u5CI6nZFTXUmYRtsZAAl0IK3HZ2F+/Fd6HctNoKrl614hKlEjKvSCkuNmmmv9BtDmk8ACmU+f17dpYvfMXTC+aDnjH3SegxVgJ9l4IJGQe1itFHuPl3Ro5wx+x8A8Tb4H5tCCf7dFz5M1kNIQmp/q1wf1QFhyn5K2EsGJHwjch8h46TqX5Jl4bMHlYFHqeqybi8IjTFG1B0JGIDcc4r1F0AGMNsYNKGF03qvvFN6J3y6eDphVI057v6Zx2FfuK80UVIrawvBb4ZPqr2bf9HSZyiEyDY82xmEkqse3DC2mdH+6eU67a1AmMw1WdG/YWoUW1KOWqES6KLKVZ6uil93BAdD";
    </script>
    
    <script id="html_notice_dialog_script" src="https://www.genspark.ai/notice_dialog.js"></script>
    