<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Manuel IA MYM 2025 - BLOC 11.6 - Post-Traitement Audio Avancé</title>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
    <style>
        .gradient-bg {
            background: linear-gradient(135deg, #8B5CF6 0%, #06B6D4 50%, #10B981 100%);
        }
        .card-hover {
            transition: all 0.3s ease;
        }
        .card-hover:hover {
            transform: translateY(-2px);
            box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
        }
        .code-block {
            background: #1a1a1a;
            border-radius: 8px;
            padding: 16px;
            margin: 16px 0;
            position: relative;
        }
        .copy-btn {
            position: absolute;
            top: 10px;
            right: 10px;
            background: #4F46E5;
            color: white;
            border: none;
            padding: 5px 10px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
        }
        .copy-btn:hover {
            background: #4338CA;
        }
        .warning-box {
            border-left: 4px solid #F59E0B;
            background: #FEF3C7;
            padding: 16px;
            margin: 16px 0;
        }
        .success-box {
            border-left: 4px solid #10B981;
            background: #D1FAE5;
            padding: 16px;
            margin: 16px 0;
        }
        .info-box {
            border-left: 4px solid #3B82F6;
            background: #DBEAFE;
            padding: 16px;
            margin: 16px 0;
        }
        .step-number {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            margin-right: 12px;
        }
        .audio-waveform {
            background: linear-gradient(90deg, #3B82F6, #06B6D4, #10B981);
            height: 60px;
            border-radius: 4px;
            position: relative;
            overflow: hidden;
        }
        .waveform-bars {
            display: flex;
            height: 100%;
            align-items: end;
            justify-content: space-around;
            padding: 8px;
        }
        .waveform-bar {
            background: rgba(255,255,255,0.8);
            width: 3px;
            border-radius: 2px;
            animation: waveform 2s ease-in-out infinite;
        }
        @keyframes waveform {
            0%, 100% { height: 20%; }
            50% { height: 90%; }
        }
        .eq-band {
            background: linear-gradient(180deg, #8B5CF6, #06B6D4);
            width: 40px;
            margin: 0 4px;
            border-radius: 4px;
            position: relative;
            cursor: pointer;
        }
        .eq-slider {
            background: #fff;
            border: 2px solid #4F46E5;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            cursor: grab;
        }
        .freq-label {
            text-align: center;
            font-size: 10px;
            margin-top: 4px;
        }
    </style>
</head>
<body class="bg-gray-50">

    <!-- Header -->
    <header class="gradient-bg text-white py-16">
        <div class="container mx-auto px-6">
            <div class="text-center">
                <div class="mb-6">
                    <i class="fas fa-volume-up text-6xl mb-4"></i>
                </div>
                <h1 class="text-5xl font-bold mb-4">BLOC 11.6 - Post-Traitement Audio Avancé</h1>
                <h2 class="text-2xl font-light mb-6">Nettoyage, Égalisation & Effets Réalistes</h2>
                <p class="text-xl max-w-4xl mx-auto leading-relaxed">
                    Maîtrisez les techniques professionnelles de post-traitement audio pour transformer vos clonages vocaux 
                    en productions studio de qualité industrielle. Ajout d'effets réalistes, nettoyage avancé et mixage professionnel.
                </p>
                <div class="mt-8 flex justify-center space-x-4">
                    <span class="bg-white bg-opacity-20 rounded-full px-6 py-2 text-sm font-medium">
                        <i class="fas fa-microphone mr-2"></i>Post-Traitement Pro
                    </span>
                    <span class="bg-white bg-opacity-20 rounded-full px-6 py-2 text-sm font-medium">
                        <i class="fas fa-sliders-h mr-2"></i>Égalisation Avancée
                    </span>
                    <span class="bg-white bg-opacity-20 rounded-full px-6 py-2 text-sm font-medium">
                        <i class="fas fa-magic mr-2"></i>Effets Réalistes
                    </span>
                </div>
            </div>
        </div>
    </header>

    <!-- Navigation -->
    <nav class="bg-white shadow-lg sticky top-0 z-50">
        <div class="container mx-auto px-6">
            <div class="flex justify-center">
                <div class="flex space-x-8 py-4">
                    <a href="#nettoyage" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-broom mr-2"></i>Nettoyage Audio
                    </a>
                    <a href="#equalisation" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-sliders-h mr-2"></i>Égalisation
                    </a>
                    <a href="#effets" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-magic mr-2"></i>Effets Réalistes
                    </a>
                    <a href="#mixage" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-volume-up mr-2"></i>Mixage Avancé
                    </a>
                    <a href="#automation" class="text-gray-600 hover:text-blue-600 font-medium transition duration-300">
                        <i class="fas fa-robot mr-2"></i>Automation
                    </a>
                </div>
            </div>
        </div>
    </nav>

    <!-- Objectif du Bloc -->
    <section class="py-16 bg-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-target mr-3 text-purple-600"></i>
                    Objectif Stratégique du Bloc 11.6
                </h3>
                <p class="text-gray-600 text-lg max-w-4xl mx-auto">
                    Transformer vos clonages vocaux bruts en productions audio professionnelles indiscernables 
                    d'enregistrements studio réels, avec tous les détails et nuances d'une voix humaine naturelle.
                </p>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-8">
                <div class="text-center">
                    <div class="bg-gradient-to-br from-blue-500 to-purple-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-broom text-white text-xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Nettoyage Professionnel</h4>
                    <p class="text-gray-600 text-sm">Suppression bruit, clics, artefacts numériques</p>
                </div>
                <div class="text-center">
                    <div class="bg-gradient-to-br from-green-500 to-blue-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-sliders-h text-white text-xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Égalisation Expert</h4>
                    <p class="text-gray-600 text-sm">EQ multi-bandes, correction formants</p>
                </div>
                <div class="text-center">
                    <div class="bg-gradient-to-br from-purple-500 to-pink-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-magic text-white text-xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Effets Réalistes</h4>
                    <p class="text-gray-600 text-sm">Respirations, hésitations, micro-détails</p>
                </div>
                <div class="text-center">
                    <div class="bg-gradient-to-br from-red-500 to-orange-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-robot text-white text-xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Automation Complète</h4>
                    <p class="text-gray-600 text-sm">Scripts Python automatisés</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 1: Nettoyage Audio Professionnel -->
    <section id="nettoyage" class="py-16 bg-gray-50">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-broom mr-3 text-blue-600"></i>
                    Nettoyage Audio Professionnel
                </h3>
                <p class="text-gray-600 text-lg">Suppression des artefacts, bruit de fond et imperfections numériques</p>
            </div>

            <!-- Visualiseur Audio Avant/Après -->
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-12">
                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-red-600">
                        <i class="fas fa-times-circle mr-2"></i>Avant Nettoyage
                    </h4>
                    <div class="audio-waveform mb-4" style="background: linear-gradient(90deg, #EF4444, #F97316, #EAB308);">
                        <div class="waveform-bars">
                            <div class="waveform-bar" style="height: 80%; animation-delay: 0s;"></div>
                            <div class="waveform-bar" style="height: 30%; animation-delay: 0.1s;"></div>
                            <div class="waveform-bar" style="height: 90%; animation-delay: 0.2s;"></div>
                            <div class="waveform-bar" style="height: 10%; animation-delay: 0.3s;"></div>
                            <div class="waveform-bar" style="height: 70%; animation-delay: 0.4s;"></div>
                            <div class="waveform-bar" style="height: 95%; animation-delay: 0.5s;"></div>
                            <div class="waveform-bar" style="height: 40%; animation-delay: 0.6s;"></div>
                            <div class="waveform-bar" style="height: 85%; animation-delay: 0.7s;"></div>
                        </div>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li><i class="fas fa-exclamation-triangle text-red-500 mr-2"></i>Bruit de fond constant</li>
                        <li><i class="fas fa-exclamation-triangle text-red-500 mr-2"></i>Clics et pops audibles</li>
                        <li><i class="fas fa-exclamation-triangle text-red-500 mr-2"></i>Artefacts de compression</li>
                        <li><i class="fas fa-exclamation-triangle text-red-500 mr-2"></i>Distorsion numérique</li>
                    </ul>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-green-600">
                        <i class="fas fa-check-circle mr-2"></i>Après Nettoyage
                    </h4>
                    <div class="audio-waveform mb-4">
                        <div class="waveform-bars">
                            <div class="waveform-bar" style="height: 75%; animation-delay: 0s;"></div>
                            <div class="waveform-bar" style="height: 45%; animation-delay: 0.1s;"></div>
                            <div class="waveform-bar" style="height: 85%; animation-delay: 0.2s;"></div>
                            <div class="waveform-bar" style="height: 25%; animation-delay: 0.3s;"></div>
                            <div class="waveform-bar" style="height: 65%; animation-delay: 0.4s;"></div>
                            <div class="waveform-bar" style="height: 80%; animation-delay: 0.5s;"></div>
                            <div class="waveform-bar" style="height: 50%; animation-delay: 0.6s;"></div>
                            <div class="waveform-bar" style="height: 70%; animation-delay: 0.7s;"></div>
                        </div>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-1">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Signal propre et clair</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Bruit de fond supprimé</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Dynamique préservée</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Qualité studio</li>
                    </ul>
                </div>
            </div>

            <!-- Script Python Nettoyage Professionnel -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-blue-600"></i>
                    Script Python - Nettoyage Audio Professionnel
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('nettoyage-code')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="nettoyage-code" class="text-green-400 text-sm overflow-x-auto"><code>import librosa
import numpy as np
import scipy.signal
from scipy.io import wavfile
import noisereduce as nr
from pydub import AudioSegment
import matplotlib.pyplot as plt

class ProfessionalAudioCleaner:
    def __init__(self):
        self.sample_rate = 44100
        self.original_audio = None
        self.cleaned_audio = None
        
    def load_audio(self, file_path):
        """Chargement audio avec préservation qualité maximale"""
        print(f"📂 Chargement: {file_path}")
        
        # Chargement haute qualité avec librosa
        self.original_audio, self.sample_rate = librosa.load(
            file_path, sr=None, mono=False
        )
        
        print(f"✅ Audio chargé: {self.sample_rate}Hz, {len(self.original_audio)} échantillons")
        return self.original_audio
    
    def advanced_noise_reduction(self, audio, noise_sample_start=0, noise_sample_duration=1.0):
        """Réduction bruit avancée avec profil adaptatif"""
        print("🔧 Réduction bruit avancée...")
        
        # 1. Estimation profil bruit sur échantillon silencieux
        noise_start_sample = int(noise_sample_start * self.sample_rate)
        noise_end_sample = int((noise_sample_start + noise_sample_duration) * self.sample_rate)
        
        if noise_end_sample < len(audio):
            noise_profile = audio[noise_start_sample:noise_end_sample]
        else:
            # Utilisation des 10% premiers échantillons comme profil bruit
            noise_profile = audio[:int(len(audio) * 0.1)]
        
        # 2. Réduction bruit spectrale
        reduced_noise = nr.reduce_noise(
            y=audio, 
            sr=self.sample_rate,
            stationary=False,  # Bruit non-stationnaire
            prop_decrease=0.8  # Réduction agressive mais préservation voix
        )
        
        # 3. Filtrage passe-haut pour voix humaine (80Hz+)
        nyquist = self.sample_rate // 2
        low_cutoff = 80 / nyquist
        b, a = scipy.signal.butter(4, low_cutoff, btype='high')
        filtered_audio = scipy.signal.filtfilt(b, a, reduced_noise)
        
        print("✅ Réduction bruit terminée")
        return filtered_audio
    
    def remove_clicks_and_pops(self, audio, threshold=0.01):
        """Suppression clics et pops avec détection automatique"""
        print("🔧 Suppression clics et pops...")
        
        # 1. Détection des pics anormaux
        diff = np.abs(np.diff(audio))
        mean_diff = np.mean(diff)
        click_threshold = mean_diff + (threshold * np.max(diff))
        
        click_indices = np.where(diff > click_threshold)[0]
        
        # 2. Réparation par interpolation
        cleaned_audio = audio.copy()
        for idx in click_indices:
            if idx > 5 and idx < len(audio) - 5:
                # Interpolation linéaire sur 11 échantillons
                start_val = audio[idx - 5]
                end_val = audio[idx + 5]
                interpolated = np.linspace(start_val, end_val, 11)
                cleaned_audio[idx-5:idx+6] = interpolated
        
        print(f"✅ {len(click_indices)} clics supprimés")
        return cleaned_audio
    
    def normalize_dynamic_range(self, audio, target_lufs=-23.0):
        """Normalisation intelligente selon standards diffusion"""
        print("🔧 Normalisation dynamique...")
        
        # 1. Calcul RMS pour normalisation énergétique
        rms = np.sqrt(np.mean(audio**2))
        
        # 2. Normalisation peak à -3dB pour headroom
        peak_normalized = audio / np.max(np.abs(audio)) * 0.707  # -3dB
        
        # 3. Compression douce pour consistance
        # Simulation compresseur avec ratio 3:1
        threshold = 0.5
        ratio = 3.0
        
        compressed = np.where(
            np.abs(peak_normalized) > threshold,
            np.sign(peak_normalized) * (
                threshold + (np.abs(peak_normalized) - threshold) / ratio
            ),
            peak_normalized
        )
        
        # 4. Normalisation finale LUFS (simulation)
        final_gain = target_lufs / -23.0  # Approximation
        final_audio = compressed * final_gain
        
        print("✅ Normalisation terminée")
        return final_audio
    
    def spectral_repair(self, audio, freq_threshold=8000):
        """Réparation spectrale pour artefacts hautes fréquences"""
        print("🔧 Réparation spectrale...")
        
        # 1. Transformation STFT
        stft = librosa.stft(audio, n_fft=2048, hop_length=512)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        
        # 2. Détection et correction artefacts HF
        freq_bins = librosa.fft_frequencies(sr=self.sample_rate, n_fft=2048)
        high_freq_mask = freq_bins > freq_threshold
        
        # 3. Réduction douce des artefacts HF
        magnitude[high_freq_mask] *= 0.7
        
        # 4. Reconstruction
        repaired_stft = magnitude * np.exp(1j * phase)
        repaired_audio = librosa.istft(repaired_stft, hop_length=512)
        
        print("✅ Réparation spectrale terminée")
        return repaired_audio
    
    def complete_professional_cleaning(self, input_file, output_file):
        """Pipeline complet de nettoyage professionnel"""
        print("🎵 DÉMARRAGE NETTOYAGE PROFESSIONNEL")
        print("=" * 50)
        
        # 1. Chargement
        audio = self.load_audio(input_file)
        
        # 2. Séquence de nettoyage optimisée
        step1 = self.advanced_noise_reduction(audio)
        step2 = self.remove_clicks_and_pops(step1)
        step3 = self.spectral_repair(step2)
        step4 = self.normalize_dynamic_range(step3)
        
        # 3. Sauvegarde haute qualité
        self.cleaned_audio = step4
        wavfile.write(output_file, self.sample_rate, 
                     (step4 * 32767).astype(np.int16))
        
        print("=" * 50)
        print(f"✅ NETTOYAGE TERMINÉ: {output_file}")
        
        # 4. Statistiques de nettoyage
        self.print_cleaning_stats()
        
        return step4
    
    def print_cleaning_stats(self):
        """Affichage statistiques de nettoyage"""
        if self.original_audio is not None and self.cleaned_audio is not None:
            original_rms = np.sqrt(np.mean(self.original_audio**2))
            cleaned_rms = np.sqrt(np.mean(self.cleaned_audio**2))
            
            print("\n📊 STATISTIQUES NETTOYAGE:")
            print(f"   RMS Original: {original_rms:.4f}")
            print(f"   RMS Nettoyé: {cleaned_rms:.4f}")
            print(f"   Amélioration SNR: {20*np.log10(cleaned_rms/original_rms):.2f} dB")

# ===============================================
# UTILISATION PRATIQUE
# ===============================================

def nettoyer_audio_clonage_vocal():
    """Pipeline optimisé pour clonage vocal"""
    
    cleaner = ProfessionalAudioCleaner()
    
    # Fichiers d'entrée et sortie
    input_file = "voice_clone_raw.wav"
    output_file = "voice_clone_professional.wav"
    
    # Nettoyage complet
    cleaned_audio = cleaner.complete_professional_cleaning(
        input_file, output_file
    )
    
    print("\n🎯 NETTOYAGE VOCAL TERMINÉ")
    print("📁 Fichier prêt pour post-traitement avancé")
    
    return output_file

# Exécution
if __name__ == "__main__":
    nettoyer_audio_clonage_vocal()</code></pre>
                </div>
            </div>

            <!-- Instructions Step-by-Step -->
            <div class="bg-white rounded-xl shadow-lg p-6">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-list-ol mr-2 text-purple-600"></i>
                    Instructions Step-by-Step - Nettoyage Audio
                </h4>

                <div class="space-y-6">
                    <div class="flex items-start">
                        <div class="step-number">1</div>
                        <div>
                            <h5 class="font-bold mb-2">Installation des Dépendances</h5>
                            <div class="code-block">
                                <button class="copy-btn" onclick="copyCode('install-deps')">
                                    <i class="fas fa-copy mr-1"></i>Copier
                                </button>
                                <pre id="install-deps" class="text-green-400 text-sm"><code>pip install librosa numpy scipy noisereduce pydub matplotlib soundfile</code></pre>
                            </div>
                            <p class="text-gray-600 text-sm mt-2">Installez toutes les bibliothèques audio nécessaires pour le traitement professionnel.</p>
                        </div>
                    </div>

                    <div class="flex items-start">
                        <div class="step-number">2</div>
                        <div>
                            <h5 class="font-bold mb-2">Préparation du Fichier Audio</h5>
                            <p class="text-gray-600 mb-2">Placez votre fichier audio brut dans le même dossier que le script :</p>
                            <ul class="list-disc ml-6 text-sm text-gray-600">
                                <li>Format recommandé : WAV 44.1kHz 16-bit minimum</li>
                                <li>Nom du fichier : <code>voice_clone_raw.wav</code></li>
                                <li>Durée optimale : 30 secondes à 5 minutes</li>
                            </ul>
                        </div>
                    </div>

                    <div class="flex items-start">
                        <div class="step-number">3</div>
                        <div>
                            <h5 class="font-bold mb-2">Analyse du Signal d'Entrée</h5>
                            <p class="text-gray-600 mb-2">Le script analyse automatiquement :</p>
                            <ul class="list-disc ml-6 text-sm text-gray-600">
                                <li>Niveau de bruit de fond (premiers 10% du fichier)</li>
                                <li>Détection des clics et artefacts</li>
                                <li>Analyse spectrale pour réparation HF</li>
                                <li>Calcul des métriques de qualité</li>
                            </ul>
                        </div>
                    </div>

                    <div class="flex items-start">
                        <div class="step-number">4</div>
                        <div>
                            <h5 class="font-bold mb-2">Exécution du Nettoyage</h5>
                            <div class="code-block">
                                <button class="copy-btn" onclick="copyCode('run-cleaning')">
                                    <i class="fas fa-copy mr-1"></i>Copier
                                </button>
                                <pre id="run-cleaning" class="text-green-400 text-sm"><code>python audio_cleaner.py</code></pre>
                            </div>
                            <p class="text-gray-600 text-sm mt-2">Le processus prend 30 secondes à 2 minutes selon la taille du fichier.</p>
                        </div>
                    </div>

                    <div class="flex items-start">
                        <div class="step-number">5</div>
                        <div>
                            <h5 class="font-bold mb-2">Vérification des Résultats</h5>
                            <p class="text-gray-600 mb-2">Fichier de sortie : <code>voice_clone_professional.wav</code></p>
                            <div class="success-box">
                                <p class="text-sm"><strong>Qualité attendue :</strong></p>
                                <ul class="list-disc ml-6 text-sm mt-2">
                                    <li>Bruit de fond réduit de 80-90%</li>
                                    <li>Clics et pops éliminés</li>
                                    <li>Signal normalisé à -23 LUFS</li>
                                    <li>Dynamique préservée</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 2: Égalisation Multi-Bandes -->
    <section id="equalisation" class="py-16 bg-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-sliders-h mr-3 text-green-600"></i>
                    Égalisation Multi-Bandes Professionnelle
                </h3>
                <p class="text-gray-600 text-lg">Correction fréquentielle précise et optimisation des formants vocaux</p>
            </div>

            <!-- Égaliseur Visuel Interactif -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-equalizer mr-2 text-green-600"></i>
                    Égaliseur 10 Bandes - Voix Féminine Optimisée
                </h4>
                
                <div class="flex justify-center space-x-2 mb-8">
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 60px;"></div>
                        <div class="freq-label">60Hz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 70px;"></div>
                        <div class="freq-label">120Hz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 50px;"></div>
                        <div class="freq-label">250Hz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 45px;"></div>
                        <div class="freq-label">500Hz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 40px;"></div>
                        <div class="freq-label">1kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 35px;"></div>
                        <div class="freq-label">2kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 30px;"></div>
                        <div class="freq-label">4kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 40px;"></div>
                        <div class="freq-label">8kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 55px;"></div>
                        <div class="freq-label">12kHz</div>
                    </div>
                    <div class="eq-band" style="height: 120px;">
                        <div class="eq-slider" style="top: 65px;"></div>
                        <div class="freq-label">16kHz</div>
                    </div>
                </div>

                <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
                    <div class="text-center">
                        <h5 class="font-bold mb-2">Graves (60-250Hz)</h5>
                        <p class="text-sm text-gray-600">Réduction légère pour éliminer les résonances parasites</p>
                    </div>
                    <div class="text-center">
                        <h5 class="font-bold mb-2">Médiums (500Hz-4kHz)</h5>
                        <p class="text-sm text-gray-600">Boost précis des formants vocaux pour clarté</p>
                    </div>
                    <div class="text-center">
                        <h5 class="font-bold mb-2">Aigus (8-16kHz)</h5>
                        <p class="text-sm text-gray-600">Contrôle brillance et respiration</p>
                    </div>
                </div>
            </div>

            <!-- Script Python Égalisation -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-green-600"></i>
                    Script Python - Égalisation Multi-Bandes
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('eq-code')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="eq-code" class="text-green-400 text-sm overflow-x-auto"><code>import numpy as np
import librosa
from scipy import signal
from scipy.io import wavfile
import matplotlib.pyplot as plt

class ProfessionalEqualizer:
    def __init__(self, sample_rate=44100):
        self.sample_rate = sample_rate
        
        # Bandes d'égalisation optimisées pour voix féminine
        self.eq_bands = {
            'sub_bass': {'freq': 60, 'q': 0.7, 'gain': -2},      # Réduction résonances
            'bass': {'freq': 120, 'q': 0.8, 'gain': -1},        # Nettoyage graves
            'low_mid1': {'freq': 250, 'q': 1.0, 'gain': 1},     # Présence voix
            'low_mid2': {'freq': 500, 'q': 1.2, 'gain': 2},     # Premier formant
            'mid': {'freq': 1000, 'q': 1.0, 'gain': 3},         # Clarté vocale
            'high_mid1': {'freq': 2000, 'q': 1.2, 'gain': 4},   # Deuxième formant
            'high_mid2': {'freq': 4000, 'q': 1.0, 'gain': 2},   # Présence
            'presence': {'freq': 8000, 'q': 0.8, 'gain': 1},    # Brillance
            'air1': {'freq': 12000, 'q': 0.6, 'gain': -0.5},    # Contrôle sibilance
            'air2': {'freq': 16000, 'q': 0.5, 'gain': -1}       # Limitation HF
        }
        
    def create_parametric_filter(self, freq, q, gain, filter_type='peaking'):
        """Création filtre paramétrique professionnel"""
        nyquist = self.sample_rate / 2.0
        norm_freq = freq / nyquist
        
        if filter_type == 'peaking':
            # Filtre peaking (bell) pour boost/cut
            b, a = signal.iirpeak(norm_freq, Q=q)
            if gain != 0:
                # Application du gain
                gain_linear = 10**(gain/20)
                if gain > 0:
                    b = b * gain_linear
                else:
                    b = b / abs(gain_linear)
        
        elif filter_type == 'highpass':
            # Filtre passe-haut
            b, a = signal.butter(4, norm_freq, btype='high')
            
        elif filter_type == 'lowpass':
            # Filtre passe-bas
            b, a = signal.butter(4, norm_freq, btype='low')
            
        return b, a
    
    def apply_vocal_eq_preset(self, audio, preset='female_warm'):
        """Application preset d'égalisation optimisé voix"""
        print(f"🎛️ Application preset EQ: {preset}")
        
        if preset == 'female_warm':
            # Preset optimisé pour voix féminine chaleureuse
            eq_settings = {
                'sub_bass': {'freq': 60, 'q': 0.7, 'gain': -3},
                'bass': {'freq': 120, 'q': 0.8, 'gain': -1},
                'low_mid': {'freq': 250, 'q': 1.0, 'gain': 1},
                'mid': {'freq': 800, 'q': 1.2, 'gain': 2},
                'vocal': {'freq': 1500, 'q': 1.0, 'gain': 3},
                'presence': {'freq': 3000, 'q': 1.2, 'gain': 3},
                'clarity': {'freq': 6000, 'q': 1.0, 'gain': 1},
                'air': {'freq': 10000, 'q': 0.6, 'gain': 0.5}
            }
        
        elif preset == 'female_bright':
            # Preset pour voix féminine brillante
            eq_settings = {
                'sub_bass': {'freq': 80, 'q': 0.7, 'gain': -2},
                'low_mid': {'freq': 200, 'q': 1.0, 'gain': 0},
                'mid': {'freq': 1000, 'q': 1.2, 'gain': 2},
                'vocal': {'freq': 2000, 'q': 1.0, 'gain': 4},
                'presence': {'freq': 4000, 'q': 1.2, 'gain': 3},
                'clarity': {'freq': 8000, 'q': 1.0, 'gain': 2},
                'air': {'freq': 12000, 'q': 0.6, 'gain': 1}
            }
        
        else:
            eq_settings = self.eq_bands
        
        processed_audio = audio.copy()
        
        # Application séquentielle de chaque bande
        for band_name, params in eq_settings.items():
            if params['gain'] != 0:  # Seulement si gain non nul
                b, a = self.create_parametric_filter(
                    params['freq'], params['q'], params['gain']
                )
                processed_audio = signal.filtfilt(b, a, processed_audio)
                print(f"   ✅ {band_name}: {params['freq']}Hz, {params['gain']:+.1f}dB")
        
        return processed_audio
    
    def formant_correction(self, audio, shift_factor=1.0):
        """Correction des formants vocaux"""
        print("🔧 Correction formants...")
        
        # 1. Analyse spectrale
        stft = librosa.stft(audio, n_fft=2048, hop_length=512)
        magnitude = np.abs(stft)
        phase = np.angle(stft)
        
        # 2. Détection formants
        freq_bins = librosa.fft_frequencies(sr=self.sample_rate, n_fft=2048)
        
        # Zones formants pour voix féminine
        formant_zones = [
            (700, 1000),   # F1 - Ouverture bouche
            (1800, 2200),  # F2 - Position langue
            (2600, 3200)   # F3 - Résonance cavité
        ]
        
        # 3. Boost ciblé des formants
        for f_low, f_high in formant_zones:
            formant_mask = (freq_bins >= f_low) & (freq_bins <= f_high)
            magnitude[formant_mask] *= (1.0 + 0.2 * shift_factor)
        
        # 4. Reconstruction
        corrected_stft = magnitude * np.exp(1j * phase)
        corrected_audio = librosa.istft(corrected_stft, hop_length=512)
        
        print("✅ Correction formants terminée")
        return corrected_audio
    
    def de_essing(self, audio, freq_center=6000, threshold=-20):
        """Suppression sibilances (de-essing)"""
        print("🔧 De-essing...")
        
        # 1. Filtrage zone sibilances (4-8kHz)
        nyquist = self.sample_rate / 2
        low_cut = 4000 / nyquist
        high_cut = 8000 / nyquist
        
        # Filtre passe-bande pour détecter sibilances
        b_detect, a_detect = signal.butter(4, [low_cut, high_cut], btype='band')
        sibilance_signal = signal.filtfilt(b_detect, a_detect, audio)
        
        # 2. Détection seuil
        sibilance_level = np.abs(sibilance_signal)
        threshold_linear = 10**(threshold/20)
        
        # 3. Compression dynamique des sibilances
        compression_ratio = 3.0
        attack_time = 0.001  # 1ms
        release_time = 0.1   # 100ms
        
        attack_samples = int(attack_time * self.sample_rate)
        release_samples = int(release_time * self.sample_rate)
        
        # Envelope follower simplifié
        envelope = np.zeros_like(sibilance_level)
        for i in range(1, len(sibilance_level)):
            if sibilance_level[i] > envelope[i-1]:
                # Attack
                envelope[i] = envelope[i-1] + (sibilance_level[i] - envelope[i-1]) / attack_samples
            else:
                # Release
                envelope[i] = envelope[i-1] * (1 - 1/release_samples)
        
        # 4. Calcul gain reduction
        gain_reduction = np.ones_like(audio)
        over_threshold = envelope > threshold_linear
        gain_reduction[over_threshold] = threshold_linear / envelope[over_threshold]
        gain_reduction[over_threshold] = gain_reduction[over_threshold] ** (1/compression_ratio)
        
        # 5. Application gain reduction dans zone sibilances seulement
        b_sib, a_sib = signal.butter(4, [low_cut, high_cut], btype='band')
        sibilance_reduced = signal.filtfilt(b_sib, a_sib, audio * gain_reduction)
        
        # Reconstruction avec signal original
        result = audio - signal.filtfilt(b_sib, a_sib, audio) + sibilance_reduced
        
        print("✅ De-essing terminé")
        return result
    
    def complete_eq_processing(self, input_file, output_file, preset='female_warm'):
        """Pipeline complet d'égalisation"""
        print("🎛️ DÉMARRAGE ÉGALISATION PROFESSIONNELLE")
        print("=" * 50)
        
        # 1. Chargement
        audio, sr = librosa.load(input_file, sr=self.sample_rate)
        print(f"📂 Audio chargé: {len(audio)} échantillons")
        
        # 2. Pipeline d'égalisation
        step1 = self.apply_vocal_eq_preset(audio, preset)
        step2 = self.formant_correction(step1, shift_factor=1.1)
        step3 = self.de_essing(step2, threshold=-18)
        
        # 3. Normalisation finale
        final_audio = step3 / np.max(np.abs(step3)) * 0.95
        
        # 4. Sauvegarde
        wavfile.write(output_file, self.sample_rate,
                     (final_audio * 32767).astype(np.int16))
        
        print("=" * 50)
        print(f"✅ ÉGALISATION TERMINÉE: {output_file}")
        
        return final_audio

# ===============================================
# UTILISATION PRATIQUE
# ===============================================

def equaliser_voix_clonee():
    """Pipeline optimisé pour voix clonée"""
    
    eq = ProfessionalEqualizer(sample_rate=44100)
    
    # Fichiers
    input_file = "voice_clone_professional.wav"  # Sortie du nettoyage
    output_file = "voice_clone_equalized.wav"
    
    # Égalisation avec preset féminin chaleureux
    equalized_audio = eq.complete_eq_processing(
        input_file, output_file, preset='female_warm'
    )
    
    print("\n🎯 ÉGALISATION VOCALE TERMINÉE")
    print("📁 Fichier prêt pour ajout d'effets")
    
    return output_file

# Exécution
if __name__ == "__main__":
    equaliser_voix_clonee()</code></pre>
                </div>
            </div>

            <!-- Presets d'Égalisation -->
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-blue-600">
                        <i class="fas fa-heart mr-2"></i>Preset "Female Warm"
                    </h4>
                    <ul class="space-y-2 text-sm">
                        <li><span class="font-medium">60Hz:</span> -3dB (réduction résonances)</li>
                        <li><span class="font-medium">250Hz:</span> +1dB (présence)</li>
                        <li><span class="font-medium">800Hz:</span> +2dB (chaleur)</li>
                        <li><span class="font-medium">1.5kHz:</span> +3dB (clarté vocale)</li>
                        <li><span class="font-medium">3kHz:</span> +3dB (présence)</li>
                        <li><span class="font-medium">6kHz:</span> +1dB (définition)</li>
                        <li><span class="font-medium">10kHz:</span> +0.5dB (air)</li>
                    </ul>
                    <p class="text-xs text-gray-500 mt-3">Idéal pour contenu intime et conversationnel</p>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-purple-600">
                        <i class="fas fa-star mr-2"></i>Preset "Female Bright"
                    </h4>
                    <ul class="space-y-2 text-sm">
                        <li><span class="font-medium">80Hz:</span> -2dB (nettoyage)</li>
                        <li><span class="font-medium">1kHz:</span> +2dB (clarté)</li>
                        <li><span class="font-medium">2kHz:</span> +4dB (formant principal)</li>
                        <li><span class="font-medium">4kHz:</span> +3dB (présence)</li>
                        <li><span class="font-medium">8kHz:</span> +2dB (brillance)</li>
                        <li><span class="font-medium">12kHz:</span> +1dB (air)</li>
                    </ul>
                    <p class="text-xs text-gray-500 mt-3">Parfait pour contenu énergique et performances</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 3: Effets Réalistes -->
    <section id="effets" class="py-16 bg-gray-50">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-magic mr-3 text-purple-600"></i>
                    Effets Vocaux Réalistes
                </h3>
                <p class="text-gray-600 text-lg">Ajout de respirations naturelles, hésitations et micro-détails humains</p>
            </div>

            <!-- Démonstration Effets -->
            <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mb-12">
                <div class="bg-white rounded-xl shadow-lg p-6 card-hover">
                    <div class="text-center mb-4">
                        <div class="bg-gradient-to-br from-blue-500 to-purple-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                            <i class="fas fa-wind text-white text-xl"></i>
                        </div>
                        <h4 class="font-bold text-lg">Respirations Naturelles</h4>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-2">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Inspirations subtiles</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Expirations contrôlées</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Pauses naturelles</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Rythme respiratoire</li>
                    </ul>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6 card-hover">
                    <div class="text-center mb-4">
                        <div class="bg-gradient-to-br from-green-500 to-blue-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                            <i class="fas fa-pause text-white text-xl"></i>
                        </div>
                        <h4 class="font-bold text-lg">Hésitations Subtiles</h4>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-2">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Micro-pauses</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Hum et euh discrets</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Variations tempo</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Naturel spontané</li>
                    </ul>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6 card-hover">
                    <div class="text-center mb-4">
                        <div class="bg-gradient-to-br from-purple-500 to-pink-600 w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4">
                            <i class="fas fa-heartbeat text-white text-xl"></i>
                        </div>
                        <h4 class="font-bold text-lg">Micro-Détails</h4>
                    </div>
                    <ul class="text-sm text-gray-600 space-y-2">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Bruits de bouche</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Clics de langue</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Variations pitch</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Texture vocale</li>
                    </ul>
                </div>
            </div>

            <!-- Script Python Effets Réalistes -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-purple-600"></i>
                    Script Python - Effets Vocaux Réalistes
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('effects-code')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="effects-code" class="text-green-400 text-sm overflow-x-auto"><code>import numpy as np
import librosa
from scipy import signal
from scipy.io import wavfile
import random

class VocalRealismEnhancer:
    def __init__(self, sample_rate=44100):
        self.sample_rate = sample_rate
        self.breath_samples = self.load_breath_samples()
        
    def load_breath_samples(self):
        """Génération échantillons de respiration synthétiques"""
        breath_samples = {}
        
        # Génération respiration inspiration (500ms)
        duration = 0.5
        t = np.linspace(0, duration, int(self.sample_rate * duration))
        
        # Profil fréquentiel respiration (bruit filtré)
        noise = np.random.normal(0, 0.1, len(t))
        
        # Filtrage passe-bas pour son de respiration naturel
        nyquist = self.sample_rate / 2
        cutoff = 800 / nyquist
        b, a = signal.butter(4, cutoff, btype='low')
        filtered_breath = signal.filtfilt(b, a, noise)
        
        # Envelope d'attaque/déclin naturelle
        attack_time = 0.1
        decay_time = 0.4
        attack_samples = int(attack_time * self.sample_rate)
        decay_samples = int(decay_time * self.sample_rate)
        
        envelope = np.ones_like(filtered_breath)
        # Attack
        envelope[:attack_samples] = np.linspace(0, 1, attack_samples)
        # Decay
        envelope[-decay_samples:] = np.linspace(1, 0, decay_samples)
        
        breath_in = filtered_breath * envelope * 0.15
        
        # Génération expiration (plus longue, 700ms)
        duration_out = 0.7
        t_out = np.linspace(0, duration_out, int(self.sample_rate * duration_out))
        noise_out = np.random.normal(0, 0.08, len(t_out))
        
        # Fréquences plus graves pour expiration
        cutoff_out = 400 / nyquist
        b_out, a_out = signal.butter(4, cutoff_out, btype='low')
        filtered_breath_out = signal.filtfilt(b_out, a_out, noise_out)
        
        # Envelope expiration plus douce
        envelope_out = np.ones_like(filtered_breath_out)
        attack_samples_out = int(0.05 * self.sample_rate)
        decay_samples_out = int(0.5 * self.sample_rate)
        
        envelope_out[:attack_samples_out] = np.linspace(0, 1, attack_samples_out)
        envelope_out[-decay_samples_out:] = np.linspace(1, 0, decay_samples_out)
        
        breath_out = filtered_breath_out * envelope_out * 0.12
        
        breath_samples['inspiration'] = breath_in
        breath_samples['expiration'] = breath_out
        
        return breath_samples
    
    def detect_speech_segments(self, audio, min_speech_duration=0.5):
        """Détection segments de parole pour insertion respirations"""
        # Calcul énergie par fenêtres
        window_size = int(0.1 * self.sample_rate)  # 100ms
        hop_size = int(0.05 * self.sample_rate)    # 50ms
        
        energy = []
        for i in range(0, len(audio) - window_size, hop_size):
            window = audio[i:i + window_size]
            energy.append(np.sum(window ** 2))
        
        energy = np.array(energy)
        
        # Seuil adaptatif pour détection parole
        threshold = np.mean(energy) * 0.3
        speech_mask = energy > threshold
        
        # Conversion en indices temporels
        speech_segments = []
        in_speech = False
        start_idx = 0
        
        for i, is_speech in enumerate(speech_mask):
            time_idx = i * hop_size
            
            if is_speech and not in_speech:
                start_idx = time_idx
                in_speech = True
            elif not is_speech and in_speech:
                duration = (time_idx - start_idx) / self.sample_rate
                if duration >= min_speech_duration:
                    speech_segments.append((start_idx, time_idx))
                in_speech = False
        
        return speech_segments
    
    def add_natural_breathing(self, audio, breath_frequency=0.3):
        """Ajout respirations naturelles entre segments"""
        print("🌬️ Ajout respirations naturelles...")
        
        speech_segments = self.detect_speech_segments(audio)
        result_audio = audio.copy()
        
        # Insertion respirations entre segments
        offset = 0
        for i in range(len(speech_segments) - 1):
            current_end = speech_segments[i][1] + offset
            next_start = speech_segments[i + 1][0] + offset
            
            gap_duration = (next_start - current_end) / self.sample_rate
            
            # Insertion respiration si gap suffisant (>1s)
            if gap_duration > 1.0 and random.random() < breath_frequency:
                breath_type = random.choice(['inspiration', 'expiration'])
                breath_sample = self.breath_samples[breath_type]
                
                # Position d'insertion (milieu du gap)
                insert_pos = current_end + int(gap_duration * 0.3 * self.sample_rate)
                
                # Insertion avec fondu
                breath_with_fade = self.apply_fade_in_out(breath_sample, 0.1, 0.2)
                
                # Extension du tableau pour insérer la respiration
                result_audio = np.concatenate([
                    result_audio[:insert_pos],
                    breath_with_fade,
                    result_audio[insert_pos:]
                ])
                
                offset += len(breath_with_fade)
                print(f"   ✅ {breath_type} ajoutée à {insert_pos/self.sample_rate:.1f}s")
        
        return result_audio
    
    def add_subtle_hesitations(self, audio, hesitation_probability=0.15):
        """Ajout hésitations subtiles (euh, hum)"""
        print("🤔 Ajout hésitations subtiles...")
        
        speech_segments = self.detect_speech_segments(audio, min_speech_duration=1.0)
        result_audio = audio.copy()
        
        offset = 0
        for segment_start, segment_end in speech_segments:
            segment_start += offset
            segment_end += offset
            
            if random.random() < hesitation_probability:
                # Génération hésitation synthétique
                hesitation = self.generate_hesitation_sound()
                
                # Position aléatoire dans le segment
                insert_pos = segment_start + int(0.2 * (segment_end - segment_start))
                
                # Insertion
                result_audio = np.concatenate([
                    result_audio[:insert_pos],
                    hesitation,
                    result_audio[insert_pos:]
                ])
                
                offset += len(hesitation)
                print(f"   ✅ Hésitation ajoutée à {insert_pos/self.sample_rate:.1f}s")
        
        return result_audio
    
    def generate_hesitation_sound(self):
        """Génération son d'hésitation naturel"""
        # Types d'hésitations
        hesitation_types = ['euh', 'hmm', 'pause']
        hes_type = random.choice(hesitation_types)
        
        if hes_type == 'euh':
            # Son "euh" : ton moyennement grave, court
            duration = random.uniform(0.2, 0.4)
            t = np.linspace(0, duration, int(self.sample_rate * duration))
            
            # Fréquence fondamentale autour de 150Hz (voix féminine basse)
            freq = random.uniform(140, 180)
            hesitation = 0.1 * np.sin(2 * np.pi * freq * t)
            
            # Ajout harmoniques pour réalisme
            hesitation += 0.05 * np.sin(2 * np.pi * freq * 2 * t)
            hesitation += 0.02 * np.sin(2 * np.pi * freq * 3 * t)
            
        elif hes_type == 'hmm':
            # Son "hmm" : bouche fermée, nasal
            duration = random.uniform(0.3, 0.6)
            t = np.linspace(0, duration, int(self.sample_rate * duration))
            
            freq = random.uniform(120, 160)
            hesitation = 0.08 * np.sin(2 * np.pi * freq * t)
            
            # Filtrage nasal (boost autour de 1kHz)
            nyquist = self.sample_rate / 2
            nasal_freq = 1000 / nyquist
            b, a = signal.butter(2, [nasal_freq * 0.8, nasal_freq * 1.2], btype='band')
            hesitation = signal.filtfilt(b, a, hesitation)
            
        else:  # pause
            # Micro-pause avec bruit de bouche très discret
            duration = random.uniform(0.1, 0.2)
            hesitation = np.random.normal(0, 0.005, int(self.sample_rate * duration))
        
        # Application envelope naturelle
        return self.apply_fade_in_out(hesitation, 0.05, 0.1)
    
    def add_mouth_sounds(self, audio, probability=0.1):
        """Ajout micro-bruits de bouche naturels"""
        print("👄 Ajout micro-bruits de bouche...")
        
        # Détection consonnes plosives (p, b, t, d, k, g)
        # Approximation par détection transitions rapides d'énergie
        
        energy = librosa.feature.rms(y=audio, frame_length=2048, hop_length=512)[0]
        energy_diff = np.abs(np.diff(energy))
        
        # Seuil pour détection transitions
        threshold = np.percentile(energy_diff, 85)
        sharp_transitions = np.where(energy_diff > threshold)[0]
        
        result_audio = audio.copy()
        offset = 0
        
        for transition_idx in sharp_transitions:
            if random.random() < probability:
                # Position temporelle
                time_pos = int(transition_idx * 512) + offset
                
                # Génération bruit de bouche subtil
                mouth_sound = self.generate_mouth_click()
                
                # Insertion juste avant la transition
                insert_pos = max(0, time_pos - len(mouth_sound))
                
                result_audio = np.concatenate([
                    result_audio[:insert_pos],
                    mouth_sound,
                    result_audio[insert_pos:]
                ])
                
                offset += len(mouth_sound)
        
        print(f"   ✅ {len([t for t in sharp_transitions if random.random() < probability])} bruits de bouche ajoutés")
        return result_audio
    
    def generate_mouth_click(self):
        """Génération clic de langue/bouche subtil"""
        duration = random.uniform(0.01, 0.03)  # Très court
        samples = int(duration * self.sample_rate)
        
        # Impulsion suivie de décroissance rapide
        click = np.zeros(samples)
        attack_samples = samples // 4
        
        # Attaque rapide
        click[:attack_samples] = np.random.normal(0, 0.02, attack_samples)
        
        # Décroissance exponentielle
        decay = np.exp(-np.linspace(0, 8, samples - attack_samples))
        click[attack_samples:] = np.random.normal(0, 0.01, samples - attack_samples) * decay
        
        # Filtrage haute fréquence pour son de clic
        nyquist = self.sample_rate / 2
        high_freq = 3000 / nyquist
        b, a = signal.butter(2, high_freq, btype='high')
        click = signal.filtfilt(b, a, click)
        
        return click * 0.3  # Volume très discret
    
    def apply_fade_in_out(self, audio, fade_in_duration, fade_out_duration):
        """Application fondus d'entrée et sortie"""
        fade_in_samples = int(fade_in_duration * self.sample_rate)
        fade_out_samples = int(fade_out_duration * self.sample_rate)
        
        result = audio.copy()
        
        # Fade in
        if fade_in_samples < len(result):
            fade_in_curve = np.linspace(0, 1, fade_in_samples)
            result[:fade_in_samples] *= fade_in_curve
        
        # Fade out
        if fade_out_samples < len(result):
            fade_out_curve = np.linspace(1, 0, fade_out_samples)
            result[-fade_out_samples:] *= fade_out_curve
        
        return result
    
    def enhance_vocal_realism(self, input_file, output_file):
        """Pipeline complet d'amélioration réalisme vocal"""
        print("🎭 DÉMARRAGE AMÉLIORATION RÉALISME VOCAL")
        print("=" * 50)
        
        # 1. Chargement
        audio, sr = librosa.load(input_file, sr=self.sample_rate)
        print(f"📂 Audio chargé: {len(audio)/sr:.1f}s")
        
        # 2. Pipeline d'effets réalistes
        step1 = self.add_natural_breathing(audio, breath_frequency=0.4)
        step2 = self.add_subtle_hesitations(step1, hesitation_probability=0.2)
        step3 = self.add_mouth_sounds(step2, probability=0.15)
        
        # 3. Normalisation finale
        final_audio = step3 / np.max(np.abs(step3)) * 0.95
        
        # 4. Sauvegarde
        wavfile.write(output_file, self.sample_rate,
                     (final_audio * 32767).astype(np.int16))
        
        print("=" * 50)
        print(f"✅ RÉALISME VOCAL TERMINÉ: {output_file}")
        print(f"📈 Durée finale: {len(final_audio)/sr:.1f}s")
        
        return final_audio

# ===============================================
# UTILISATION PRATIQUE
# ===============================================

def ajouter_realisme_vocal():
    """Pipeline d'ajout de réalisme vocal"""
    
    enhancer = VocalRealismEnhancer(sample_rate=44100)
    
    # Fichiers
    input_file = "voice_clone_equalized.wav"  # Sortie égalisation
    output_file = "voice_clone_realistic.wav"
    
    # Amélioration réalisme
    realistic_audio = enhancer.enhance_vocal_realism(
        input_file, output_file
    )
    
    print("\n🎯 RÉALISME VOCAL TERMINÉ")
    print("📁 Fichier prêt pour mixage final")
    
    return output_file

# Exécution
if __name__ == "__main__":
    ajouter_realisme_vocal()</code></pre>
                </div>
            </div>

            <!-- Paramètres de Réalisme -->
            <div class="bg-white rounded-xl shadow-lg p-6">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-sliders-h mr-2 text-purple-600"></i>
                    Paramètres de Réalisme Optimaux
                </h4>

                <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                    <div>
                        <h5 class="font-bold mb-3">Respirations Naturelles</h5>
                        <ul class="space-y-2 text-sm">
                            <li><span class="font-medium">Fréquence:</span> 0.3-0.4 (30-40% des pauses)</li>
                            <li><span class="font-medium">Durée inspiration:</span> 0.5s</li>
                            <li><span class="font-medium">Durée expiration:</span> 0.7s</li>
                            <li><span class="font-medium">Volume:</span> 12-15% du signal principal</li>
                            <li><span class="font-medium">Filtrage:</span> Passe-bas 800Hz (inspiration), 400Hz (expiration)</li>
                        </ul>
                    </div>

                    <div>
                        <h5 class="font-bold mb-3">Hésitations & Micro-détails</h5>
                        <ul class="space-y-2 text-sm">
                            <li><span class="font-medium">Probabilité hésitations:</span> 15-20%</li>
                            <li><span class="font-medium">Types:</span> "euh" (140-180Hz), "hmm" (120-160Hz)</li>
                            <li><span class="font-medium">Bruits bouche:</span> 10% des transitions</li>
                            <li><span class="font-medium">Durée clics:</span> 10-30ms</li>
                            <li><span class="font-medium">Filtrage clics:</span> Passe-haut 3kHz</li>
                        </ul>
                    </div>
                </div>

                <div class="info-box mt-6">
                    <p class="text-sm">
                        <strong>💡 Conseil Pro :</strong> Les effets de réalisme doivent rester subtils. Un excès d'effets 
                        peut rendre l'audio artificiel. Ajustez les probabilités selon le style de contenu 
                        (plus d'hésitations pour du contenu conversationnel, moins pour du contenu préparé).
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 4: Mixage Avancé -->
    <section id="mixage" class="py-16 bg-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-volume-up mr-3 text-red-600"></i>
                    Mixage Audio Professionnel
                </h3>
                <p class="text-gray-600 text-lg">Finalisation studio avec compression, limiteur et spatialisation</p>
            </div>

            <!-- Console Mixage Virtuelle -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-mixing-desk mr-2 text-red-600"></i>
                    Console de Mixage Virtuelle
                </h4>

                <div class="grid grid-cols-1 md:grid-cols-4 gap-6">
                    <div class="text-center">
                        <h5 class="font-bold mb-3">Compression</h5>
                        <div class="bg-gradient-to-b from-red-500 to-red-700 h-32 w-16 mx-auto rounded mb-2 relative">
                            <div class="absolute bottom-8 left-1/2 transform -translate-x-1/2 w-6 h-6 bg-white rounded-full border-2 border-red-500"></div>
                        </div>
                        <p class="text-xs text-gray-600">Ratio 3:1<br>Attaque: 5ms<br>Release: 100ms</p>
                    </div>

                    <div class="text-center">
                        <h5 class="font-bold mb-3">Limiteur</h5>
                        <div class="bg-gradient-to-b from-orange-500 to-orange-700 h-32 w-16 mx-auto rounded mb-2 relative">
                            <div class="absolute bottom-4 left-1/2 transform -translate-x-1/2 w-6 h-6 bg-white rounded-full border-2 border-orange-500"></div>
                        </div>
                        <p class="text-xs text-gray-600">Seuil: -1dB<br>Release: 50ms<br>Lookahead: 5ms</p>
                    </div>

                    <div class="text-center">
                        <h5 class="font-bold mb-3">Reverb</h5>
                        <div class="bg-gradient-to-b from-blue-500 to-blue-700 h-32 w-16 mx-auto rounded mb-2 relative">
                            <div class="absolute bottom-16 left-1/2 transform -translate-x-1/2 w-6 h-6 bg-white rounded-full border-2 border-blue-500"></div>
                        </div>
                        <p class="text-xs text-gray-600">Room: Studio<br>Decay: 1.2s<br>Mix: 15%</p>
                    </div>

                    <div class="text-center">
                        <h5 class="font-bold mb-3">Stéréo</h5>
                        <div class="bg-gradient-to-b from-purple-500 to-purple-700 h-32 w-16 mx-auto rounded mb-2 relative">
                            <div class="absolute bottom-20 left-1/2 transform -translate-x-1/2 w-6 h-6 bg-white rounded-full border-2 border-purple-500"></div>
                        </div>
                        <p class="text-xs text-gray-600">Width: 85%<br>Center: 0%<br>Focus: Vocal</p>
                    </div>
                </div>
            </div>

            <!-- Script Python Mixage -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-red-600"></i>
                    Script Python - Mixage Studio Final
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('mixage-code')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="mixage-code" class="text-green-400 text-sm overflow-x-auto"><code>import numpy as np
import librosa
from scipy import signal
from scipy.io import wavfile
import matplotlib.pyplot as plt

class StudioMixingEngine:
    def __init__(self, sample_rate=44100):
        self.sample_rate = sample_rate
        
    def apply_vocal_compression(self, audio, threshold=-12, ratio=3.0, 
                              attack_ms=5, release_ms=100):
        """Compression vocale professionnelle"""
        print(f"🔧 Compression: {ratio}:1, seuil {threshold}dB")
        
        # Conversion paramètres temporels
        attack_samples = int(attack_ms * 0.001 * self.sample_rate)
        release_samples = int(release_ms * 0.001 * self.sample_rate)
        
        # Conversion seuil en linéaire
        threshold_linear = 10**(threshold/20)
        
        # Calcul envelope du signal
        envelope = np.abs(audio)
        
        # Lissage de l'envelope (ballistics du compresseur)
        smoothed_envelope = np.zeros_like(envelope)
        gain_reduction = np.ones_like(audio)
        
        for i in range(1, len(envelope)):
            # Détection dépassement seuil
            if envelope[i] > threshold_linear:
                # Calcul gain reduction nécessaire
                over_threshold = envelope[i] / threshold_linear
                target_gain = 1 / (1 + (over_threshold - 1) * (ratio - 1) / ratio)
                
                # Attack/Release ballistics
                if target_gain < gain_reduction[i-1]:
                    # Attack (réduction gain)
                    alpha = 1 - np.exp(-1 / attack_samples)
                else:
                    # Release (retour gain)
                    alpha = 1 - np.exp(-1 / release_samples)
                
                gain_reduction[i] = (
                    gain_reduction[i-1] * (1 - alpha) + target_gain * alpha
                )
            else:
                # Release progressif vers gain unitaire
                alpha = 1 - np.exp(-1 / release_samples)
                gain_reduction[i] = gain_reduction[i-1] * (1 - alpha) + 1 * alpha
        
        # Application compression
        compressed = audio * gain_reduction
        
        # Makeup gain automatique
        makeup_gain = 1 / np.mean(gain_reduction)
        compressed *= makeup_gain
        
        print(f"   ✅ Réduction moyenne: {-20*np.log10(np.mean(gain_reduction)):.1f}dB")
        return compressed
    
    def apply_peak_limiter(self, audio, ceiling_db=-1, release_ms=50, 
                          lookahead_ms=5):
        """Limiteur de pics transparent"""
        print(f"🔧 Limiteur: plafond {ceiling_db}dB")
        
        ceiling_linear = 10**(ceiling_db/20)
        lookahead_samples = int(lookahead_ms * 0.001 * self.sample_rate)
        release_samples = int(release_ms * 0.001 * self.sample_rate)
        
        # Délai pour lookahead
        delayed_audio = np.concatenate([
            np.zeros(lookahead_samples), audio
        ])
        
        # Détection des pics avec lookahead
        envelope = np.abs(audio)
        gain_reduction = np.ones(len(delayed_audio))
        
        for i in range(len(audio)):
            if envelope[i] > ceiling_linear:
                # Calcul gain reduction nécessaire
                target_gain = ceiling_linear / envelope[i]
                
                # Application release graduel
                for j in range(lookahead_samples + i, 
                             min(len(gain_reduction), 
                                 lookahead_samples + i + release_samples)):
                    release_factor = (j - lookahead_samples - i) / release_samples
                    gain_reduction[j] = min(
                        gain_reduction[j],
                        target_gain + (1 - target_gain) * release_factor
                    )
        
        # Application limitation
        limited = delayed_audio * gain_reduction
        
        print(f"   ✅ Pics limités à {ceiling_db}dB")
        return limited[:len(audio)]  # Suppression du délai
    
    def apply_studio_reverb(self, audio, room_size=0.6, decay_time=1.2, 
                           mix_level=0.15, pre_delay_ms=20):
        """Réverbération studio subtile"""
        print(f"🔧 Réverb studio: decay {decay_time}s, mix {mix_level*100:.0f}%")
        
        # Génération réponse impulsionnelle salle studio
        pre_delay_samples = int(pre_delay_ms * 0.001 * self.sample_rate)
        ir_length = int(decay_time * self.sample_rate)
        
        # Réponse impulsionnelle synthétique
        t = np.linspace(0, decay_time, ir_length)
        
        # Décroissance exponentielle + diffusion
        decay_envelope = np.exp(-3 * t / decay_time)
        
        # Ajout de réflexions multiples
        reflections = np.zeros(ir_length)
        reflection_times = [0.01, 0.023, 0.041, 0.067, 0.089, 0.134]
        reflection_gains = [0.8, 0.6, 0.5, 0.4, 0.3, 0.2]
        
        for time_offset, gain in zip(reflection_times, reflection_gains):
            offset_samples = int(time_offset * self.sample_rate)
            if offset_samples < ir_length:
                reflections[offset_samples] += gain
        
        # Convolution avec bruit pour diffusion
        diffusion_noise = np.random.normal(0, 1, ir_length // 4)
        diffusion = np.convolve(reflections, diffusion_noise, mode='same')
        
        # Réponse impulsionnelle finale
        impulse_response = (reflections + 0.3 * diffusion) * decay_envelope
        
        # Ajout pré-délai
        if pre_delay_samples > 0:
            impulse_response = np.concatenate([
                np.zeros(pre_delay_samples),
                impulse_response
            ])
        
        # Normalisation
        impulse_response /= np.max(np.abs(impulse_response))
        
        # Convolution avec signal
        reverb_signal = np.convolve(audio, impulse_response, mode='same')
        
        # Mixage wet/dry
        final = (1 - mix_level) * audio + mix_level * reverb_signal
        
        print(f"   ✅ Réverb appliquée")
        return final
    
    def stereo_widening(self, audio, width=0.85, bass_mono_freq=120):
        """Élargissement stéréo avec préservation graves mono"""
        print(f"🔧 Élargissement stéréo: {width*100:.0f}%")
        
        # Conversion mono vers stéréo si nécessaire
        if len(audio.shape) == 1:
            # Création stéréo artificiel
            left = audio.copy()
            right = audio.copy()
            
            # Ajout légères différences pour élargissement
            delay_samples = int(0.001 * self.sample_rate)  # 1ms delay
            right = np.concatenate([np.zeros(delay_samples), right])[:-delay_samples]
            
            # Modulation de phase légère sur canal droit
            modulation = 0.95 + 0.05 * np.sin(2 * np.pi * 0.5 * np.arange(len(right)) / self.sample_rate)
            right *= modulation
            
            stereo_audio = np.column_stack([left, right])
        else:
            stereo_audio = audio.copy()
        
        # Extraction Mid/Side
        mid = (stereo_audio[:, 0] + stereo_audio[:, 1]) / 2
        side = (stereo_audio[:, 0] - stereo_audio[:, 1]) / 2
        
        # Filtrage graves en mono
        nyquist = self.sample_rate / 2
        bass_cutoff = bass_mono_freq / nyquist
        b, a = signal.butter(2, bass_cutoff, btype='low')
        
        bass_mono = signal.filtfilt(b, a, mid)
        high_stereo = mid - bass_mono
        
        # Application élargissement sur side et hautes fréquences
        widened_side = side * width
        
        # Reconstruction stéréo
        left_final = bass_mono + high_stereo + widened_side
        right_final = bass_mono + high_stereo - widened_side
        
        result = np.column_stack([left_final, right_final])
        
        print(f"   ✅ Stéréo élargi, graves <{bass_mono_freq}Hz en mono")
        return result
    
    def final_mastering_chain(self, audio):
        """Chaîne de mastering finale"""
        print("🎛️ Chaîne mastering finale...")
        
        # 1. EQ de mastering subtil
        # Boost très léger présence 2-4kHz
        nyquist = self.sample_rate / 2
        freq_center = 3000 / nyquist
        b, a = signal.iirpeak(freq_center, Q=2)
        eq_audio = signal.filtfilt(b, a, audio) * 1.05  # +0.4dB
        
        # 2. Compression multibande simplifiée
        # Séparation graves/aigus à 1kHz
        split_freq = 1000 / nyquist
        b_low, a_low = signal.butter(4, split_freq, btype='low')
        b_high, a_high = signal.butter(4, split_freq, btype='high')
        
        low_band = signal.filtfilt(b_low, a_low, eq_audio)
        high_band = signal.filtfilt(b_high, a_high, eq_audio)
        
        # Compression légère sur chaque bande
        low_compressed = self.apply_vocal_compression(
            low_band, threshold=-15, ratio=2.5, attack_ms=10, release_ms=150
        )
        high_compressed = self.apply_vocal_compression(
            high_band, threshold=-10, ratio=3.0, attack_ms=3, release_ms=80
        )
        
        # Reconstruction
        mastered = low_compressed + high_compressed
        
        # 3. Limitation finale
        final = self.apply_peak_limiter(
            mastered, ceiling_db=-0.3, release_ms=30, lookahead_ms=3
        )
        
        print("   ✅ Mastering terminé")
        return final
    
    def complete_studio_mix(self, input_file, output_file, stereo_output=True):
        """Pipeline complet de mixage studio"""
        print("🎚️ DÉMARRAGE MIXAGE STUDIO PROFESSIONNEL")
        print("=" * 55)
        
        # 1. Chargement
        audio, sr = librosa.load(input_file, sr=self.sample_rate, mono=True)
        print(f"📂 Audio chargé: {len(audio)/sr:.1f}s")
        
        # 2. Pipeline de mixage
        step1 = self.apply_vocal_compression(audio)
        step2 = self.apply_studio_reverb(step1)
        
        # 3. Traitement stéréo si demandé
        if stereo_output:
            step3 = self.stereo_widening(step2)
            step4 = self.final_mastering_chain(step3)
            
            # Sauvegarde stéréo
            stereo_output_data = (step4 * 32767).astype(np.int16)
            wavfile.write(output_file, self.sample_rate, stereo_output_data)
        else:
            step3 = self.final_mastering_chain(step2)
            
            # Sauvegarde mono
            mono_output_data = (step3 * 32767).astype(np.int16)
            wavfile.write(output_file, self.sample_rate, mono_output_data)
        
        print("=" * 55)
        print(f"✅ MIXAGE STUDIO TERMINÉ: {output_file}")
        print(f"🎯 Format: {'Stéréo' if stereo_output else 'Mono'}")
        
        return step4 if stereo_output else step3

# ===============================================
# UTILISATION PRATIQUE
# ===============================================

def mixage_final_studio():
    """Pipeline complet mixage studio"""
    
    mixer = StudioMixingEngine(sample_rate=44100)
    
    # Fichiers
    input_file = "voice_clone_realistic.wav"  # Sortie effets réalistes
    output_file = "voice_clone_FINAL_STUDIO.wav"
    
    # Mixage studio complet
    final_mix = mixer.complete_studio_mix(
        input_file, output_file, stereo_output=True
    )
    
    print("\n🎯 MIXAGE STUDIO TERMINÉ")
    print("🏆 VOIX CLONÉE PRÊTE POUR DIFFUSION")
    print("📊 Qualité: Studio professionnel")
    
    return output_file

# Exécution
if __name__ == "__main__":
    mixage_final_studio()</code></pre>
                </div>
            </div>

            <!-- Métriques Audio Finales -->
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-green-600">
                        <i class="fas fa-chart-line mr-2"></i>Métriques Qualité Studio
                    </h4>
                    <ul class="space-y-3 text-sm">
                        <li class="flex justify-between">
                            <span>Niveau RMS :</span>
                            <span class="font-medium text-green-600">-23 LUFS</span>
                        </li>
                        <li class="flex justify-between">
                            <span>Peak Maximum :</span>
                            <span class="font-medium text-green-600">-0.3 dBFS</span>
                        </li>
                        <li class="flex justify-between">
                            <span>Dynamic Range :</span>
                            <span class="font-medium text-green-600">12-15 dB</span>
                        </li>
                        <li class="flex justify-between">
                            <span>THD+N :</span>
                            <span class="font-medium text-green-600">&lt; 0.1%</span>
                        </li>
                        <li class="flex justify-between">
                            <span>Réponse freq. :</span>
                            <span class="font-medium text-green-600">80Hz-16kHz</span>
                        </li>
                    </ul>
                </div>

                <div class="bg-white rounded-xl shadow-lg p-6">
                    <h4 class="font-bold text-lg mb-4 text-blue-600">
                        <i class="fas fa-headphones mr-2"></i>Tests d'Écoute Recommandés
                    </h4>
                    <ul class="space-y-2 text-sm">
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Écoute casque studio (référence plate)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Haut-parleurs monitoring (near-field)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Écouteurs grand public (simulation utilisateur)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Smartphone/laptop (compatibilité mobile)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Test mono (vérification compatibilité)</li>
                        <li><i class="fas fa-check text-green-500 mr-2"></i>Niveaux d'écoute variables (20-85 dB SPL)</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- Section 5: Automation Complète -->
    <section id="automation" class="py-16 bg-gray-50">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold text-gray-800 mb-4">
                    <i class="fas fa-robot mr-3 text-indigo-600"></i>
                    Automation du Post-Traitement
                </h3>
                <p class="text-gray-600 text-lg">Pipeline automatisé complet de A à Z</p>
            </div>

            <!-- Workflow Automation -->
            <div class="bg-white rounded-xl shadow-lg p-6 mb-8">
                <h4 class="font-bold text-xl mb-6">
                    <i class="fas fa-workflow mr-2 text-indigo-600"></i>
                    Pipeline Automatisé Complet
                </h4>
                
                <div class="space-y-4">
                    <div class="flex items-center bg-blue-50 rounded-lg p-4">
                        <div class="step-number">1</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Nettoyage Audio</h5>
                            <p class="text-sm text-gray-600">Réduction bruit, suppression clics, normalisation</p>
                        </div>
                        <div class="text-blue-600 font-bold">30s</div>
                    </div>
                    
                    <div class="flex items-center">
                        <i class="fas fa-arrow-down text-gray-400 text-xl mx-4"></i>
                    </div>
                    
                    <div class="flex items-center bg-green-50 rounded-lg p-4">
                        <div class="step-number">2</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Égalisation Pro</h5>
                            <p class="text-sm text-gray-600">EQ multi-bandes, correction formants, de-essing</p>
                        </div>
                        <div class="text-green-600 font-bold">45s</div>
                    </div>
                    
                    <div class="flex items-center">
                        <i class="fas fa-arrow-down text-gray-400 text-xl mx-4"></i>
                    </div>
                    
                    <div class="flex items-center bg-purple-50 rounded-lg p-4">
                        <div class="step-number">3</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Effets Réalistes</h5>
                            <p class="text-sm text-gray-600">Respirations, hésitations, micro-détails</p>
                        </div>
                        <div class="text-purple-600 font-bold">60s</div>
                    </div>
                    
                    <div class="flex items-center">
                        <i class="fas fa-arrow-down text-gray-400 text-xl mx-4"></i>
                    </div>
                    
                    <div class="flex items-center bg-red-50 rounded-lg p-4">
                        <div class="step-number">4</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Mixage Studio</h5>
                            <p class="text-sm text-gray-600">Compression, limiteur, réverb, stéréo</p>
                        </div>
                        <div class="text-red-600 font-bold">40s</div>
                    </div>
                    
                    <div class="flex items-center">
                        <i class="fas fa-arrow-down text-gray-400 text-xl mx-4"></i>
                    </div>
                    
                    <div class="flex items-center bg-yellow-50 rounded-lg p-4">
                        <div class="step-number">✓</div>
                        <div class="flex-1">
                            <h5 class="font-bold">Fichier Final Studio</h5>
                            <p class="text-sm text-gray-600">Prêt pour diffusion MYM/OnlyFans</p>
                        </div>
                        <div class="text-yellow-600 font-bold">Total: 3min</div>
                    </div>
                </div>
            </div>

            <!-- Script Master Automation -->
            <div class="bg-white rounded-xl shadow-lg p-6">
                <h4 class="font-bold text-xl mb-4">
                    <i class="fas fa-code mr-2 text-indigo-600"></i>
                    Script Master - Automation Complète
                </h4>
                
                <div class="code-block">
                    <button class="copy-btn" onclick="copyCode('master-automation')">
                        <i class="fas fa-copy mr-1"></i>Copier
                    </button>
                    <pre id="master-automation" class="text-green-400 text-sm overflow-x-auto"><code>#!/usr/bin/env python3
"""
Master Audio Post-Processing Pipeline
Pipeline automatisé complet pour clonage vocal professionnel
"""

import os
import sys
import time
import argparse
from pathlib import Path

# Import des modules précédents
# (Placez tous les scripts précédents dans le même dossier)
from audio_cleaner import ProfessionalAudioCleaner
from equalizer import ProfessionalEqualizer  
from vocal_realism import VocalRealismEnhancer
from studio_mixer import StudioMixingEngine

class MasterAudioPipeline:
    def __init__(self, sample_rate=44100, temp_dir="temp_processing"):
        self.sample_rate = sample_rate
        self.temp_dir = Path(temp_dir)
        self.temp_dir.mkdir(exist_ok=True)
        
        # Initialisation des modules
        self.cleaner = ProfessionalAudioCleaner()
        self.equalizer = ProfessionalEqualizer(sample_rate)
        self.realism_enhancer = VocalRealismEnhancer(sample_rate)
        self.mixer = StudioMixingEngine(sample_rate)
        
        # Compteurs et métriques
        self.start_time = None
        self.step_times = {}
        
    def validate_input_file(self, input_file):
        """Validation fichier d'entrée"""
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"Fichier introuvable: {input_file}")
        
        # Vérification format audio
        valid_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.aac']
        if not any(input_file.lower().endswith(ext) for ext in valid_extensions):
            raise ValueError(f"Format non supporté. Formats valides: {valid_extensions}")
        
        # Vérification taille fichier (max 100MB)
        file_size = os.path.getsize(input_file) / (1024 * 1024)  # MB
        if file_size > 100:
            raise ValueError(f"Fichier trop volumineux: {file_size:.1f}MB (max: 100MB)")
        
        print(f"✅ Fichier validé: {input_file} ({file_size:.1f}MB)")
        return True
    
    def setup_output_structure(self, output_dir):
        """Création structure de sortie"""
        output_path = Path(output_dir)
        
        # Création dossiers
        folders = [
            'final',           # Fichier final
            'intermediate',    # Fichiers intermédiaires
            'analysis',        # Rapports et analyses
            'backups'          # Sauvegardes
        ]
        
        for folder in folders:
            (output_path / folder).mkdir(parents=True, exist_ok=True)
        
        return output_path
    
    def generate_temp_filename(self, step_name, extension='.wav'):
        """Génération nom fichier temporaire"""
        timestamp = int(time.time())
        return self.temp_dir / f"step_{step_name}_{timestamp}{extension}"
    
    def time_step(self, step_name):
        """Décorateur pour chronométrage étapes"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                print(f"\n{'='*20} {step_name.upper()} {'='*20}")
                step_start = time.time()
                
                result = func(*args, **kwargs)
                
                step_duration = time.time() - step_start
                self.step_times[step_name] = step_duration
                
                print(f"✅ {step_name} terminé en {step_duration:.1f}s")
                return result
            return wrapper
        return decorator
    
    def step_1_cleaning(self, input_file):
        """Étape 1: Nettoyage audio"""
        output_file = self.generate_temp_filename('01_cleaned')
        cleaned_audio = self.cleaner.complete_professional_cleaning(
            input_file, str(output_file)
        )
        return str(output_file)
    
    def step_2_equalization(self, input_file, eq_preset='female_warm'):
        """Étape 2: Égalisation"""
        output_file = self.generate_temp_filename('02_equalized')
        eq_audio = self.equalizer.complete_eq_processing(
            input_file, str(output_file), preset=eq_preset
        )
        return str(output_file)
    
    def step_3_realism(self, input_file):
        """Étape 3: Effets réalistes"""
        output_file = self.generate_temp_filename('03_realistic')
        realistic_audio = self.realism_enhancer.enhance_vocal_realism(
            input_file, str(output_file)
        )
        return str(output_file)
    
    def step_4_mixing(self, input_file, stereo_output=True):
        """Étape 4: Mixage studio"""
        output_file = self.generate_temp_filename('04_mixed')
        mixed_audio = self.mixer.complete_studio_mix(
            input_file, str(output_file), stereo_output=stereo_output
        )
        return str(output_file)
    
    def process_single_file(self, input_file, output_file, config=None):
        """Traitement complet fichier unique"""
        
        # Configuration par défaut
        default_config = {
            'eq_preset': 'female_warm',
            'stereo_output': True,
            'save_intermediates': False,
            'generate_report': True
        }
        
        if config:
            default_config.update(config)
        config = default_config
        
        self.start_time = time.time()
        
        try:
            print("🎵 DÉMARRAGE PIPELINE AUDIO PROFESSIONNEL")
            print("=" * 60)
            print(f"📂 Entrée: {input_file}")
            print(f"📁 Sortie: {output_file}")
            print(f"⚙️ Config: {config}")
            
            # Validation
            self.validate_input_file(input_file)
            
            # Pipeline de traitement
            step1_output = self.time_step("NETTOYAGE")(self.step_1_cleaning)(input_file)
            step2_output = self.time_step("ÉGALISATION")(self.step_2_equalization)(
                step1_output, config['eq_preset']
            )
            step3_output = self.time_step("RÉALISME")(self.step_3_realism)(step2_output)
            step4_output = self.time_step("MIXAGE")(self.step_4_mixing)(
                step3_output, config['stereo_output']
            )
            
            # Copie vers fichier final
            import shutil
            shutil.copy2(step4_output, output_file)
            
            # Sauvegarde intermédiaires si demandé
            if config['save_intermediates']:
                output_dir = Path(output_file).parent
                intermediate_dir = output_dir / 'intermediate'
                
                stages = [
                    (step1_output, 'cleaned.wav'),
                    (step2_output, 'equalized.wav'), 
                    (step3_output, 'realistic.wav'),
                    (step4_output, 'mixed.wav')
                ]
                
                for stage_file, stage_name in stages:
                    shutil.copy2(stage_file, intermediate_dir / stage_name)
            
            # Génération rapport
            if config['generate_report']:
                self.generate_processing_report(input_file, output_file)
            
            # Nettoyage fichiers temporaires
            self.cleanup_temp_files()
            
            total_time = time.time() - self.start_time
            
            print("=" * 60)
            print("🏆 PIPELINE TERMINÉ AVEC SUCCÈS")
            print(f"⏱️ Temps total: {total_time:.1f}s")
            print(f"📁 Fichier final: {output_file}")
            
            return True
            
        except Exception as e:
            print(f"❌ ERREUR PIPELINE: {e}")
            self.cleanup_temp_files()
            return False
    
    def process_batch(self, input_dir, output_dir, config=None):
        """Traitement par lot"""
        input_path = Path(input_dir)
        output_path = self.setup_output_structure(output_dir)
        
        # Recherche fichiers audio
        audio_extensions = ['*.wav', '*.mp3', '*.flac', '*.m4a', '*.aac']
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(input_path.glob(ext))
        
        if not audio_files:
            print(f"❌ Aucun fichier audio trouvé dans {input_dir}")
            return False
        
        print(f"📂 {len(audio_files)} fichiers trouvés pour traitement")
        
        # Traitement séquentiel
        success_count = 0
        for i, input_file in enumerate(audio_files, 1):
            print(f"\n🎵 FICHIER {i}/{len(audio_files)}: {input_file.name}")
            
            output_file = output_path / 'final' / f"processed_{input_file.stem}.wav"
            
            if self.process_single_file(str(input_file), str(output_file), config):
                success_count += 1
            else:
                print(f"❌ Échec traitement: {input_file.name}")
        
        print(f"\n🎯 TRAITEMENT BATCH TERMINÉ")
        print(f"✅ Succès: {success_count}/{len(audio_files)}")
        
        return success_count == len(audio_files)
    
    def generate_processing_report(self, input_file, output_file):
        """Génération rapport de traitement"""
        report_file = Path(output_file).parent / 'analysis' / 'processing_report.txt'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("RAPPORT DE TRAITEMENT AUDIO PROFESSIONNEL\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"Fichier d'entrée: {input_file}\n")
            f.write(f"Fichier de sortie: {output_file}\n")
            f.write(f"Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("ÉTAPES DE TRAITEMENT:\n")
            f.write("-" * 30 + "\n")
            
            total_time = 0
            for step_name, duration in self.step_times.items():
                f.write(f"{step_name.ljust(20)}: {duration:.1f}s\n")
                total_time += duration
            
            f.write(f"{'TOTAL'.ljust(20)}: {total_time:.1f}s\n\n")
            
            f.write("PARAMÈTRES UTILISÉS:\n")
            f.write("-" * 30 + "\n")
            f.write("• Nettoyage: Réduction bruit, suppression clics, normalisation\n")
            f.write("• Égalisation: Preset féminin chaleureux, correction formants\n")
            f.write("• Réalisme: Respirations naturelles, hésitations subtiles\n")
            f.write("• Mixage: Compression 3:1, limiteur -0.3dB, réverb studio\n\n")
            
            f.write("QUALITÉ FINALE:\n")
            f.write("-" * 30 + "\n")
            f.write("• Niveau: -23 LUFS (standard diffusion)\n")
            f.write("• Peak: -0.3 dBFS (headroom sécurisé)\n")
            f.write("• Dynamic Range: 12-15 dB\n")
            f.write("• Format: WAV 44.1kHz 16-bit\n")
        
        print(f"📊 Rapport généré: {report_file}")
    
    def cleanup_temp_files(self):
        """Nettoyage fichiers temporaires"""
        import shutil
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)
            print("🧹 Fichiers temporaires nettoyés")

# ===============================================
# INTERFACE LIGNE DE COMMANDE
# ===============================================

def main():
    parser = argparse.ArgumentParser(description='Pipeline Audio Professionnel')
    parser.add_argument('input', help='Fichier ou dossier d\'entrée')
    parser.add_argument('output', help='Fichier ou dossier de sortie')
    parser.add_argument('--preset', choices=['female_warm', 'female_bright'], 
                       default='female_warm', help='Preset d\'égalisation')
    parser.add_argument('--mono', action='store_true', help='Sortie mono')
    parser.add_argument('--save-intermediate', action='store_true', 
                       help='Sauvegarder fichiers intermédiaires')
    parser.add_argument('--batch', action='store_true', 
                       help='Mode traitement par lot')
    
    args = parser.parse_args()
    
    # Configuration
    config = {
        'eq_preset': args.preset,
        'stereo_output': not args.mono,
        'save_intermediates': args.save_intermediate,
        'generate_report': True
    }
    
    # Initialisation pipeline
    pipeline = MasterAudioPipeline()
    
    # Traitement
    if args.batch:
        success = pipeline.process_batch(args.input, args.output, config)
    else:
        success = pipeline.process_single_file(args.input, args.output, config)
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()

# ===============================================
# UTILISATION RAPIDE
# ===============================================

def traitement_rapide(input_file, output_file):
    """Traitement rapide avec paramètres par défaut"""
    pipeline = MasterAudioPipeline()
    return pipeline.process_single_file(input_file, output_file)

# Exemple d'utilisation
# traitement_rapide("voice_raw.wav", "voice_final_studio.wav")</code></pre>
                </div>
            </div>
        </div>
    </section>

    <!-- Récapitulatif Final -->
    <section class="py-16 bg-gradient-to-br from-purple-600 to-blue-700 text-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-12">
                <h3 class="text-3xl font-bold mb-4">
                    <i class="fas fa-trophy mr-3"></i>
                    Récapitulatif BLOC 11.6 Complet
                </h3>
                <p class="text-xl">Pipeline de post-traitement audio professionnel maîtrisé</p>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6 mb-8">
                <div class="text-center">
                    <div class="bg-white bg-opacity-20 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-broom text-3xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Nettoyage Maîtrisé</h4>
                    <p class="text-sm opacity-90">Réduction bruit, suppression artefacts, normalisation intelligente</p>
                </div>

                <div class="text-center">
                    <div class="bg-white bg-opacity-20 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-sliders-h text-3xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">EQ Professionnel</h4>
                    <p class="text-sm opacity-90">Multi-bandes, formants corrigés, presets optimisés</p>
                </div>

                <div class="text-center">
                    <div class="bg-white bg-opacity-20 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-magic text-3xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Réalisme Naturel</h4>
                    <p class="text-sm opacity-90">Respirations, hésitations, micro-détails humains</p>
                </div>

                <div class="text-center">
                    <div class="bg-white bg-opacity-20 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <i class="fas fa-volume-up text-3xl"></i>
                    </div>
                    <h4 class="font-bold text-lg mb-2">Mixage Studio</h4>
                    <p class="text-sm opacity-90">Compression, limiteur, spatialisation, mastering</p>
                </div>
            </div>

            <div class="text-center">
                <div class="success-box">
                    <h4 class="font-bold text-xl mb-4 text-gray-800">🎯 Objectif Atteint</h4>
                    <p class="text-gray-700 mb-4">
                        Votre clonage vocal est maintenant transformé en production audio de qualité studio professionnelle, 
                        indiscernable d'un enregistrement réel et prêt pour monétisation sur MYM/OnlyFans.
                    </p>
                    <div class="grid grid-cols-1 md:grid-cols-3 gap-4 text-sm text-gray-700">
                        <div>
                            <strong>Qualité Technique :</strong><br>
                            Studio professionnel, -23 LUFS, THD &lt; 0.1%
                        </div>
                        <div>
                            <strong>Réalisme Humain :</strong><br>
                            Respirations, hésitations, micro-détails naturels
                        </div>
                        <div>
                            <strong>Automation :</strong><br>
                            Pipeline complet en 3 minutes, reproductible
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Navigation vers autres blocs -->
    <section class="py-12 bg-white">
        <div class="container mx-auto px-6">
            <div class="text-center mb-8">
                <h3 class="text-2xl font-bold text-gray-800 mb-4">Navigation Formation Clonage Vocal</h3>
                <p class="text-gray-
    <script id="html_badge_script1">
        window.__genspark_remove_badge_link = "https://www.genspark.ai/api/html_badge/" +
            "remove_badge?token=To%2FBnjzloZ3UfQdcSaYfDlt1n2H98BoHF0yEN%2B5RyRJ%2BrwpFg2Feo2Try5bFzFWmZUIAZgccxDSCTebWrKrAsWc%2FdTUled%2BOqqrhVfMN4fSwZSNqv7MbEjAIT%2FzvkNe1%2F080BdQcxczZzCyUWJAseeyCukSgu05DRjzHlSjkWNWyp2fkUjkmYAU%2FHI4Tp%2FyaygOxE9AF05c%2FV15m5pW2vE5aQiWpt5cvwfcfYzdDl5SD0uVSEFv0qaHJ%2BsM1483JfqS3A2FI55AbUTf6xRNDicMEluNu5d0iRkVFjnF7m7hMjZczIFcypVeRHCi%2BmnXETTScpTtrbBesCcm%2F1974GeR%2BoIOAX58Dw9uKQ8fT7DxV0zizNeMZNpXcEhOtjG1QWaIMIv%2FzPxoAZhgw8UDH18LtiKT2Pqk9L9A0sm51CmRLjK90ZMz%2BzDjaD6UYtfnI5tOEc9Pz6mYJeIzdfHZ4OobQ91QvpJNAKxWxPML%2BsUlJ5jMty1WcxsAxdg6bI4qprQAh%2BJV68MmLKRi8yV%2Bt1xZh1qUAr33Uw11KqzXHorQEtwbf0RZCUn%2BFBDSHFw3U";
        window.__genspark_locale = "fr-FR";
        window.__genspark_token = "To/BnjzloZ3UfQdcSaYfDlt1n2H98BoHF0yEN+5RyRJ+rwpFg2Feo2Try5bFzFWmZUIAZgccxDSCTebWrKrAsWc/dTUled+OqqrhVfMN4fSwZSNqv7MbEjAIT/zvkNe1/080BdQcxczZzCyUWJAseeyCukSgu05DRjzHlSjkWNWyp2fkUjkmYAU/HI4Tp/yaygOxE9AF05c/V15m5pW2vE5aQiWpt5cvwfcfYzdDl5SD0uVSEFv0qaHJ+sM1483JfqS3A2FI55AbUTf6xRNDicMEluNu5d0iRkVFjnF7m7hMjZczIFcypVeRHCi+mnXETTScpTtrbBesCcm/1974GeR+oIOAX58Dw9uKQ8fT7DxV0zizNeMZNpXcEhOtjG1QWaIMIv/zPxoAZhgw8UDH18LtiKT2Pqk9L9A0sm51CmRLjK90ZMz+zDjaD6UYtfnI5tOEc9Pz6mYJeIzdfHZ4OobQ91QvpJNAKxWxPML+sUlJ5jMty1WcxsAxdg6bI4qprQAh+JV68MmLKRi8yV+t1xZh1qUAr33Uw11KqzXHorQEtwbf0RZCUn+FBDSHFw3U";
    </script>
    
    <script id="html_notice_dialog_script" src="https://www.genspark.ai/notice_dialog.js"></script>
    <script defer src="https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon='{"rayId":"950e68813859250f","serverTiming":{"name":{"cfExtPri":true,"cfEdge":true,"cfOrigin":true,"cfL4":true,"cfSpeedBrain":true,"cfCacheStatus":true}},"version":"2025.6.2","token":"4edd5f8ec12a48cfa682ab8261b80a79"}' crossorigin="anonymous"></script>
